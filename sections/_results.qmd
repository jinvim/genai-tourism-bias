## Descriptive analysis

We first report instances where the large language models provided invalid responses.
Most cases were recommendations for non-US destinations.
For instance, most frequently recommended non-US destination was Montreal, Canada (n=302) for Gemini 2.5 Flash Lite, and San Juan, Puerto Rico for GPT-4.1 Nano (n=272).
Removing invalid data resulted in 531 and 823 missing values for Gemini 2.5 Flash Lite and GPT-4.1 Nano.
The maximum number of missing values for a single iteration was 7 for Gemini 2.5 Flash Lite (iteration=906) and 22 for GPT-4.1 Nano (iteration=50). 

@tbl-top10 shows the top 10 most frequently recommended destinations for each large language model.
Most of the highly ranked locations are popular tourist destinations, including Chicago, San Francisco, Austin, Asheville, and Napa Valley.
However, there are notable differences between the two models.
For instance, Gemini 2.5 Flash Lite most frequently recommended Maui, Hawaii (n=56,296), which did not appear in GPT-4.1 Nano's top 10. 
Conversely, Sedona, Arizona ranked as GPT-4.1 Nano's most frequently recommended destination (n=31,874), but did not appear in Gemini 2.5 Flash Lite's top 10.

{{< include tables/_tbl-top10.qmd >}}
: Top 10 most frequently recommended destinations {#tbl-top10}

Additionally, we analyzed the distribution of tourist flows by state and month. 
@fig-month shows the percentage of tourist arrivals by state and month, averaged across 1,000 iterations.
Large language model-simulated tourist visits concentrate in a few states, such as California, Texas, Hawaii, and Florida.
While empirical-based scenarios also exhibit high tourist arrivals in these states, large language model simulations show greater differences between popular and less popular states.
Seasonal patterns are also more pronounced in the large language model outputs than in the empirical-based scenarios.
Gemini 2.5 Flash Lite shows a clear peak during September and October, with more than half of all simulated tourist arrivals concentrated in these two months.
GPT-4.1 Nano shows peaks in April (22.11%), May (18.83%), and September (16.44%).
We also observe that the two large language model simulations exhibit peaks for specific state-month combinations, more so for Gemini 2.5 Flash Lite.
For example, both models show a peak in tourist arrivals to California in September (7.07% and 3.88% for Gemini 2.5 Flash Lite and GPT-4.1 Nano).

![Distribution of simulated tourist arrivals by state and month (mean over 1,000 simulations)](figures/fig-month.png){#fig-month}

@tbl-corr presents direct comparisons of the five scenarios.
The table shows the average Pearson correlation coefficients ($\bar{r}$) between the simulated networks across all 1,000 iterations.
As expected, the random network shows the lowest correlation with the other four scenarios ($\bar{r} \le 0.114$).
Networks with the highest similarities are simulations based on alternative specifications of mobility data and the GPT-4.1 Nano ($\bar{r} = 0.975$).
The two large language model-driven networks also show high correlation ($\bar{r} = 0.942$).

{{< include tables/_tbl-corr.qmd >}}
: Correlation matrix of simulated networks (mean over 1,000 iterations) {#tbl-corr}

{{< pagebreak >}}

## Comparison of characteristics of simulated networks

Boxplots in @fig-stats present the distribution of key metrics across all 1,000 iterations, grouped by simulation scenario.
The dotted red line is the mean of each metric for the random scenario, indicating what can be expected by chance alone.
We conducted permutation T-tests with 10,000 resamples to assess the statistical significance of mean differences between scenarios.
All pairwise differences in means are statistically significant at $\alpha = 0.001$.
Therefore, any differences reported below are statistically significant.
However, statistical significance does not guarantee practical significance [see @gunter2019a], and we emphasize the latter in subsequent discussions.

The two large language model-driven networks have substantially high Gini indices across months (Mean = 0.523 and 0.414 for Gemini 2.5 Flash Lite and GPT-4.1 Nano).
Meaning, large language models produced more seasonal tourist flows, consistent with the descriptive analysis above.
This level of seasonality exceeds that of the random network (Mean Gini index=0.056) and the two empirical-based scenarios (Mean Gini index=0.080 and 0.098 for mobility data and its alternative specification).
The two empirical-based simulations show higher in-strength centralization on average (Mean=0.824 and 0.817) compared to the random network (Mean=0.356).
Large language models produce slightly higher levels (Mean=0.846 and 0.867) than the rest three scenarios.
In other words, the US domestic tourist arrivals are already concentrated in a few states, but large language models produce slightly greater concentration.
These findings support Hypotheses 1 and 2.

Empirical-based networks also show higher levels of reciprocity (Mean=0.155 and 0.179) compared to the random model (Mean=0.102).
This number is equivalent to destinations reciprocating about 16% to 18% of the tourists received. 
However, large language model simulations show lower levels of reciprocity than expected by chance (Mean=0.070 and 0.039). 
Simply put, the large language models produce tourist flows with a clear separation between states that send tourists and those that receive them, supporting Hypothesis 3.

The mean of mean travel distances for the random model is 1,887km (for reference, the mean of all pairwise distances between states is 1,938km).
The empirical-based simulations show much lower mean travel distance on average (Mean=321km and 602km).
The two large language models are noticeably different in geographic patterns.
Gemini 2.5 Flash Lite produces a longer travel distance than empirical models (Mean=768km).
In contrast, GPT-4.1 Nano produces the shortest travel distance (Mean=207km).
GPT-4.1 Nano also exhibits a lower ratio of flows to bordering states (Mean=0.059) than empirical models (Mean=0.154 and 0.231), and a higher self-loop ratio (Mean=0.840) than the two empirical scenarios (Mean=0.700 and 0.472).
Gemini 2.5 Flash Lite produces a similar ratio of flows to bordering states (Mean=0.186) and self-loop ratio (Mean=0.553) as the empirical models.
These findings do not support Hypotheses 4a and 5a, but partially support Hypothesis 6a.

![Distributions of metrics](figures/fig-stats.svg){#fig-stats}

The effects of the last three factors on tourist flows are further examined using Poisson regression (@fig-reg).
Consistent with the literature, distance reduces tourist flows between two states in the empirical models (Mean B=-0.255 and -0.287).
This equals a 22.5% and 24.9% decrease in tourist flows for each 1,000km increase in distance, holding other factors constant.
GPT-4.1 shows a similar negative effect of distance (Mean B=-0.199; 18.0% decrease per 1,000km).
Unexpectedly, Gemini 2.5 Flash Lite shows a positive distance effect (Mean B=0.173; 18.9% increase per 1,000km).
Based on these findings, we do not support Hypothesis 4b.

Other factors being equal, shared borders increase tourist flows in the empirical models (Mean B=2.021 and 1.679; 655% and 436% increase).
Compared to empirical-based scenarios, the effect of shared borders is stronger for Gemini 2.5 Flash Lite (Mean B=2.337; 935% increase) but weaker for GPT-4.1 (Mean B=1.499; 348% increase).
Empirical-based networks also show strong tendencies for self-loops (intra-state tourism).
Because of how we specified the alternative mobility data, the effect of self-loops differs greatly between the two empirical models (Mean B=4.905 and 3.747; 13,360% and 4,417% increase).
Gemini 2.5 Flash Lite shows a stronger effect of self-loops (Mean B=4.987; 14,503% increase), as does GPT-4.1 Nano which shows the largest coefficient across all scenarios (Mean B=5.566; 26,053% increase).
Hence, the results do not support Hypothesis 5b, but partially support Hypothesis 6b.

![Distributions of Poisson regression estimates](figures/fig-reg.svg){#fig-reg}