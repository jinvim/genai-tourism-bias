## Definition of population and simulated samples

The population of our simulations is US residents aged 18 and over. 
To simplify the simulation, we assume that each person chooses one domestic destination within the US (50 US states and the District of Columbia).
The US domestic tourism market is one of the largest in the world [@unwto], offering geographically and socioeconomically diverse destinations.
Hence, the US context provides sufficient variability for large-scale simulations, while excluding complications of international tourism like visa requirements.
Most generative AI models also perform better on English tasks [@qin2025], making the US context advantageous for these models.

From the population, we took a random sample of 1,000 individuals stratified by state, sex, age, and income.
Stratum weights were derived from the 2019-2023 American Community Survey 5-Year Public Use Microdata Sample.
This sampling procedure was repeated 1,000 times, yielding one million simulated individuals with demographic characteristics that mirror the population.
@tbl-demo summarizes the mean, minimum, and maximum values of demographic variables across the 1,000 iterations of simulated sampling.

{{< include tables/_tbl-demo.qmd >}}
: Summary statistics of the demographic profile across the 1,000 simulated samples {#tbl-demo}


## Baseline simulations: Random choice and empirical-based models

Three simulations inform baseline patterns of tourist flows: one assuming random choice and two grounded on empirical data.
The first random choice scenario assumes an equal probability of choosing a destination (a probability of 1/51).
This scenario is equivalent to rolling a die to select a destination.
It provides a baseline that assumes no structure in tourist flow, serving as a null model.

More realistic scenarios use empirical mobility data to derive the probabilities of traveling from a given state.
We used the @advanresearcha mobility dataset from January through December 2024, which estimates movements across US census block groups based on mobile device panels.
Following @lee2025c, commuters and visits within the county of residence were excluded.
Additionally, we used an alternative version that removes visits to adjacent counties.
This offers more conservative estimates by filtering out short-distance trips likely not tourism-related.

Using these estimates as weights, we simulated tourist flows by randomly assigning destinations and months to each individual in the simulated sample.
Due to data anonymization, demographic factors could not be incorporated into the model.
Therefore, we assume that the probability of traveling to another state in a given month is equal for all individuals in a given origin state. 
For instance, if 10% of Illinois residents visited Florida in January 2024, all Illinois residents were given a 0.1 probability to travel to Florida in January (irrespective of other demographic factors).
Two empirical-based scenarios may still under- or over-represent true US domestic tourism flows, but offer more realistic benchmarks than the random choice scenario.

## Large language model simulations

As generative AI models evolve, they are increasingly used in social science research.
Examples include using large language models to simulate social interactions [@liu2023b] and human decision-making under game theory [@akata2025]. 
Tourism researchers have also adopted large language models to replicate survey-based findings [@xiong2024].
Here, we propose the first use of large language models for simulating a tourist flow network.

First, large language models were given a system prompt containing the simulation context, response structure, and examples (available in Appendix \ref{apx-prompt}).
The large language models were instructed to act as travel agents recommending one domestic travel destination based on the provided demographic profile.
The system prompt was followed by a user prompt that included demographic characteristics of each simulated individual.
Twenty people were processed at a time to improve the efficiency of the simulation. 
This process is similar to agent-based modeling using large language models [@gao2024].
But the key difference is that we prompt large language models to act as travel agents, rather than as tourists.

Given the probabilistic nature of large language model outputs, we employ a technique similar to bootstrapping.
The large language models generated recommendations for 1,000 simulated individuals across 1,000 samples.
This process produces a distribution of simulated tourist visits given the demographic profile, helpful in assessing whether the differences in network characteristics between scenarios are meaningful.
Studies have used similar approaches for assessing structural properties of social networks [e.g., @bearman2004].
The difference is that large language models generate networks, rather than defining a model with explicit rules about the formulation of relationships.

To establish the consistency of our findings across different large language models, we used two different models for simulations: Google's Gemini 2.5 Flash Lite (version June 2025) and OpenAI's GPT-4.1 Nano (version April 2025).
They are among the leading large language models currently available in terms of their capabilities and market share.
Because our simulations require a large number of responses, we chose their smallest variants optimized for speed and cost.
Although the two large language models are closed-source, they are comparable in pricing structures ($0.10 per million input tokens; $0.30 and $0.40 per million output tokens, respectively).

All requests were made from the IP address of the university located in the Southeastern US, using custom automation scripts.
To avoid potential bias, we explicitly instructed the models not to use IP-specific details when generating recommendations.
Data collection continued until we achieved a complete dataset.


## Network analysis of simulated tourist flows

We first validated the large language model simulation data, removing any recommendations featuring non-US or invalid destinations.
Duplicate responses were filtered by retaining only the first recommendation.
Researchers also cleaned the state names to ensure consistency (replacing “Washington D.C." with "District of Columbia,” for example).
Subsequently, we aggregated tourist flows at the state-level.
This process was repeated across the 1,000 iterations, resulting in 1,000 origin-destination tourist flow networks for each scenario.
The nodes of networks are US states, and the edges are the number of simulated tourists traveling from one state to another, making them directed weighted networks. 

We then calculated statistics that summarize characteristics of each network, resulting in distributions of metrics across all 1,000 iterations.
The metrics are summarized in @tbl-metrics, along with their relevance, range, and the related hypothesis.
For brevity, we do not provide mathematical definitions of the metrics here, but they are available in Appendix \ref{apx-eq}.

{{< include tables/_tbl-metrics.qmd >}}
: Summary of metrics used in the analysis {#tbl-metrics tbl-colwidths="[35,35,15,15]"}

The index measures the seasonality of tourist flows across months (H1), which is commonly used in tourism and hospitality literature [@duro2016].
The index nears 0 for even seasonal distribution and approaches 1 for strong seasonality.
In-strength centralization is a network-level metric that captures the concentration of tourist flows toward a specific destination (H2).
Similar to the Gini index, values close to 1 indicate concentrated tourist arrivals toward a specific state.
Reciprocity refers to the tendency of nodes to form mutual relationships—in our case, two states exchanging a similar number of tourists (H3).
We adopted the reciprocity metric proposed by @squartini2013.
This metric calculates the ratio of reciprocated flows to total flow, where 1 indicates that states send and receive the same number of tourists.

The mean travel distance represents the average distance tourists travel from their origin to destination (H4a), calculated by averaging the distance between states weighted by the number of simulated tourist visits. 
We also computed the ratio of flows to bordering states (H5a) and the self-loop ratio (H6a).
The former is the proportion of tourist flows between neighboring states compared to total flows, while the latter is the ratio of intra-state tourist flows compared to total flows.

As discussed previously, the mean travel distance, ratio of flows to bordering states, and self-loop ratio are highly interdependent.
To address this interdependence, we tested the effects of travel distance (H4b), shared border (H5b), and self-loop (H6b) on tourist flows using the following Poisson regression model:

$$
x_{ij} = exp(\alpha + \beta_1 \cdot Distance_{ij} + \beta_2 \cdot Border_{ij} + \beta_3 \cdot Selfloop_{ij})
$$ {#eq-reg}

where $x_{ij}$ is the number of simulated tourists traveling from state $i$ to state $j$, $Distance_{ij}$ is the distance between states $i$ and $j$, $Border_{ij}$ is a binary variable that equals 1 if states $i$ and $j$ share borders, and $Selfloop_{ij}$ is a binary variable that equals 1 if $i = j$.
The coefficients $\beta_1$, $\beta_2$, and $\beta_3$ represent the effects of travel distance, border, and self-loop on the volume of tourist flows, respectively.
Same as other metrics, we fitted the model for each of the 1,000 iterations and collected the coefficients across all iterations. 

We acknowledge that inferential network models better account for interdependencies of network data, like the Exponential Random Graph Models [@krivitsky2012]. 
However, these models require Monte Carlo simulations for parameter estimation. 
Such computations are infeasible given our study design, which requires 1,000 estimations for each scenario.
@fig-steps summarizes our simulation and analysis process.

![Overview of the simulation and analysis process](figures/fig-steps.svg){#fig-steps}

## Robustness checks

After the main analysis, we performed the following robustness checks.
First, model size and complexity substantially influence large language model outputs.
To assess the sensitivity of our findings to model size, we repeated the analysis using larger variants of the two models: Gemini 2.5 Flash (version May 2025) and GPT-4.1 Mini (version April 2025).
Temperature settings also affect the randomness of outputs.
In addition to the default temperature setting of 1.0, we repeated the main analysis using lower and higher temperature settings of 0.5 (more deterministic) and 1.5 (more random).
Another major factor that can affect the results is the prompt used to generate recommendations.
We conducted robustness checks with a simplified system prompt that only kept the essential context and excluded any examples that might have influenced the responses.
Finally, large language models from different companies have distinct architectures and training data, which inevitably affect outputs.
The robustness checks include results from two additional models: Meta AI's Llama 4 Scout (version April 2025) and xAI's Grok 3 Mini (version Feb 2025).

Due to budget and time constraints, we only used the first 100 iterations for these checks (i.e., 100,000 simulated individuals).
While changes in temperature settings and system prompts did not significantly alter the results, larger models and models from different companies produced notably different tourist flows.
Nevertheless, our main findings remained consistent across all robustness checks.
The results of the robustness checks are available in Appendix \ref{apx-robust}.