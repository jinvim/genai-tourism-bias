```{r} 
#| label: setup
#| include: false
library(tidyverse)
library(arrow)
library(sf)
library(colorspace)
library(gt)
library(gtsummary)
library(ggtext)
library(glue)
library(patchwork)
library(broom)
```

```{r} 
#| label: load-functions
# load custom functions and theme
source("r/helpers.r")
source("r/theme.r")
theme_set(theme_myriad())

color.rand <- "#777777"
color.nhts <- "#af9da6"
color.advan <- "#c4b4a1"
color.gemini <- "#214e7b"
color.gpt <- "#ff7f05"
```

```{r} 
#| label: read-data
#| include: false
source("r/data.r")
```

# Highlights

- Quantifies generative AI’s potential impact on US domestic tourist flows
- Proposes a Baseline-Rescaling-Outcome Model for testing algorithmic biases in tourism
- Large language models produce more seasonal and less diverse tourist flows
- The models exhibit a popularity bias that favors popular destination-month pairs
- Raises the need to assess the consequences of adopting generative AI in tourism

# Introduction

Generative AI has moved quickly from novelty to everyday tool, changing how we make decisions.
Such algorithmic collaborators are always available and can guide us in making mundane choices to critical business decisions.
Or at least, that is what companies like OpenAI, Google, and Anthropic envision—"outsourcing” components of a human decision to generative AI [@marr2023].
Tourism is no exception.
Most travelers are already using generative AI to plan their trips [@booking.com2025].
Major travel intermediaries like Expedia and TripAdvisor are integrating generative AI into their platforms [@tripadvisor2023;@expedia2023].
Beyond travel planning, generative AI is also supporting core operations in tourism and hospitality firms, such as marketing, revenue management, and human resource management [@amadeus2024].
At destinations, generative AI is expected to shape tourists' experiences during their visits [@dogru2025].

Despite widespread adoption of generative AI across the tourism system, empirical studies on its impact on tourism are scarce [@hsu2024; @gossling2025; @mellors2025]. 
A particular concern is that these algorithms contain ethical and cultural biases [@ali2025; @law2025].
As more tourists and practitioners rely on AI for decision-making, biases in generative AI consequently lead to behavioral shifts that can reproduce or amplify biases in tour society [@kordzadeh2022; @vicente2023].
However, revealing these mechanisms is challenging, given that we lack access to the internal workings of generative AI models and what data they were trained on [@bai2025; @gallegos2024]. 
Even if we had such access, the complexity and black-box nature of generative AI models make it difficult to interpret their decision-making processes.

This study offers empirical insights into how this rapid adoption of generative AI may reshape tourism.
Our focus is on tourist destination choices and its implications for destination sustainability and resilience.
We show how large language models generate travel patterns that deviate from empirical US domestic tourism patterns.
These deviations are explained as systematic *biases* in generative AI, particularly biases that favor popular options and pairs of options.
Because modeling process of generative AI is opaque, we develop the *Baseline-Rescaling-Outcome Model* that can test such biases using empirical expectations, model outputs, and hypothesized bias mechanisms.
Using demographic profiles from the US Census Bureau, we created a simulated sample of 1,000 US residents and provided their profiles to two LLMs: Gemini 2.5 Flash Lite and GPT 4.1 Nano.
The models were instructed to act as travel agents and recommend one domestic travel destination for each individual.
We repeated this process for 1,000 iterations, yielding one million simulated tourist visits for each large language model. 

The two large language models yield less diverse destination-origin-month combinations compared to empirical US domestic tourism patterns.
They also produced more evenly distributed tourist flows where destinations rely on specific months and less diverse origins for tourism demand.
Both models showed a strong destination-month popularity bias—a tendency to favor visiting destinations during their peak seasons.
However, tested models differed in popularity biases toward popular destinations, months, and origin-destination pairs.
The findings serve as early empirical evidence that generative AI poses significant potential to undermine the sustainability and resilience of the tourism sector.
Thus, we call for tourism scholars and practitioners to assess and prepare for generative AI's impact on the tourism system.

# Background

## Generative AI and its impacts on tourism

AI has become a catch-all term that encompasses various technologies aimed at simulating human intelligence. 
Adding to the confusion, tourism literature often discusses AI alongside other technologies like robotics, augmented reality, and virtual reality [@gossling2025].
This study focuses on generative AI and its implications for tourism. Trained to recognize patterns in vast data, these models can produce content such as text, images, or videos [see @epstein2023].
We avoid *chatbots* because they represent just one way generative AI is used.
Likewise, we do not use brand-specific terms like *ChatGPT* when discussing generative AI in general.

Despite widespread adoption of generative AI across industries, empirical studies on its impact on tourism are scarce [@hsu2024].
Tourism and hospitality sector has seen rapid integration of generative AI tools, sparking scholarly interest.
Studies primarily looked at who, when, and why tourists and practitioners adopt generative AI [see recent reviews by @gossling2025; @li2025].
This gap calls for more research providing evidence for projecting how generative AI will shift tourism's trajectory [@law2025; @mellors2025].

Preliminary works explore both positive and negative implications of generative AI in tourism. 
One perspective is that generative AI brings benefits to tourists and businesses.
For tourists, generative AI reduces cognitive load during travel planning, thereby increasing visit intentions and decision satisfaction [@shin2025].
Businesses can also benefit by using generative AI to assist in marketing and content creation [@fan2025].
However, generative AI adoption in tourism also raises concerns about its negative impacts.
@lehto2025 warned against "algorithmic flattening" that erases destination uniqueness.
Generative AI may undermine the sustainability of tourism by exacerbating over-tourism [@mellors2025].
Some conceptual works have examined both positive and negative aspects of generative AI adoption in tourism, concerning value co-creation and co-destruction [e.g., @dogru2025; @grundner2021].

## How AI biases shape tourism

Regardless of whether the study focuses on positive or negative impacts, bias in generative AI is a common concern [refs].
This mirrors previous discussions about biases in other technologies and their impacts on tourism, such as search engines, social media, or smart technologies [@gong2024a;@leung2013; @pan2021].
Consequences of biases in AI is that they lead to behavioral shifts to users relying on AI for decision-making, which reproduce or amplify biases existing of humans [@kordzadeh2022; @vicente2023].

Many studies on biases in algorithms focus on social biases, specifically racial and gender stereotypes [see @ghosh2025; @kordzadeh2022].
Social biases in AI and their ethical implications are also implicit in tourism and hospitality research.
For example, @law2025 highlight ethical challenges of AI adoption in tourism and hospitality sectors, urging inclusiveness of AI adoption with reduced "biased and discriminatory actions" (p.287).
@hsu2024 suggests fine-tuning generative AI with tourism-specific data, noting that such models "could perpetuate stereotypes and result in discrimination" (p.2).
@viglia2024a discuss using AI-generated data for tourism research, giving a specific example of bias against AI generating racist content.

Beyond ethical concerns, AI biases could undermine the sustainability and resilience of tourism sector.
Several schloars mention popularity biases in generative AI as a potential threat, where algorithms favor popular options while underrepresenting less popular ones [@law2024; @lehto2025; @mellors2025].
This bias is of practical concern because it can exacerbate challenges like over-tourism for popular destinations, while less popular destinations struggle to sustain their tourism sector.

Stiil, AI's social and popularity biases in tourism remain as concerns, with little empirical evidence.
We can only speculate that generative AI produce such biases in tourism context.
Generally, these models still exhibit stereotype biases like humans and show less diversity in outputs compared to human counterparts [see @abdollahpouri2020; @bai2025; @wu2024a].
But such biases can have positive consequences.
For example, reduced diversity in generative AI outputs are beneficial in programming task, as correct and efficient solutions are being favored.
Without empirical evidence, we cannot know in what ways and to what extent biases would be benefical or harmful for the tourism sector.

## Defining and measuring biases in generative AI

First we need to define *bias* to understand generative AI's biases in tourism and their implications for the sector.
Works on AI biases in tourism and hospitality are often vague about what is meant by these algorithms being *biased*.
This issue is not unique to tourism scholarship; broader AI bias literature have also been criticized for lacking explicit definition of bias [@ghosh2025].
Such ambiguity in defining bias results in discrepancies between the concerns raised and the empirical evidence provided [@blodgett2020].
Although, AI biases is often undefined or vauguly defined even outside of academia.
For example, the EU's AI Act that mandates AI providers to assess and mitigate biases does not specify what constitutes bias [@vanbekkum2025].

Definition of bias varies not only across disciplines but also by the purpose of examining bias.
When the focus is on stereotyping, studies define bias as *act of* unjustified association between social groups and attributes [for example @bai2025].
This definition is inhereted from social psychology literature on implicit asssociations [@greenwald1998].
Studies examining ethical implications of AI biases often define bias in terms of *outcomes or treatment*: unequal allocation of resources or unfavorable representation of social groups [for example @blodgett2020; @gallegos2024; @kordzadeh2022].
Such definitions are analogous to legal definition of discrimination, a behaviroal outcome of biases, as disparate impacts or treatement [@seiner2006].
Others distinguish bias from harm, where bias is defined as having a particular inclination or deviation of model outputs from empirical data [for example @ghosh2025; @wu2024a].
In this more netural definition of bias that are closely tied to statistical and computer science, bias is considered unavoidable for generalization and because data itself reflects biases of the real world [@chen2023d; @ghosh2025].

Even with a clear definition of bias, measuring biases in generative AI is challenging.
Major obstacle is proprietary and closed-source nature of these models
@ali2025 proposes using tools such as IBM's AI Fairness 360 or Google’s What-If toolkits to asses biasses in AI generated data for tourism reseachers.
These bias assesment tools assume that one has access to the data and internals of the AI models. 
For commonly used generative AI models, however, neither the training data nor the model itself is accessible to end users and researchers [@gallegos2024].
Even with access to the model, recent generative AI models go through value alignment and safety tuning stage to avoid explicit biases [@santurkar2023].
Thus, generative AI models tend to show implicit biases that are harder to detect [@bai2025].
Existing methods for aessing biases in AI are also designed to quantify one type of bias at a time [see review of bias metrics by @gallegos2024; @kordzadeh2022].
For example, a tourism recommendation algorithm may exhibit racial stereotype bias and  popularity bias simultaneously.
But current metrics do not allow for measuring multiple biases at once, which limits diagnoses as models become more complex and their biases become more subtle.

# Baseline-Rescaling-Outcome Model for testing algorithmic biases in tourism

We propose a Baseline-Rescaling-Outcome Model to test algorithmic biases in tourism.
Bias in this model is defined as a *systematic deviation of algorithmic outputs from empirically grounded expectations of tourism phenomena.*
This definition separates bias from harm [@ghosh2025], as what is considered harmful depends on who is being affected [@blodgett2020].
Consider tourism as a system involving multiple stakeholders [@leiper1979].
If an algorithm systematically favors one destination over another, such bias is benefical to the favored but harmful to the rest.
Even for the destination being favored, the tourism sector in that destination could benefit while locals suffer from over-tourism.

Our model tests bias by modeling the divergence between algorithmic *outcome* and empirical *baseline* as a function of *rescaling* factors representing hypothesized bias mechanisms (@fig-model).
Compared to existing methods for assessing biases in AI, our approach has three advantages.
The model assume that the model and its modeling process are inaccessible, which allows testing biases in proprietary and closed-source models.
This assumption is no different from how social scientists study human biases.
We cannot directly observe the biases in cognitive processes, but we can infer countious or uncontious biases from behavioral outcomes such as speed of responses and error rates [@greenwald1998].
Our approach is also flexible.
As long as we can derive empirically grounded expectations, rescaling factors, and algorithmic outputs, we can test biases in algorithms beyond generative AI and outside of tourism context.
Finally, the rescaling factors allows interpretable diagnosis of biases, ideal for translating findings into practical suggestions for mitigating biases.
Although, we caution that the model is not, nor aiming to be, a theory of how biases arise in algorithms.
Biases in algorithms are *caused by* complex socio-technical processes that includes biases in data generating processes, model architectures, and human feedback [@santurkar2023; @viglia2024a].
Because we often lack access to these processes and due to uninterpretable nature of some algorithms, we can only speculate on what causes biases [@bai2025].

![Baseline-Rescaling-Outcome Model](figures/model.svg){#fig-model}

## Outcome: Projected tourism patterns under complete reliance on the algorithm

Given that we assume no access to the modeling process, output of the algorithm is the only means to assess the bias.
Specifically, we use outcome of when *all* decisions are made by the algorithm under study.
This follows the practice of scenario-based projection models that predict outcomes under specified conditions [@runge2024].
Examples include Shared Socioeconomic Pathways for climate trajectories [@ipcc2021] and COVID-19 diffusion models [@adam2020].
These models contain “worst-case” scenarios that project the most extreme outcomes: climate projections without emission reductions or infection rates without government interventions.
Though unrealistic, these extreme scenarios serve as benchmarks for assessing whether action is necessary.
We apply the same logic to studying algorithmic biases.
For example, if we want to test whether generative AI for tourist recommendation system is biased, we project a scenario where all tourists rely on the generative AI.
Simiarly, biases in hiring algorithms for tourism firm can be tested by projecting a scenario where all hiring decisions are made by the algorithm. 

## Baseline: Empirically grounded expectations of tourism phenomena

But without a baseline, we cannot know whether the outputs are biased.
Consider a situation where an algorithm has a four-in-ten chance of suggesting US domestic tourists to visit San Francisco.
Could we say that this algorithm has a systematic tendency to favor San Francisco as a tourism destination?
We argue that to answer this question, one first need an empirical benchmark of what would "unbiased" suggestions look like.
If four in ten Americans visit San Francisco, then the algorithm's tendency is simply reproducing what is expected in the real-world tourism patterns.
However, if only one in ten US domestic tourists visit San Francisco, then the algorithm does favor San Francisco beyond the empirical expectation.
@santurkar2023 implement a similar approach to assess representation biases in large language models by comparing empirical distribution of public opinions with model-generated opinions.
@abdollahpouri2020 similarly used real-world music and movie ratings to assess popularity biases by comparing empirical and algorithm-produced distributions of popularities.

## Rescaling: Testable factors for hypothesized bias mechanisms

Rescaling is the final component of the model that tests specific mechanisms that produce biases.
We do so by reproducing the algorithm outcome using the baseline and a set of rescaling factors.
Under the null condition of no bias, the algorothm should reproduce the baseline hence the rescaling factors are unnecessary.
If the algorithm deviates from the baseline, we can test whether such deviation is systematic by explaining the divergence using hypothesized mechanisms.
This approach yields interpretable tests of specific bias in algorithms, going beyond simply measuring the degree of divergence between baseline and algorithm output.
The direction of bias is another important aspect that our model can capture.
Since we adopted a neutral definition of bias, it is possible for an algorithm to exhibit bises that reduce empricially-observed asymmetries [@ghosh2025].
For example, algorithms could be designed to favor less popular destinations and off-peak seasons, diversifying the tourism demand across destinations and time.
Our model can test for such biases as negative rescaling factors, allowing us to explain algorithm outputs as mixtures of amplification and attenuation of empirical patterns.

# Study design

## Empirical framework for testing popularity biases in generative AI travel suggestions

Using our Baseline-Rescaling-Outcome Model, we test whether generative AI exhibits biases in the tourism context.
In particular, the focus is popularity biases in generative AI when used for travel recommendations.
Popularity bias is defined as tendency where popular options "are recommended even more frequently than their popularity would warrant" [@abdollahpouri2020, p.1].
As major online travel agencies are already intergrating generative AI into their platforms, understanding popularity bias in tourism recommendation context is ideal for providing timely and practical insights.
Popularity bias is not unique to algorithms.
Humans also exhibit similar behaviors, such as popular people gaining even more friends over time [@barabasi1999] and tourists flocking to popular destinations [@lee2025a].
Consequently, our model tests whether generative AI amplifies or attenuates such popularity biases beyond what is observed empirically.

We also argue that examining pouplarity in tourism context is of theoretical significance, even though pouplarity bias is commonly observed in other recommendation algorithms [@chen2023d].
Unlike recommending movies or music, tourism recommendations need to consider spatial and temporal dimmensions of travel choices.
Decision to travel is not only about *whether* to travel, but also *from where*, *to where*, and *when*.
Thus, we further extend popuarity bias into four types that are tourism-specific: destination popularity, month popularity, destination-month popularity, and origin-destination popularity biases.
The first two measure whether popular destinations and peak months are favored by generative AI than what is expected empirically.
While these two factors account for destination and month popularities independently, bias may also exist in specific combinations of destinations and months.
Destination-month popularity bias caputure whether algorithms favor specific destinations during specific months.
Similarly, origin-destination popularity bias capture tendency to excessively pair tourists from specific origins to specific destinations.

Below are operationalizations of the four popularity biases and the empirical framework for testing them.
Define number of tourist flow from origin $i$ to destination $j$ in month $m$ as $Flow_{(i,j,m)}$.
Let $P_{(i,j,m)}$ be the share of tourists from origin $i$ to destination $j$ in month $m$ over all tourist flow ($Flow_{(i,j,m)} / \sum{Flow_{(i,j,m)}}$).
Under the null condition that large language models produce "unbiased" travel suggestions, we expect:
$$
Flow^{LLM}_{(i,j,m)} \sim \sum_{j,m}{Flow^{LLM}_{(i,j,m)}} \cdot P^{Empirical}_{(j,m|i)} = Baseline_{(i,j,m)}
$$ {#eq-null}
where $P^{Empirical}_{(j,m|i)}$ is the share of tourists traveling to destination $j$ in month $m$ given origin $i$ observed empirically ($P_{(i,j,m)} / \sum_{j,m}{P_{(i,j,m)}}$).
This share is multiplied by total number of LLM-simulated tourists from origin $i$, which scales the expected number of tourists based on total tourist outflow from origin $i$.
Meaning, the right hand side of @eq-null is the baseline expectation when LLMs can perfectly replicate empirical tourism patterns ($Baseline_{(i,j,m)}$).

Destination and month popularities are defined as:
$$
\begin{aligned}
D_{j} &= \sum_{i,m}{P^{Empirical}_{(i,j,m)}} \\
M_{m} &= \sum_{i,j}{P^{Empirical}_{(i,j,m)}}
\end{aligned}
$$ {#eq-d-m}
where $D_{j}$ is the popularity of destination $j$ across all origins and months, and $M_{m}$ is the popularity of month $m$ across all origins and destinations.

We account for the popularity of specific destination-month pairs as a joint probability of choosing destination $j$ in month $m$ beyond what can be expected from their independent popularities:
$$
DM_{j,m} = \frac{\sum_{i}{P^{Empirical}_{(i,j,m)}}}{D_{j} \cdot M_{m}}
$$ {#eq-dm}
The denominator in @eq-dm is the expected popularity of the destination-month pair if destination and month popularities were independent.
If $DM_{j,m} > 1$, destination-month pair $(j,m)$ is more popular than expected under independence, while $DM_{j,m} < 1$ indicates the pair is less popular than expected.
Similarly, we account for the popularity of specific origin-destination pairs:
$$
OD_{i,j} = \frac{\sum_{m}{P^{Empirical}_{(i,j,m)}}}{O_{i} \cdot D_{j}}
$$ {#eq-od}
where $O_{i} = \sum_{j,m}{P^{Empirical}_{(i,j,m)}}$.
Same as @eq-dm, $OD_{i,j}$ measures how popular the origin-destination pair $(i,j)$ is compared to what would be expected if origin and destination popularities were independent.

We test the four popularity rescaling factors using the following multiplicative model:
$$
\frac{Flow_{(i,j,m)}^{LLM}}{Baseline_{(i,j,m)}} = 
(D_{j})^{\beta_1} \cdot 
(M_{m})^{\beta_2} \cdot 
(DM_{j,m})^{\beta_3} \cdot 
(OD_{i,j})^{\beta_4}
$$ {#eq-model}
Under the null hypotheses of no systematic bias, we expect all $\beta=0$. If $\beta>0$ for a factor, it positively rescales that factor's popularity in their suggestions; if $\beta<0$, it negatively rescales that factor's popularity.

@fig-beta-demo illustrate how different $\beta_2$ values (month popularity rescaling) affect the distribution of monthly tourist share.
For example, if $\beta_2 = 1$, seasonal variation in tourist flow is amplified, whereas $\beta_2 = -1$ produces a uniform distribution across months.
The model isolate the biases toward specific combinations because $DM_{j,m}$ and $OD_{i,j}$ measure popularities beyond independent popularities of a single factor.
Meaning, if we generate tourist flows with only the destination-month popularity bias ($\beta_3 \ne 0$), the resulting data would show no changes in overall destination or month popularity ($\beta_1 = 0, \beta_2 = 0$).

```{r} 
#| label: fig-beta-demo
#| fig-cap: Example of how different $\beta_2$ values affect distribution of monthly tourist share
#| fig-height: 5
df.beta.demo |> 
    mutate(
        case = factor(
            case,
            levels = c(
                "p.neg2",
                "p.neg1",
                "p",
                "p.pos1",
                "p.pos2"
            ),
            labels = c(
                "beta[2]==-2",
                "beta[2]==-1",
                "beta[2]==0",
                "beta[2]==1",
                "beta[2]==2"
            ),
            ordered = TRUE
        ),
    ) |>
    ggplot(aes(x = month, y = p)) +
    geom_bar(stat = "identity", fill = color.gemini) +
    scale_x_discrete(breaks = c("Jan", "Dec")) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    coord_cartesian(clip = "off") +
    facet_wrap( ~ case, ncol = 5, labeller = label_parsed) +
    theme(
        panel.spacing = unit(1.0, "lines"),
        panel.grid.major.x = element_blank(),
        plot.margin = margin(t = 10, r = 30, b =10, l = 10)
    ) +
    labs(
        title = "Positive β Amplifies Popularity, Negative β Suppresses and Inverts Popularity",
        x = "Month",
        y = "Share of total tourist flow",
    )
```

By taking the log of @eq-model, we can fit a regression model that tests the four popularity biases:
$$
\begin{aligned}
\ln Flow_{(i,j,m)}^{LLM} & = \ln Baseline_{(i,j,m)} \\
& + \beta_1 \cdot \ln D_{j} + \beta_2 \cdot \ln M_{m} + \beta_3 \cdot \ln DM_{j,m} + \beta_4 \cdot \ln OD_{i,j}
\end{aligned}
$$ {#eq-log-model}

## Data collection and analysis

@fig-steps summarizes our data collection and analysis process.
The simulation process involves generating tourist flow under the scenario where all tourists rely on generative AI for travel suggestions.
Using empirically grounded demographic profiles, we created simulated tourists and provided their information to two large language models.
Separately from the simulation, two data sources were used to estimate real-world tourism patterns.
This empirical data is then used to derive baseline expectations and popularity factors.
Finally, we combine simulation and empirical data to test four hypothesized popularity biases by fitting the regression model in @eq-log-model.

![Overview of the simulation and analysis process](figures/steps.svg){#fig-steps}

### Definition of population and simulated samples

The population of our simulations is US residents aged 18 and over. 
The US domestic tourism market is one of the largest in the world [@unwto], offering geographically and socioeconomically diverse destinations.
Hence, the US context provides sufficient variability for large-scale simulations, while excluding complications of international tourism like visa requirements.
Most generative AI models also perform better on English tasks [@qin2025], making the US context advantageous for these models.

We used 2019-2023 American Community Survey 5-Year Public Use Microdata Sample data to derive stratum weights for the population.
@tbl-demo summarizes sex, age, and household income proportions of the population.
From this population, we took a random sample of 1,000 individuals stratified by state, sex, age, and income.
This sampling procedure was repeated 1,000 times, yielding one million simulated individuals with demographic characteristics that mirror the population.
By using empirically derived profiles, we ensure that the demographic distribution of simulated travelers resembles that of US domestic tourists.
This approach also fixes the number of outgoing tourists from each state, allowing us to control for origin-specific propensity to travel.
One limitation is that generative AI models may also influence the decision to travel itself, which we do not account for here.

```{r} 
#| label: tbl-demo
#| tbl-cap: Age, sex, and household income proportions of the population
df.demo.prop |>
    mutate(category = indent_row(category)) |>
    gt(groupname_col = "strat") |>
    fmt_number(
        columns = p,
        decimals = 3
    ) |>
    cols_label(
        category = "",
        p = "Proportion"
    ) |>
    cols_align(
        align = "left",
        columns = category
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_style(
        style = cell_text(whitespace = "nowrap"),
        locations = cells_body(columns = category)
    ) |>
    tab_footnote(
        "Note: Based on 2019-2023 American Community Survey 5-Year Public Use Microdata Sample."
    )
```

### Large language model simulations

Social science researchers are increasingly using generative AI models for generating synthetic data.
Examples include using large language models to simulate social interactions [@liu2023b] and human decision-making under game theory [@akata2025]. 
Tourism scholars have also began noting the benefits and challenges of using AI-generated synthetic data [see @ali2025; @viglia2024a].

We propose an approach that differs from prior studies in four ways.
We assume that large language models do not accurately replicate real-world tourism and contain biases.
Hence, these synthetic datare used to measure such biases, rather than using AI-generated data to *mimic* tourist behavior [for example @viglia2024a; @xiong2024].
Next, we base our simulations on empirically derived demographic profiles.
This modification is to ensure that any divergence from empirical tourism patterns is attributable to algorithmic biases, instead of using arbitrary or non-representative profiles that would confound the results [for example, @andreev2025].
Third, unlike studies that relied on a few handpicked responses or a single simulation run [for example @andreev2025; @mellors2025; @xiong2024], we ran multiple iterations of simulations to sufficiently capture the uncertainty in large language model outputs.
Finally, our approach recognizes the network and temporal nature of tourism.
Beyond looking at the propensity of large language models to suggest specific destinations, our simulation captures the entire tourist flow network across origins, destinations, and months.

The simulation starts with a system prompt containing the simulation context, response structure, and examples (available in @apx-prompt).
To simplify the simulation, we assume that each person chooses one domestic destination within the US (50 US states and the District of Columbia).
The large language models were instructed to act as travel agents recommending one domestic travel destination based on the provided demographic profile.
The system prompt was followed by a user prompt that included demographic characteristics of each simulated individual.
Twenty people were processed at a time to improve the efficiency of the simulation. 
This process is similar to agent-based modeling using large language models [@gao2024].
But the key difference is that we prompt large language models to act as travel agents, rather than as tourists.
The rationale for this choice is that our goal is to project how generative AI would influence tourist flows if widely adopted, rather than using it to substitute for human travelers as research subjects.

Because outputs of large language models are probabilistic, we took an iterative approach to capture the uncertainty in their recommendations.
The large language models generated recommendations for 1,000 simulated individuals across 1,000 samples.
This process produces a distribution of simulated tourist visits given the demographic profile, helpful in assessing whether the differences in network characteristics between scenarios are meaningful.
Studies have used similar approaches for assessing structural properties of social networks [e.g., @bearman2004].
The difference is that large language models generate tourist flow networks, rather than defining a model with explicit rules about the formulation of the network.

To establish the consistency of our findings across different large language models, we used two different models for simulations: Google's Gemini 2.5 Flash Lite (version June 2025) and OpenAI's GPT-4.1 Nano (version April 2025).
They are among the leading large language models currently available in terms of their capabilities and market share.
Because our simulations require a large number of responses, we chose their smallest variants optimized for speed and cost.
We chose these two models also because they use different architectures.
Gemini 2.5 family of models are build on mixture-of-experts architecture, while GPT-4.1 family are built on more traditional transformer architecture.
As these two models are developed by different companies, they likely be trained on different datasets and tuning processes, which is ideal for assessing the generalizability of our findings.
Although the two large language models are closed-source, they are comparable in pricing structures ($0.10 per million input tokens; $0.30 and $0.40 per million output tokens, respectively).

All requests were made from the IP address of the university located in the southeastern US, using custom automation scripts.
We explicitly instructed large language models not to use IP-specific details when generating recommendations to avoid potential bias.
Data collection continued until we achieved a complete dataset.
The collected data were then aggregated to create destination-origin-month matrices for each iteration and model, where each cell represents the number of tourists from the origin. $i$ to destination $j$ in a month $m$.

### Empirical baseline data and simulations

The empirical data serves two purposes in this study.
It provides the baseline for real-world tourism patterns against which we compare the characteristics of AI-simulated tourist flows.
Additionally, we use the empirically derived baseline and popularity factors to explain the discrepancies between AI-simulated and empirical tourist flows.
Because biases also exist in the empirical mobility data [see @huang2021a; @li2024b], we rely on two different data sources to ensure the robustness of our findings.
Our primary data source is the @advan Mobility Data, which estimates movements across US census block groups based on mobile device panels.
This dataset is our primary data source due to its high spatial and temporal resolution, and availability of longitudinal data.
The supplementary data source is the Department of Transportation's 2022 National Household Travel Survey (NHTS).
National Household Travel Survey is the only official national travel survey in the US, which collects travel behavior data such as trip purpose, modes, and distances [@nhts2022].

For both datasets, we used monthly data from January through December 2022 (the latest available for NHTS). 
Following pre-processing steps were employed to filter out non-tourism mobility flows.
We first excluded visits to home and work locations, and movements within the county of residence [@lee2025c].
Additionally, trips under 50 miles one-way and trips within NHTS designated commuting zones were considered non-tourism. 
This offers more conservative estimates of tourist visits by filtering out short-distance and commuting trips that are less likely to be tourism-related.
These estimates were then used to compute the empirical shares and the four popularity factors in the @eq-model.

Since we employed an iterative approach for the large language model simulations, direct comparison with empirical data is inappropriate.
Therefore, we also conducted empirical-based simulations for descriptive comparison between AI-simulated and empirical tourist flows.
Using empirical estimates as weights, we simulated tourist flows by randomly assigning destinations and months to each individual in the simulated sample.
Due to data anonymization, demographic factors could not be incorporated in the empirical-based simulations.
Therefore, we assume that the probability of traveling to another state in a given month is equal for all individuals in a given origin state. 
For instance, if 10% of Illinois residents visited Florida in January 2024, all Illinois residents were given a 0.1 probability to travel to Florida in January (irrespective of other demographic factors).
Same as the large language model simulations, the empirical-based simulation was repeated 1,000 times to generate a distribution of tourist flows.
Subsequently, the results were aggregated to create destination-origin-month matrices for each iteration and two data sources.

## Hypotheses testing

The last step of the analysis is to combine simulation and empirical data to test hypothesized popularity biases.
We achieve this goal by fitting @eq-log-model using the Poisson count model. 
Essentially, the model explains variations in large language model-simulated tourist flows ($Flow_{(i,j,m)}^{LLM}$) beyond what can be expected by empirical data ($Baseline_{(i,j,m)}$), using the four popularity factors as predictors.
We chose the Poisson pseudo-maximum likelihood estimatior, which is widely used in estimating gravity models of trade and migration.
The Poisson pseudo-maximum likelihood estimator only requires the conditional mean to be correctly specified, without requiring a specific distributional assumption.
This estimator is robust to heteroskedasticity and having many zeros in the dependent variable, making the estimator suitable for our analysis [@silva2006; @silva2011].
Because we ran 1,000 iterations of simulations, the model is fitted separately for each iteration and model.
Then, we collect the estimated coefficients across iterations to assess their significance.

# Results

## Descriptive analysis

```{r}
#| label: intext-desc
max.advan <- round(df.sum |> filter(data.name == "Simulation: ADVAN Mobility Data", variable == "Tourist flow") |> pull(max))
max.nhts <- round(df.sum |> filter(data.name == "Simulation: National Household Travel Survey", variable == "Tourist flow") |> pull(max))
max.gemini <- round(df.sum |> filter(data.name == "Simulation: Gemini 2.5 Flash Lite", variable == "Tourist flow") |> pull(max))
max.gpt <- round(df.sum |> filter(data.name == "Simulation: GPT 4.1 Nano", variable == "Tourist flow") |> pull(max))
```

```{r}
#| label: tbl-desc
#| tbl-cap: Descriptive statistics of simulation and empirical data
df.sum |>
    mutate(
        variable = indent_row(variable)
    ) |>
    gt(groupname_col = "data.name") |>
    sub_small_vals(threshold = 0.001) |>
    fmt_number(decimals = 3) |>
    fmt_markdown(columns = notation, rows = TRUE) |>
    cols_align(
        align = "left",
        columns = variable
    ) |>
    cols_label(
        notation = "Notation",
        variable = "Variable",
        min = "Min",
        max = "Max",
        median = "Median",
        mean = "Mean",
        sd = "SD"
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote(
        md("Note: For *simulation* data, statistics are calculated over 1,000 iterations (N=31,212,000). Statistics for *empirical* data are based on a single destination-origin-month matrix (N=31,212).")
    )
```

```{r} 
#| label: tbl-any
#| tbl-cap: Agreement in precence of any tourist flow between large language model simulations and empirical-based simulations
t.any.gemini.advan <- df.any |>
    tbl_cross(
        row = gemini,
        col = advan,
        percent = "cell",
        margin = NULL
    ) |>
    remove_row_type(type = "header")
 
t.any.gemini.nhts <- df.any |>
    tbl_cross(
        row = gemini,
        col = nhts,
        percent = "cell",
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gpt.advan <- df.any |>
    tbl_cross(
        row = gpt,
        col = advan,
        percent = "cell",
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gpt.nhts <- df.any |>
    tbl_cross(
        row = gpt,
        col = nhts,
        percent = "cell",
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gemini <- tbl_merge(
    list(t.any.gemini.advan, t.any.gemini.nhts ),
    tab_spanner = c(
        "*Simulation: ADVAN*",
        "*Simulation: NHTS*"
    )
) 
t.any.gpt <- tbl_merge(list(t.any.gpt.advan, t.any.gpt.nhts )) 

tbl_stack(
    list( t.any.gemini, t.any.gpt),
    group_header = c("Simulation: Gemini 2.5 Flash Lite", "Simulation: GPT 4.1 Nano"),
    ) |> 
    as_gt() |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote("Note: ADVAN=ADVAN Mobility Data, NHTS=National Household Travel Survey. Counts and percentages of destination-origin-month cells with no tourist flow in either simulations, any flow in either of simulations, and any flow in both simulations. Percentages are calculated based on number of possible destination-origin-month combinations (N=31,212). Based on simulated visits aggregated across all 1,000 iterations.")
```

```{r}
#| label: intext-any-prop
intext.any <- df.any |>
    mutate(
        only.gemini.advan = (gemini == "Any flow" & advan == "No flow"),
        only.gemini.nhts = (gemini == "Any flow" & nhts == "No flow"),
        only.gpt.advan = (gpt == "Any flow" & advan == "No flow"),
        only.gpt.nhts = (gpt == "Any flow" & nhts == "No flow"),
        only.advan.gemini = (advan == "Any flow" & gemini == "No flow"),
        only.nhts.gemini = (nhts == "Any flow" & gemini == "No flow"),
        only.advan.gpt = (advan == "Any flow" & gpt == "No flow"),
        only.nhts.gpt = (nhts == "Any flow" & gpt == "No flow")
    ) |>
    summarize(across(
        starts_with("only."),
        sum 
    )) / 31212
intext.any <- lapply(intext.any * 100, sprintf, fmt = "%.1f%%")
```


@tbl-desc presents descriptive statistics of simulation and empirical data.
The origin total outflow are closely matched across all simulations, as our simulated sample is stratified to reflect the population distribution across origins states.
The median tourist flow per destination-origin-month cell is 0 for all simulations, indicating that more than half of the cells have no tourist flow.
This sparsity is expected, given that each iteration assigns 1,000 tourists across 31,212 possible combinations (51 origins × 51 destinations × 12 months).
Thus, even if we randomly assign each of simulated tourists, only about 3.2% of destination-origin-month cells would have at least one tourist flow.
But the head of the distribution differs across simulations.
Large language model simulations show higher concentration of tourist flows in the most popular destination-origin-month combination.
The maximum tourist flow across all cells and iterations is `{r} max.gemini` for Gemini 2.5 Flash Lite and `{r} max.gpt` for GPT 4.1 Nano, which are higher than the two empirical-based simulations (`{r} max.advan` for ADVAN Mobility Data and `{r} max.nhts` for National Household Travel Survey).

Similar patterns are observed when considering presence of *any* tourist flow, without accounting for differences in number of tourists.
@tbl-any presents the agreement between large language model and empirical-based simulations in the precense of any tourist flow across destination-origin-month combinations.
We aggregated the simulated visits across all 1,000 iterations, to reduce the sparsity arising from having only 1,000 tourists per iteration.
Hence, the results indicate whether any of one million simulated tourists were assigned to a given destination-origin-month combination.
In all four comparisons, large language models exclude specific destination-origin-month combinations even though they are present in empirical-based simulations.
For example, `{r} intext.any$only.advan.gemini` of 31,212 combinations are observable in simulation based on empirical ADVAN Mobility Data but not in flows generated by Gemini 2.5 Flash Lite.
Another consistent pattern is that large language models rarely suggest destination-origin-month combinations that are absent in empirical-based simulations. 
Meaning, large language models typically *prune* a large portion of destination-origin-month combinations, but rarely generate new combinations that are absent in empirical data.

```{r}
#| label: intext-dst
dst.gini.advan <- df.dst |> filter(data.name == "advan") |> pull(median.gini) |> first() |> pval_format()
dst.gini.nhts <- df.dst |> filter(data.name == "nhts") |> pull(median.gini) |> first() |> pval_format()
dst.gini.gemini <- df.dst |> filter(data.name == "gemini") |> pull(median.gini) |> first() |> pval_format()
dst.gini.gpt <- df.dst |> filter(data.name == "gpt") |> pull(median.gini) |> first() |> pval_format()
```

```{r}
#| label: plot-dst
#| include: false
bbox <- st_bbox(sf.states)
data_labeller <- as_labeller(
            c(
                "advan" = "ADVAN Mobility Data",
                "nhts" = "National Household Travel Survey",
                "gemini" = "Gemini 2.5 Flash Lite",
                "gpt" = "GPT 4.1 Nano"
            )
        )

df.dst.label <- df.dst |>
    group_by(data.name) |>
    summarize(median.gini = first(median.gini)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

p.dst <- df.dst |>
    ggplot() +
    geom_sf(
        aes(fill = median.sum.p, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Reds 2",
    ) +
    geom_sf_label(
        data = df.dst.label,
        aes(
            geometry = geometry,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Gini: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Are slightly more concentrated at popular destinations",
        fill = "Share of tourist flow (median over 1,000 iterations)",
        x = "",
        y = ""
    )
p.dst
```

```{r} 
#| label: intext-month-prop
month.gini.advan <- df.month |> filter(data.name == "advan") |> pull(median.gini) |> first() |> pval_format()
month.gini.nhts <- df.month |> filter(data.name == "nhts") |> pull(median.gini) |> first() |> pval_format()
month.gini.gemini <- df.month |> filter(data.name == "gemini") |> pull(median.gini) |> first() |> pval_format()
month.gini.gpt <- df.month |> filter(data.name == "gpt") |> pull(median.gini) |> first() |> pval_format()
```

```{r} 
#| label: plot-month
#| include: false
p.month <- df.month |>
    mutate(month = fct_rev(month)) |>
    ggplot() +
    geom_bar(
        aes(y = month, x = median.sum.p, fill = data.name),
        stat = "identity"
    ) +
    geom_label(
        data = df.month |>
            group_by(data.name) |>
            summarize(median.gini = first(median.gini)),
        aes(
            y = "Dec",
            x = 0.25,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Gini: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    # cheating my way to add y axis line for each facet
    geom_vline(xintercept = 0, lty = 1, color = "black") +
    scale_fill_manual(
        values = c(
            "advan" = color.advan,
            "nhts" = color.nhts,
            "gemini" = color.gemini,
            "gpt" = color.gpt
        )
    ) +
    scale_x_continuous(expand = expansion(mult = c(0.0, 0.1))) +
    scale_y_discrete(breaks = c("Jan", "Dec")) +
    coord_cartesian(clip = "off") +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    theme(
        axis.line.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.ticks.y = element_line(linewidth = 0.3),
        legend.position = "none"
    ) +
    labs(
        subtitle = "Are highly seasonal",
        x = "Share of tourist flow (median over 1,000 iterations)",
        y = "",
        fill = "Scenario"
    )
p.month 
```

```{r} 
#| label: plot-month-gini
#| include: false
df.gini.label <- df.month.gini |>
    group_by(data.name) |>
    summarize(median.gini = median(median.gini)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

# for in-text numbers
dst.month.gini.advan <- df.gini.label[1,2] |> pval_format()
dst.month.gini.nhts <- df.gini.label[2,2] |> pval_format()
dst.month.gini.gemini <- df.gini.label[3,2] |> pval_format()
dst.month.gini.gpt <- df.gini.label[4,2] |> pval_format()

p.month.gini <- df.month.gini |>
    ggplot() +
    geom_sf(
        aes(fill = median.gini, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Blues 2",
        rev = TRUE,
        limits = c(0, 1),
        breaks = seq(0, 1, by = 0.2)
    ) +
    geom_sf_label(
        data = df.gini.label,
        aes(
            geometry = geometry,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Median: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Destinations have higher seasonality in tourism demand",
        fill = "Gini coefficient (median over 1,000 iterations; higher values indicate greater inequality)",
        x = "",
        y = ""
    )
p.month.gini
```

```{r} 
#| label: plot-org-entropy
#| include: false
df.entropy.label <- df.org.entropy |>
    group_by(data.name) |>
    summarize(median.entropy = median(median.entropy)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

# for in-text numbers
dst.entropy.advan <- df.entropy.label[1,2] |> pval_format()
dst.entropy.nhts <- df.entropy.label[2,2] |> pval_format()
dst.entropy.gemini <- df.entropy.label[3,2] |> pval_format()
dst.entropy.gpt <- df.entropy.label[4,2] |> pval_format()

p.org.entropy <- df.org.entropy |>
    ggplot() +
    geom_sf(
        aes(fill = median.entropy, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Greens 2",
        limits = c(0.0, 3.0),
    ) +
    geom_sf_label(
        data = df.entropy.label,
        aes(
            geometry = geometry,
            label = median.entropy |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Median: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap( ~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Destinations have less diversified and balanced tourism demand",
        fill = "Entropy index (median over 1,000 iterations; higher values indicate more diversified and balanced demand)",
        x = "",
        y = ""
    )

p.org.entropy
```

```{r}
#| label: fig-prop
#| fig-cap: Characteristics of destination, month, destination-month, and origin-destination popularities across simulations
#| fig-width: 12
#| fig-height: 16 
(p.dst / p.month / p.month.gini / p.org.entropy) + 
    plot_annotation(
        title = "Large Language Models Produce More Unevenly Distributed Tourist Flows",
        subtitle = "Simulations using large language models tend to generate tourist flows that...",
        tag_levels = "a",
        tag_prefix = "(", tag_suffix = ")"
    ) & 
    theme(
        plot.tag = element_text(size = 20, face = "bold")
    )
```

We further examine differences in distribution of tourist flow across simulations by looking at the four popularity factors.
Since we ran 1,000 iterations of simulations, we summarize the findings by taking the median across all iterations.
Mathematical definitions of the metrics are available in @apx-eq.
First, we examine distribution of tourist share by destination states ($D_j$) and months ($M_m$).
We use the Gini index to quantify the inequality in these distributions, where a higher Gini index indicates greater concentration of tourist share among fewer states or months.
In all four simulations, tourist visits concentrate in a few popular states, such as California, Florida, and Texas (@fig-prop[a]()).
However, large language model simulations show higher Gini indices than empirical-based simulations, indicating greater inequality in tourist arrivals across states (ADVAN Mobility Data=`r dst.gini.advan` and National Household Travel Survey=`r dst.gini.nhts`; Gemini 2.5 Flash Lite=`r dst.gini.gemini` and GPT 4.1 Nano=`r dst.gini.gpt`).

Seasonal patterns are also more pronounced in the large language model outputs than in the empirical-based scenarios (@fig-prop[b]()).
The two large language model-generated networks also have substantially high Gini indices across months (Median = `r month.gini.gemini` and `r month.gini.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).
This level of seasonality exceeds that of the two empirical-based scenarios (Median = `r month.gini.advan` and `r month.gini.nhts` for ADVAN Mobility Data and National Household Travel Survey).
Although, the two large language models are different in which months are most popular.
Gemini 2.5 Flash Lite shows a clear peak during September and October, with more than half of all simulated tourist arrivals concentrated in these two months.
GPT-4.1 Nano shows peaks in April, May, and September.
Further, large language models worsen the seasonality of tourism demand at the destination level.
In @fig-prop[c](), we calculated Gini index of monthly tourist share for each destination state and took the median over 1,000 iterations.
Few states show relatively high seasonality in the empirical-based simulations, such as Alaska and Hawaii.
However, most states exhibit high seasonality in the large language model simulations.
This tendency leads to overall higher level Gini indices accross all destinations (Median of medians = `r dst.month.gini.advan` and `r dst.month.gini.nhts` for ADVAN Mobility Data and National Household Travel Survey; `r dst.month.gini.gemini` and `r dst.month.gini.gpt` for Gemini 2.5 Flash Lite and GPT 4.1 Nano).

Examining patterns in origin-destination pairs require a different approach.
Although Gini index can be used, it does not effectively capture whether destination states receive tourists from a diverse set of origin states or rely on a few.
Such demand characteristics are of importance for tourism sector, as less diversity of tourist origins and higher reliance on a few origin markets undermines resilience to shocks [see @lee2025c].
We use entropy index for measuring how diversified and balanced the demand for destinations is.
A higher entropy value indicates that a destination receives tourists from wide range of origins (diversified demand) and that each origin have similar contribution to the total tourist arrivals (balanced demand).
We calculate the entropy index for each destination and summarize the results over 1,000 iterations by taking the median.

@fig-prop[d]() shows that large language models have tendency to generate travel suggestions that destinations rely on a few origins.
The empirical simulations show that states such as Florida, Illinois, and North Carolina tend to have diversified and balanced demand (higher entropy).
For the two AI-simulated tourist flows, the entropy indices are overall lower than those of empirical-based simulations (Median of medians = `r dst.entropy.advan` and `r dst.entropy.nhts` for ADVAN Mobility Data and National Household Travel Survey; `r dst.entropy.gemini` and `r dst.entropy.gpt` for Gemini 2.5 Flash Lite and GPT 4.1 Nano).
We also observe that fewer states exhibit relatively high entropy values in the large language model simulations (for example, Colorado and Hawaii for Gemini 2.5 Flash Lite).

```{r} 
#| label: intext-graph-stats
df.graph.sum <- df.graph |>
    group_by(stat, data.name) |>
    summarize(
        median.value = median(value)
    )
# reciprocity
recip.advan <- df.graph.sum[1,3] |> pval_format()
recip.nhts <- df.graph.sum[2,3] |> pval_format()
recip.gemini <- df.graph.sum[3,3] |> pval_format()
recip.gpt <- df.graph.sum[4,3] |> pval_format()
# median travel distance
mdist.advan <- df.graph.sum[5,3] |> round()
mdist.nhts <- df.graph.sum[6,3] |> round()
mdist.gemini <- df.graph.sum[7,3] |> round()
mdist.gpt <- df.graph.sum[8,3] |> round()
# border ratio
br.advan <- df.graph.sum[9,3] |> pval_format()
br.nhts <- df.graph.sum[10,3] |> pval_format()
br.gemini <- df.graph.sum[11,3] |> pval_format()
br.gpt <- df.graph.sum[12,3] |> pval_format()
# self-loop ratio
sl.advan <- df.graph.sum[13,3] |> pval_format()
sl.nhts <- df.graph.sum[14,3] |> pval_format()
sl.gemini <- df.graph.sum[15,3] |> pval_format()
sl.gpt <- df.graph.sum[16,3] |> pval_format()
```

```{r} 
#| label: fig-graph-stats
#| fig-cap: Characteristics of tourist flow structure across simulations
#| fig-height: 10
df.graph |>
    mutate(
        data.name = fct_rev(data.name) 
    ) |>
    ggplot(aes(x = value, y = data.name, fill = data.name)) +
    geom_vline(
        data = df.graph.rand |>
            group_by(stat) |>
            summarize(value = median(value)),
        aes(xintercept = value),
        linetype = "dashed",
        linewidth = 0.7,
        color = "red",
    ) +
    geom_boxplot(
        alpha = 0.8,
        width = 0.6,
        linewidth = 0.3,
        outlier.shape=1,
    ) +
    scale_fill_manual(
        values = c(
            "ADVAN" = color.advan,
            "NHTS" = color.nhts,
            "Gemini 2.5 Flash Lite" = color.gemini,
            "GPT 4.1 Nano" = color.gpt
        )
    ) +
    facet_wrap( ~ stat, ncol = 1, scales = "free_x", strip.position = "bottom") +
    expand_limits(x = 0) +
    theme(
        strip.text = element_text(face = "plain"),
        strip.placement = "outside",
        axis.ticks.y = element_line(linewidth = 0.3),
        axis.text.y = element_text(face = "italic"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5),
        panel.grid.major.y = element_blank(),
        panel.spacing = unit(2.0, "lines"),
        legend.position = "none",
        plot.margin = margin(t = 10, r = 60, b = 10, l = 10)
    ) +
    labs(
        title = "Generative AI Produce Structurally Different Tourist Flows",
        subtitle = "Large language model-generated tourist flows exhibit lower reciprocity and fewer trips to bordering states",
        caption = "Note. Dashed red line indicates what would be expected if destination-origin-month combinations are completely random (uniform probability).",
        x = "",
        y = "",
    )
```

In addition to analyzing individual popularity factors, we analyze the overall structure of tourist flows.
We constructed an origin-destination matrix by aggregating tourist numbers at the year level.
Then we computed four statistics capturing how the global structure of tourist flows differ across simulations.
Box-plots in @fig-graph-stats present the distribution of the four network-level statistics across 1,000 iterations, colored by simulation scenario.
The dotted red line indicates what can be expected by chance alone, if there is no structure in tourist flow.
This expectation under complete randomness is calculated by assuming that each individual have equal probability of choosing a destination (a probability of $1/51$).

Reciprocity refers to the tendency to form mutual relationships—in our case, two states exchanging a similar number of tourists.
Empirical-based simulations show higher levels of reciprocity compared to the random expectation (Median = `r recip.advan` and `r recip.nhts` for ADVAN Mobility Data and National Household Travel Survey).
However, large language model simulations show lower levels of reciprocity than expected by chance (Median = `r recip.gemini` and `r recip.gpt` for Gemini 2.5 Flash Lite and GPT 4.1 Nano).
Simply put, the large language models produce tourist flows with a clear separation between states that send tourists and those that receive them.

Gemini 2.5 Flash Lite and GPT 4.1 Nano tend to suggest farther destinations compared to empirical data, when looking at median travel distance excluding in-state trips (Median of medians = `r mdist.gemini` and `r mdist.gpt`).
Similarly, Gemini 2.5 Flash Lite has lower ratio of tourist flows between bordering states compared to the empirical models (Median = `r br.gemini`).
GPT-4.1 Nano shows even lower tendency to suggest bordering states, lower that what would be expected under randomness (Median = `r br.gpt`). 
The two models show different propensity to suggest in-state tourism.
Gemini 2.5 Flash Lite shows ratio of in-state trips comparable to the empirical models (Median = `r sl.gemini`).
In contrast, GPT 4.1 Nano shows much stronger preference for recommending tourist to travel within their own state (Median = `r sl.gpt`).

## Model estimation results

```{r} 
#| label: intext-betas
# d coeffs
b.d.gemini.advan <- betas.sum[1, 4] |> sprintf(fmt = "%4.3f")
b.d.gemini.nhts <- betas.sum[5, 4] |> sprintf(fmt = "%4.3f")
b.d.gpt.advan <- betas.sum[9, 4] |> sprintf(fmt = "%4.3f")
b.d.gpt.nhts <- betas.sum[13, 4] |> sprintf(fmt = "%4.3f")

# m coeffs
b.m.gemini.advan <- betas.sum[2, 4] |> sprintf(fmt = "%4.3f")
b.m.gemini.nhts <- betas.sum[6, 4] |> sprintf(fmt = "%4.3f")
b.m.gpt.advan <- betas.sum[10, 4] |> sprintf(fmt = "%4.3f")
b.m.gpt.nhts <- betas.sum[14, 4] |> sprintf(fmt = "%4.3f")

# dm coeffs
b.dm.gemini.advan <- betas.sum[3, 4] |> sprintf(fmt = "%4.3f")
b.dm.gemini.nhts <- betas.sum[7, 4] |> sprintf(fmt = "%4.3f")
b.dm.gpt.advan <- betas.sum[11, 4] |> sprintf(fmt = "%4.3f")
b.dm.gpt.nhts <- betas.sum[15, 4] |> sprintf(fmt = "%4.3f")

# od coeffs
b.od.gemini.advan <- betas.sum[4, 4] |> sprintf(fmt = "%4.3f")
b.od.gemini.nhts <- betas.sum[8, 4] |> sprintf(fmt = "%4.3f")
b.od.gpt.advan <- betas.sum[12, 4] |> sprintf(fmt = "%4.3f")
b.od.gpt.nhts <- betas.sum[16, 4] |> sprintf(fmt = "%4.3f")
```

@tbl-betas and @fig-betas summarizes how the four popularity factors can explain deviation between large language model-simulated tourist flows and the empirical expectations (@eq-log-model).
Across two large language models and two empirical baselines, destination-month popularity consistently has the largest positive coefficient.
Meaning, large language models show a tendency to favor popular destination-month combinations when generating travel recommendations.
Although, lower bounds of 95% credible intervals for Gemini 2.5 Flash Lite crosses zero with ADVAN Mobility Data baseline and is very wide with National Household Travel Survey baseline, indicating unncertainty around the estimate.

One way to interpret the coefficient for destination-month popularity is to consider it as an elasticity.
For example, GPT 4.1 Nano with ADVAN Mobility Data baseline had a median coefficient of `r b.dm.gpt.advan` for destination-month popularity.
If real-world data shows that a particular destination-month combination is twice as popular than what is expected under independence of destination and month popularity ($DM_{(j,m)} = 2$), then the expected tourist flow generated by GPT 4.1 Nano for that combination is approximately `r round(2 ** as.numeric(b.dm.gpt.advan), 1)` times higher ($2^{1.771}$), holding other factors constant.

We find mixed results for the rest of the popularity factors.
Some effects are specific to the large language model.
For example, Gemini 2.5 Flash Lite consistently shows negative coefficients for destination popularity, indicating that it tends to negatively rescale popular destinations (Median $\beta_{1}$ = `r b.d.gemini.advan` and `r b.d.gemini.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).
The same pattern is only observed for GPT 4.1 Nano with National Household Travel Survey baseline (Median $\beta_{1}$ = `r b.d.gpt.nhts`) but not with ADVAN Mobility Data baseline (Median $\beta_{1}$ = `r b.d.gpt.advan`).
GPT 4.1 Nano with shows positive rescaling for origin-destination popularity (Median $\beta_{4}$ = `r b.od.gpt.advan` and `r b.od.gpt.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines), while Gemini 2.5 Flash Lite shows mixed findings (Median $\beta_{4}$ = `r b.od.gemini.advan` and `r b.od.gemini.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).

Finally, we note that the month popularity coefficients are negative for GPT 4.1 Nano (Median $\beta_{2}$ = `r b.m.gpt.advan` and `r b.m.gpt.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).
This is contradictory, given prior descriptive analysis indicated GPT 4.1 Nano having greater seasonality.
One possible explanation is that peak months in GPT 4.1 Nano simulations do not align with those in empirical data (see @fig-prop[b]()).
Therefore, the model attempts to fit the month popularity factor by flattening the empirical month popularity distribution.

```{r}
#| label: tbl-betas
#| tbl-cap: Median and 95% credible intervals of Poisson model coefficients accross 1,000 iterations
betas.sum |> 
    pivot_wider(names_from = emp, values_from = c(median.coeff, lower.ci, upper.ci)) |>
    relocate(ends_with("_ADVAN"), .after = param) |>
    mutate(
        param = factor(
            param,
            levels = levels(param),
            labels = md(
                c(
                "$\\beta_{1}$: Destination",
                "$\\beta_{2}$: Month",
                "$\\beta_{3}$: Destination-Month",
                "$\\beta_{4}$: Origin-Destination"
                )
            )
        ),
        sim = paste("Simulation:", sim)
    ) |>
    mutate(param = indent_row(param)) |>
    gt() |>
    tab_spanner(
        label = html("Empirical: ADVAN"),
        columns = ends_with("_ADVAN")
    ) |>
    tab_spanner(
        label = html("Empirical: NHTS"),
        columns = ends_with("_NHTS")
    ) |>
    fmt_number(decimals = 3) |>
    fmt_markdown(columns = param, rows = TRUE) |>
    cols_align(
        align="left",
        columns = param
    ) |>
    cols_label(
        param = "",
        starts_with("median.coeff") ~ "Median",
        starts_with("lower.ci") ~ "2.5%",
        starts_with("upper.ci") ~ "97.5%",
    ) |>
    # italicize sim & emp names
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_column_spanners()
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote(
        md("Note: ADVAN=ADVAN Mobility Data, NHTS=National Household Travel Survey. Summary of Poisson model results over 1,000 iterations.")
    )
```

```{r} 
#| label: fig-betas
#| fig-cap: Summary of popularity effect estimates across 1,000 iterations
text.beta <- data.frame(
    median.coeff = c(0, 0),
    param = c(4, 4),
    emp = c("ADVAN", "ADVAN"),
    sim = c("GPT 4.1 Nano", "GPT 4.1 Nano"),
    label = c("***Negative rescaling*** ←", "→ ***Positive rescaling***")
)

p.betas <- draw_beta_fig(betas.sum) +
    scale_shape_manual(
        values = c("Gemini 2.5 Flash Lite" = 20, "GPT 4.1 Nano" = 18)
    ) +
    scale_color_manual(
        values = c("Gemini 2.5 Flash Lite" = color.gemini, "GPT 4.1 Nano" = color.gpt)
    ) +
    # annotate attenuation (B<0) and amplification (B>0)
    geom_richtext(
        data = text.beta,
        label = text.beta$label,
        color = "black",
        fill = NA, label.color = NA,
        vjust = -2,
        hjust = c(1.1, -0.1),
        size = 4,
    ) +
    labs(
        title = "Generative AI Amplify Popularity of Destination-Month Pairs",
        subtitle = "Other popularity factors are dependent on specific large language model used and show mixed results",
        caption = "Note: Summary of Poisson model results over 1,000 iterations. Error bars represent 95% credible intervals for the estimates.",
    )
p.betas
```

## Robustness checks

We conducted following robustness checks to test the sensitivity of our findings to different simulation choices (reported in @apx-robust).
These additional simulations were performed with the first 100 iterations due to budget and computing time constraints.
First, using alternative prompts does not substantially change the main findings.
Large language model outputs are sensitive to the specific prompts used.
Hence, we collected additional simulation data using slightly modified prompts (see @apx-prompt).
One version excluded explicit instruction that demographic factors influence tourist choices ("reduced instruction" prompt).
Another version instructed the models to act as *tourists* choosing destinations instead of travel agents giving suggestions ("tourist persona" prompt)
None of these alterations substantially changed the main findings (@fig-prompt-betas).
One notable exception is that Gemini 2.5 Flash Lite with reduced instruction prompt showed negative coefficients for month popularity.
However, this case also showed stronger effects for destination-month and origin -destination popularity.

Changing the temperature parameter also does not alter the results.
The temperature parameter controls randomness in large language model outputs.
Higher temperature setting produce more diverse outputs, while lower temperature setting generate more deterministic outputs.
The default temperature setting used in our main analysis is 1.0.
We collected additional data using temepratures of 0.5 and 1.5 (@fig-temp-betas).
GPT 4.1 Nano with temperature of 1.5 could not generate valid outputs and hence was excluded.
Similiar to @bai2025, we find that temperature setting has minimal impact on the popularity bias of large language models.

Larger models in the Gemini 2.5 and GPT 4.1 series, as well as models from other providers, still show amplified destination-month popularity.
We repeated the main analysis with larger variants of Gemini 2.5 and GPT-4.1 series models (Gemini 2.5 Flash and GPT-4.1 Mini).
Additionally, we collected data using xAI's Grok 3 Mini and Meta's Llama 4 Scout to examine whether the findings are generalizable beyond OpenAI and Google models.
Across all models tested, destination-month popularity shows strongest positive effects (@fig-model-betas).
Compared to the models used in our main analysis, larger models show stronger destination-month popularity bias, not weaker.

Finally, we examined robustness of our findings to alternative approach for fitting Poisson regression model to our iterative simulation data.
Our results are robust to using aggregated data instead of fitting Poisson regression models for each iteration separately.
We conducted alternative hypothesis tests by aggregating the simulation data across all 1,000 iterations and fitting a single Poisson regression model for each large language model simulation.
This approach significantly reduces the number of destination-origin-month cells with zero tourist counts.
We can also obtain significance levels for the estimated coefficients using  traditional frequentist tests.
Coefficient estimates using aggregated data are nearly identical to median estimates from our main approach (see @tbl-agg-betas).

# Discussions

Despite the rapid adoption of generative AI in tourism, there exists little empirical evidence on how these algorithms operate.
Understanding these mechanisms is crucial, as downstream of these algoritms are real-world decisions made by tourists and practitioners.
Our focus is in what way generative AI diverges from empricial tourism patterns and what underlying mechanisms drive such differences.
However, revealing these mechanisms is challenging, given we lack access to the internal workings of generative AI models and what data they were trained on.
Even we had such access, the complexity and black-box nature of generative AI models make it difficult to intepret their decision-making processes.
But so are humans—tourists are complex decision-makers influenced by myriad factors, many of which are not fully understood.
Same as how social scientists study human cognitive bases based on their behaviors, we propose a model for testing biases in algorithms based on their outcomes.
Our framework models the difference between algorithm outcomes and emprically-grounded baselines using hypothsized mechanisms, producing interpretable results on what factors drive such differences.

## Key findings

The models generate less diverse and more unevenly distributed tourist flows compared to empirical US domestic tourism patterns.
Of 31,212 possible combinations of destination-origin-month, less than 10% are "new" combinations that were not observed in the empirical data (@tbl-any).
In contrast, about `{r} intext.any$only.nhts.gpt` to `{r} intext.any$only.advan.gemini` of combinations never appeared in the large language model simulations, even though they were observed in the empirical data.
States show slightly more unequal levels of tourist arrivals, with popular states continuing to be popular in large language model simulations (@fig-prop[a]()).
More concerning issue is that both models produce highly seasonal tourism patterns.
While seasonality is common feature of tourism [@butler1994; @duro2016], these algorithms show much sharper peaks and troughs than empirical data (@fig-prop[b]()).
This finding is alarming for *all* US destinations, as both popular and less popular states show greater seasonality in tourist arrivals (@fig-prop[c]()).
Destinations also become more reliant on a few tourist origins in large language model simulations (@fig-prop[d]()).

Large language models also produce structurally different tourist flows (@fig-graph-stats).
These models produce less reciprocal tourist flows to farther states.
Meaning popular destinations would receive more tourists but send fewer to others, leading to a more "one-way" tourism system.
Other spatial patterns differ between the two large language models.
GPT 4.1 Nano shows much stronger avoidance for bordering states and favors in-state tourism.
Tendency to avoid bordering states is not as severe in Gemini 2.5 Flash Lite, while showing prevalence of in-state tourism similar to empirical baseline.

Large language models favor visiting destinations during their peak months (@fig-betas).
We find consistent evidence of this destination-month popularity bias, across three different prompts, three temperature settings, and six large language models (@apx-robust).
Findings are mixed for the other three popularity factors.
The results mostly vary by large language model used, rather than alternative settings for simulations or empirical baselines.
For example, the models other than GPT 4.1 family attenuate empirically popular destinations, while the two GPT 4.1 family mdoels also show bias toward popular origin-destination pairs.
Unfortenately, this study could not identify why the models show different types and degree of popularity biases.
Because process of building these models remain opaque, we can only speculate that the differences arise from variations in training data, model architectures, and human feedback [@chen2023d; @santurkar2023].
Given that these algorithms are *language* models, they may also reflect linguistic and cultural representations of what is meant by tourism or to travel [see @resnik2025; @tao2024].

## Theoretical implications

This study provides early empirical evidence that generative AI poses significant potential to undermine sustainability and resilience of tourism sector.
While we are seeing generative AI increasingly affecting decisions of tourists and pracitioners, what this entails for stakeholders in the tourism system reamined unclear.
Hence, understanding the downstream consequences of generative AI adoption is urgent real-world issue that tourism research could impact society [@li2026].

Our findings substantiate prior concerns that these algorithms could introduce bises that exacerbate ethical and social issues in tourism [@law2025; @lehto2025; @mellors2025].
We show that such biases not only have ethical implications but also practical consequences for economic sustainability of tourism industries.
Generative AI models provide travel suggestions that worsen seasonality of tourism for destinations, reduce diversity of demand origins, and reduce bi-directional exchange of tourists among regions.
All these patterns go against conditions for fostering sustainable tourism development and resilient tourism sector [for example, @cisneros-martinez2018; @lee2025c; @wttc2022].
Thus, we echo the previous cautions that technology adoptions in tourism should not be seen as *progress* or *advancements*; rather, they are *changes* that we must navigate to assess their implications for all tourism stakeholders [@tribe2017].

The proposed Baseline-Rescaling-Outcome Model contribute to existing literature on AI bias metrics by offering an interpretable framework for testing algorithmic bises.
The existing methods often required access to internal model parameters and could mainly tell whether biases exists [@bai2025; @chen2023d].
Our approach goes further by testing multiple hypothesized mechanisms that could amplify or attenuate empirical patterns, thereby explaining why we observe certain divergence from empirical data.
While these explanations are still correlational rather than causal, they allow us to understand systemic mechanisms behind the black-box algorithms.

This study focused on measuring bias in genreative AI from supplier-side and its implications for destinations.
However, bias and their consequences can also be studied from both demand-side, focusing on whether *tourists* are exposed to personalized and diverse travel options.
For instance, recommendation algorithm with popularity biase from supply-side can also lead to users receiving less satisfying options [@abdollahpouri2020].
Similarly, casues of these biases can also be spectulated from both demand- and supply-side.
These biases may arises from learning to reflect popular tourist behvaviors (demand-side) or content from popular destinations with more marketing resources being more prevalent in training data (supply-side).

Our large language model simulations are projections wherein *all* tourists’ decisions are made by generative AI.
They are hypothetical scenarios, far from the current reality.
However, we use these projections because they can illustrate how generative AI might reshape tourist flows, by isolating the patterns of generative AI-driven tourism and comparing them to empirical baselines.
This present an opportunity to shift the relationship between empirical phenomena of generative AI adoption in tourism and related tourism knowledge.
Currently, empirical phenomena of generative AI adoption outpace tourism knowledge production, due to generative AI's rapid evolution and academic publication delays.
This study demonstrates an alternative route: *a priori* knowledge production by tourism scholars that informs decision-making in tourism practice.
Such guiding knowledge will prove crucial for tourism scholarship and practitioners to ensure sustainable and resilient tourism systems amid rapid technological changes.

## Methodological contributions

We pioneer a large-scale simulation using generative AI for projecting their potential impacts on tourism and testing biases in these algorithms.
We provide all code and synthetic data from the simulations, for replicating and extending our analyses.
This includes the full dataset of two millon individual-level travel suggestions from two main large language models and additional one million obtaind for robustness checks.

Our methodological contributions are twofold.
One is providing empirically-grounded profiles of simulated tourists to ensure representativeness of the simulations.
This approach contrasts with prior tourism studies that used synthetic data from generative AI, which either assumed hypothetical tourist segments or bludly instructed to simulate tourist behavior without first providing what touirists the model needs to simulate [for example @andreev2025; @xiong2024].

Another difference is that we account for stochasticity in simulations by running multiple iterations instead of relying on a single run [for example @andreev2025;@mellors2025].
Tourism is a complex system, where the outcomes are probabilistic rather than deterministic [@faulkner2003].
As such, our approach acknowledges that even the empirical data is one of many possible outcomes.
By creating simulated realizations of the tourism patterns under empirical-driven and AI-driven scenarios, we can better project the range of possible outcomes and identify which observed patterns constitute robust features versus artifacts of stochastic variation.

Based on the findings, we question relability of using AI-generated synthetic data even for exploratory and early-stage research purposes [suggested by @ali2025; @viglia2024a].
Despite our efforts to ensure representativeness and robustness of simulations, large language models still produced tourism patterns that diverge substantially from empirical data.
@santurkar2023 also found that generative AI poorly represent the general public nor particular subpopulation even when steered to do so.
Because our purpose is to examine the biases in generative AI, such divergences are informative.
However, if researchers use AI-generated synthetic data for a pilot study, the results may mislead future research directions.
As these algorithms behave in more extreme and different ways than real-world tourists, we must caution synthetic data *limiting* tourism knowledge development rather than advancing it.

## Practical implications

Our perspective is that generative AI has benefits for tourism sectors but we also need to weigh its potential risks.
It can be used as a tool for tourists to efficiently seek travel information, practitionrs to guide their decisions, and destinations to get ideas for improving their tourism experiences [refs].
Nevertheless, these benefits are not without costs; they also introducing new issues to tourism system [@dogru2025].

Therefore, we urge tourism practitioners and regulators to monitor and prepare for generative AI’s potential impacts on tourist behavior and destination choice.
Lesser-known destinations are particularly vulnurable.
Generative AI models train on extensive cross-domain datasets, making their outputs difficult to alter.
Addressing such challenges would require efforts from both regulators and tourism intermediaries to ensure equitable and diverse representation of destinations.
For example, EU AI Act mandates bias testing for high-risk AI systems, such as credit scoring and employment screening [@vanbekkum2025].
Tourism could also advocate for simliar legislation for auditing biases using methods like the one proposed in this study.
Such bias audits would needed for both tourist- and employee-facing generative AI applications.
We argue that already-popular destinations to take part in such effect, as they also are expected to exprience negative consequences from worsened seasonality and reduced demand diversity.
More simple interventions include putting a disclosure that "AI-generated suggestions may overrepresent popular options" and stratifying options before producing AI-generated options.

We call for national and international tourism organizations begin assessing implications of generative AI adoption.
Beyond sustainability and resilience issues discussed, potential ethical and social consequences should also be assesed.
Organizations must recognize that tourism functions not merely as a "market offering" but as a societal force affecting people and communities [@higgins-desbiolles2006].
For example, one social benefit of tourism is that it provides experiences and opportunities for socially excluded groups [@mccabe2020a].
These benefits may diminish if generative AI limits travel options for particular demographic groups.
While we caution generative AI's potential consequences for tourism, the time is right to proactively shape the future of tourism before generative AI is further integrated into tourism industries.
Our projected generative AI-driven tourism is still hypothetical; it is up to us whether such a future may never come to pass.

## Limitations and future research

Consider the following key limitations when interpreting our findings.
First, our large language model simulations rely solely on demographic factors and exclude psychological, behavioral, and social variables that shape tourist decisions.
One of which is tourist motivation.
Even if two individuals with an identical demographic profile visited the same destination, they could have entirely different motivations for visiting.
Consequently, our findings only provide a general view of tourist flows generated by generative AI.
Future research could consider specifying preferences and motivations for each simulated tourist [see @gao2024].
In addition, simulations could incorporate different rates of accepting AI-generated recommendations for more realistic projections.
For instance, younger individuals are generally more inclined to accept generative AI recommendations compared to older individuals [@seyfi2025], which could result in different travel patterns than those observed in our "extreme-case" scenarios.

The results are subject to the modifiable areal unit problem, as the choice of geographic unit affects the results [@fotheringham1991].
Large language models recommended destinations in varying geographic units, which we aggregated to the state level for analyses.
This aggregation masks variations at finer geographic scales, thus likely underestimates the differences between the empirical and generative AI-driven scenarios.

Our simulations assume that everyone travels and selects a single destination.
But we must consider that there are non-travelers who choose not to travel [@haukeland1990] and tourists visiting multiple destinations during a single trip [@yang2013].
One tourist's decision can also influence the decisions of others [@lee2025a], although our simulations do not account for interactions between simulated individuals.
Further, studies show that generative AI exhibits stonger bias when decisions are relative rather than absolute [@bai2025].
Since we instructed the model to recommend a single destination instead of chosing one among given options, the degree of popularity bias shown in this study may be conservative.
However, decisions of real-world tourists also are significantly affected by how and what choices are presented [@kim2025c].
For future research examining generative AI models' biases in relative decision-making, we recommend both empricial expriments and AI-driven simulations.

Future research could refine how popularity biases are measured.
For example, popularity bias may be non-linear where destinations with popularity under certain threshold receive no recommendations at all.
Fianally, we recommend applying our model to other types of biases and algorithms.
As tourism and hospitality firms are adopting generative AI for consumer and employee-facing applications, examining socio-demographic biases would be crucial for ensuring ethical and fair integration of generative AI.

# Data availability

The data and code for reproducing the results are available at [https://github.com/jinvim/genai-tourism-bias](https://github.com/jinvim/genai-tourism-bias).


::: {#refs}
:::

{{< pagebreak >}}

{{< include appendix.qmd >}}