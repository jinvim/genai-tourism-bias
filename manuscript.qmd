```{r} 
#| label: setup
#| include: false
library(tidyverse)
library(arrow)
library(sf)
library(colorspace)
library(gt)
library(gtsummary)
library(ggtext)
library(glue)
library(patchwork)
library(broom)
```

```{r} 
#| label: load-functions
# load custom functions and theme
source("r/helpers.r")
source("r/theme.r")
theme_set(theme_myriad())

color.rand <- "#777777"
color.nhts <- "#af9da6"
color.advan <- "#c4b4a1"
color.gemini <- "#214e7b"
color.gpt <- "#ff7f05"
```

```{r} 
#| label: read-data
#| include: false
source("r/data.r")
```

# Highlights

- Quantifies generative AI’s potential impact on US domestic tourist flows
- Proposes a Baseline-Rescaling-Outcome Model for testing algorithmic biases in tourism
- Large language models produce more seasonal and less diverse tourist flows
- The models exhibit a popularity bias that favors popular destination-month pairs
- Calls for assessing generative AI biases and their consequences in tourism

# Introduction

Generative AI has moved quickly from novelty to everyday tool.
Pepole use these algorithms as always-ready collaborators that can assist in making mundane choices to critical business decisions [@marr2023]
Tourism is no exception.
With most travelers already using generative AI to plan their trips, major travel intermediaries like Expedia and TripAdvisor are integrating generative AI into their platforms [@booking.com2025; @tripadvisor2023;@expedia2023].
Beyond travel planning, generative AI is also supporting core operations of tourism industry and destination management, such as marketing, human resource management, and tourism experience design [@amadeus2024; @dogru2025].

Despite widespread adoption of generative AI in tourism, empirical evidence on its impacts are scarce [@hsu2024; @gossling2025; @mellors2025]. 
Ethical and cultural biases in these algorithms are key concerns [@ali2025; @law2025].
As more tourists and practitioners rely on generative AI, algorithmic biases can lead to behavioral shifts that reproduce or amplify biases in our society [@kordzadeh2022; @vicente2023].
Revealing these biases is difficult sinece we have limited access to generative AI models' internals or their training data [@bai2025; @gallegos2024]. 
Even if we had such access, the complexity and black-box nature of generative AI models make it difficult to interpret the process behind generated outputs.
This knowledge gap leaves tourism destinations and businesses uncertain about how to prepare for generative AI’s potential impacts, or to determine whether such preparation is even necessary.

This empirical study assess how the rapid adoption of generative AI and its algorithmic biases can reshape tourist destination choices.
We develop the *Baseline-Rescaling-Outcome Model* that can test algorithmic biases using empirical expectations, algorithmic outcomes, and hypothesized bias mechanisms.
Using demographic profiles from the US Census Bureau, we created a simulated sample of one million US residents.
Two large language models, Gemini 2.5 Flash Lite and GPT-4.1 Nano, acted as travel agents who recommend one domestic travel destination for each individual.
We show that large language models generate travel patterns that deviate from empirical US domestic tourism.
These deviations are explained as systematic *biases* in generative AI, particularly biases that favor popular options and pairs of options.

Compared to empirical tourism patterns, large language models yield less diverse tourist flows that are more concentrated on specific combinations of destination, origin, and month.
They also produced more unevenly distributed tourist flows where destinations have more seasonal and less diversified tourism demand.
The models showed a strong tendency to favor visiting destinations during their peak seasons, indicating amplification of destination-month popularity.
However, tested models differed in popularity biases toward popular destinations, months, and origin-destination pairs.
The findings serve as early empirical evidence that generative AI poses significant potential to undermine the sustainability and resilience of the tourism sector.
Given these risks, we urge tourism scholars and practitioners to assess and prepare for generative AI's impact on the tourism system.

# Background

## Generative AI and its impacts on tourism

This study focuses on generative AI and its implications for tourism.
AI has become a catch-all term that encompasses various technologies aimed at simulating human intelligence. 
Adding to the confusion, tourism literature often discusses AI alongside other technologies like robotics, augmented reality, and virtual reality [@gossling2025].
Generative AI specifically refers to a class of AI mdoels that are trained to recognize patterns in vast data and generate content such as text, images, or videos [see @epstein2023].
We avoid *chatbots* because they represent just one application of generative AI.
Likewise, we do not use brand-specific terms like *ChatGPT* when discussing generative AI in general.

We currently lack empiricial evidence on how and to what extent generative AI will affect tourism [@hsu2024; @mellors2025].
Although tourism and hospitality literature on generative AI is growing, their primary focus is on adoption behaviors: who, when, and why tourists and practitioners adopt generative AI [see recent reviews by @gossling2025; @li2025].
Some preliminary works underscore benefits that generative AI brings to businesses and tourists.
Businesses who announced generative AI integration saw competitive advantages in market value [@jung2026].
Additionally, counterfactual analysis shows that underperforming businesses can improve their revenue by using generative AI for product marketing [@fan2025].
For tourists, generative AI reduces cognitive load during travel planning, thereby increasing visit intentions and decision satisfaction [@shin2025].
However, others also caution that generative AI could undermine ethical, sustainable, and resilient tourism [@law2025; @lehto2025].
A few studies investigate how generative AI have biases that favor mainstream tourism patterns [@andreev2025; @mellors2025].
Such biases are concerning because they can affect behaviors of users relying on generative AI, leading to real-world impacts that reproduce or amplify existing biases in society [@kordzadeh2022; @vicente2023].
These preliminary findings echo standing debates about how technologies---from search engines to social media---have both benefited and harmed tourism [@gong2024a; @leung2013; @pan2021].

## Challenges of defining and measuring biases in generative AI

Both conceptual and empirical works on generative AI in tourism commonly raise concerns about *biases* in these algorithms.
In particular, social biases in AI and their ethical implications are prominent focus of tourism and hospitality research.
This trend aligns with broader literature on algorithmic biases that emphasize ethical challenges of such biases, specifically racial and stereotypes [see @ghosh2025; @kordzadeh2022].
For example, @law2025 highlight ethical challenges of AI adoption in tourism and hospitality sectors, urging inclusiveness of AI adoption with reduced "biased and discriminatory actions" (p.287).
@hsu2024 suggests fine-tuning generative AI with tourism-specific data, noting that such models "could perpetuate stereotypes and result in discrimination" (p.2).
@viglia2024a discuss using AI-generated data for tourism research, giving a specific example of bias against AI generating racist content.
Beyond ethical concerns, several schloars mention popularity biases in generative AI as a potential threat, where algorithms favor popular options while underrepresenting less popular ones [@law2024; @lehto2025].
This bias poses practical concerns for the tourim sector, as it can exacerbate challenges like over-tourism for popular destinations, while less popular destinations struggle to sustain their tourism sector [@mellors2025].

We note two key challenges in examining biases in generative AI: defining and measuring biases.
First, works on AI biases in tourism and hospitality are often vague about what is meant by these algorithms being *biased*.
This issue is not unique to tourism scholarship; broader AI bias literature have also been criticized for lacking explicit definition of bias [@ghosh2025].
Even in AI policy documents, like EU AI Act that mandates AI providers to assess and mitigate biases, what constitutes bias is often unspecified [@vanbekkum2025].
Such ambiguity in defining bias results in discrepancies between the concerns raised and the empirical evidence provided [@blodgett2020].

Algorithmic bias has no single definition.
When the focus is on stereotyping, studies define bias as *act of* unjustified association between social groups and attributes [for example @bai2025].
This definition follows social psychology literature on implicit asssociations [@greenwald1998].
Studies examining ethical implications of algorithmic biases often define bias in terms of *outcomes or treatment*: unequal allocation of resources or unfavorable representation of social groups [for example @blodgett2020; @gallegos2024; @kordzadeh2022].
Such definitions are analogous to how laws require proof of disparate impacts or treatement as the behavioral outcome of biases, because bias is seen as individual beliefs that are unactionable [@seiner2006] 
Others distinguish bias from harm, where bias is defined as a model having a particular inclination or deviation of model outputs from empirical data [for example @ghosh2025; @wu2024a].
This is more netural definition of bias that are closely tied to statistical and computer science, where bias is considered unavoidable for generalization [@chen2023d; @ghosh2025].
Thus, definition of algorithmic bias varies not only across disciplines but also by specific bias being examined.

Even with clear definitions, measuring biases in generative AI is challenging.
A major obstacle is that these models are often proprietary and closed-source.
@ali2025 proposes using tools such as IBM's AI Fairness 360 or Google’s What-If toolkits to assess biases in AI generated data for tourism research.
However, these tools assume access to data and model internals, neither of which is available for commonly used generative AI models like ChatGPT [@gallegos2024].
Detecting biases is further complicated because recent generative AI models undergo safety tunings to avoid explicit biases, making biases implicit and harder to detect [@bai2025; @santurkar2023].
Moreover, most existing AI bias metrics are designed to quantify disparate outcomes, not to explain how such disparities arise [see review of bias metrics by @gallegos2024; @kordzadeh2022].
For example, existing metrics can identify that generative AI disproportionately suggest resort destinations to certain racial groups.
But they cannot explain whether such disparities arise due to favoring popular destinations, peak seasons, racial stereotypes, or a combination of these mechanisms.
These definitional and measurement challenges collectively limit our ability to effectively assess biases in generative AI models and their implications for tourism.

# Baseline-Rescaling-Outcome Model for testing algorithmic biases in tourism

We define biase as a *systematic deviation of algorithmic outputs from empirically grounded expectations of phenomena*.
Our definition separate bias from harm since what is considered harmful depends on who is affected [@blodgett2020; @ghosh2025]
For example, if an algorithm systematically favors one destination over another, such bias is benefical to the favored but harmful to the rest.
Even within the favored destination, the tourism sector may benefit while locals suffer from over-tourism.
We therefore separate the detection of biases from the assessment of their consequences.

To test for such biases, we propose the Baseline-Rescaling-Outcome model designed to address the challenges of measuring biases in proprietary and closed-source algorithms.
Our model tests bias by modeling the divergence between algorithmic *outcome* and empirical *baseline* as a function of *rescaling* factors representing hypothesized bias mechanisms (@fig-model).
This approach has three advantages compared to existing tests for algorithmic biases.
First, the model can test biases without access to model internals or training data.
We apply the same approach used in social sciences to study human biases that infer presence of biases from behavioral outcomes, such as speed of responses and error rates [@greenwald1998]
Similar to how biases in cognitive processes are treated unboservable, the model assumes that  the algorithm and its modeling process are inaccessible.
Instead, algorithm's output is used as the means to assess biases.
Our approach is also flexible.
As long as we can derive empirically grounded expectations, rescaling factors, and algorithmic outputs, we can test biases in algorithms beyond generative AI and outside of tourism context.
Finally, the rescaling factors allows interpretable diagnosis of biases, ideal for translating findings into practical suggestions for mitigating biases.
Although, the model cannot provide *causal* explanations of how biases arise in algorithms.
Biases in algorithms are caused by complex socio-technical processes that includes biases in data generating processes, model architectures, and human feedback [@santurkar2023; @viglia2024a].
Because we often lack access to these processes and due to uninterpretable nature of some algorithms, we can only speculate on what causes biases [@bai2025].

![Baseline-Rescaling-Outcome Model](figures/model.svg){#fig-model}

## Outcome: Projected tourism patterns under complete reliance on the algorithm

The first component of our model is the *outcome* when the phenomena are entirely driven by the algorithm.
We follow the logic of scenario-based projection models to test algorithmic biases.
Examples of such projections models include Shared Socioeconomic Pathways for climate trajectories and COVID-19 diffusion models [@adam2020; @ipcc2021].
These models contain “worst-case” scenarios that project the most extreme outcomes: climate projections without emission reductions or infection rates without government interventions.
For example, we can test bias in generative AI tourism recommendatinos by projecting the outcome when generative AI makes all destination choices.
Similarly, biases in hiring algorithms for tourism firms can be tested by projecting a scenario where all hiring decisions are made by the algorithm.
Though unrealistic, these undilluted outcome of algorithms are necessary to reveal the full extent of their biases.

## Baseline: Empirically grounded expectations of phenomena

Empirical baseline is a foundational component of our model.
Prior works have used similiar empirically-grounded approaches, comparing real-world distributions with algorithmic outputs to assess representation and popularity biases [@abdollahpouri2020; @santurkar2023].
Consider a situation where an algorithm has a four-in-ten chance of suggesting US domestic tourists to visit San Francisco.
Could we say that this algorithm has a systematic tendency to favor San Francisco as a tourism destination?
If four in ten Americans visit San Francisco, then the algorithm's tendency is simply reproducing what is expected in the real-world tourism patterns.
However, if only one in ten US domestic tourists visit San Francisco, then the algorithm does favor San Francisco beyond the empirical expectation.
We argue that to answer this question, one first need an empirical benchmark of what would "unbiased" suggestions look like.



## Rescaling: Testable factors for hypothesized bias mechanisms

Rescaling is the final component of the model that tests specific mechanisms that produce biases.
We do so by reproducing the algorithm outcome using the baseline and a set of rescaling factors.
Under the null condition of no bias, the algorothm should reproduce the baseline hence the rescaling factors are unnecessary.
If the algorithm deviates from the baseline, we can test whether such deviation is systematic by explaining the divergence using hypothesized mechanisms.
This approach yields interpretable tests of specific bias in algorithms, going beyond simply measuring the degree of divergence between baseline and algorithm output.
The direction of bias is another important aspect that our model can capture.
Since we adopted a neutral definition of bias, it is possible for an algorithm to exhibit bises that reduce empricially-observed asymmetries [@ghosh2025].
For example, algorithms could be designed to favor less popular destinations and off-peak seasons, diversifying the tourism demand across destinations and time.
Our model can test for such biases as negative rescaling factors, allowing us to explain algorithm outputs as mixtures of amplification and attenuation of empirical patterns.

# Study design

## Empirical framework for testing popularity biases in generative AI travel suggestions

We demonstrate the application of our Baseline-Rescaling-Outcome Model by testing for popularity biases in generative AI travel recommendations.
Popularity bias is defined as tendency where popular options "are recommended even more frequently than their popularity would warrant" [@abdollahpouri2020, p.1].
Understanding this bias in tourism is particularly timely and practical, as major online travel agencies are already integrating generative AI into their platforms.
However, popularity bias is not unique to algorithms---Humans also exhibit similar behaviors, such as popular people gaining even more friends over time and tourists flocking to popular destinations [@barabasi1999; @lee2025a].
Our study therefore tests whether generative AI amplifies or attenuates such popularity biases beyond what is observed empirically.

We also argue that examining pouplarity in tourism context is of theoretical significance, even though pouplarity bias is commonly observed in other recommendation algorithms [@chen2023d].
Unlike recommending movies or music, tourism recommendations need to consider spatial and temporal dimmensions of travel choices.
Decision to travel is not only about *whether* to travel, but also *from where*, *to where*, and *when*.
Thus, we further extend popuarity bias into four types that are tourism-specific: destination popularity, month popularity, destination-month popularity, and origin-destination popularity biases.
The first two measure whether popular destinations and peak months are favored by generative AI than what is expected empirically.
While these two factors account for destination and month popularities independently, bias may also exist in specific combinations of destinations and months.
Destination-month popularity bias caputure whether algorithms favor specific destinations during specific months.
Similarly, origin-destination popularity bias capture tendency to excessively pair tourists from specific origins to specific destinations.

Below is the empirical model for testing four popularity biases.
Define number of tourist flow from origin $i$ to destination $j$ in month $m$ as $Flow_{(i,j,m)}$.
Let $P_{(i,j,m)}$ be the share of tourists from origin $i$ to destination $j$ in month $m$ over all tourist flow ($Flow_{(i,j,m)} / \sum{Flow_{(i,j,m)}}$).
Under the null condition that large language models produce "unbiased" travel suggestions, we expect:
$$
Flow^{LLM}_{(i,j,m)} \sim \sum_{j,m}{Flow^{LLM}_{(i,j,m)}} \cdot P^{Empirical}_{(j,m|i)} = Baseline_{(i,j,m)}
$$ {#eq-null}
where $P^{Empirical}_{(j,m|i)}$ is the share of tourists traveling to destination $j$ in month $m$ given origin $i$, observed empirically ($P_{(i,j,m)} / \sum_{j,m}{P_{(i,j,m)}}$).
This share is multiplied by total number of large language model-produced tourists from origin $i$, which scales the expected number of tourists based on total tourist outflow from origin $i$.
Meaning, the right hand side of @eq-null is the baseline expectation when generative AI can perfectly replicate empirical tourism patterns ($Baseline_{(i,j,m)}$).

Destination and month popularities are defined as:
$$
\begin{aligned}
D_{j} &= \sum_{i,m}{P^{Empirical}_{(i,j,m)}} \\
M_{m} &= \sum_{i,j}{P^{Empirical}_{(i,j,m)}}
\end{aligned}
$$ {#eq-d-m}
where $D_{j}$ is the popularity of destination $j$ across all origins and months, and $M_{m}$ is the popularity of month $m$ across all origins and destinations.

We account for the popularity of specific destination-month pairs as a joint probability of choosing destination $j$ in month $m$ beyond what can be expected from their independent popularities:
$$
DM_{j,m} = \frac{\sum_{i}{P^{Empirical}_{(i,j,m)}}}{D_{j} \cdot M_{m}}
$$ {#eq-dm}
The denominator in @eq-dm is the expected popularity of the destination-month pair if destination and month popularities were independent.
If $DM_{j,m} > 1$, destination-month pair $(j,m)$ is more popular than expected under independence, while $DM_{j,m} < 1$ indicates the pair is less popular than expected.
Similarly, we account for the popularity of specific origin-destination pairs:
$$
OD_{i,j} = \frac{\sum_{m}{P^{Empirical}_{(i,j,m)}}}{O_{i} \cdot D_{j}}
$$ {#eq-od}
where $O_{i} = \sum_{j,m}{P^{Empirical}_{(i,j,m)}}$.
Same as @eq-dm, $OD_{i,j}$ measures how popular the origin-destination pair $(i,j)$ is compared to what would be expected if origin and destination popularities were independent.

We test the four popularity rescaling factors using the following multiplicative model:
$$
\frac{Flow_{(i,j,m)}^{LLM}}{Baseline_{(i,j,m)}} = 
(D_{j})^{\beta_1} \cdot 
(M_{m})^{\beta_2} \cdot 
(DM_{j,m})^{\beta_3} \cdot 
(OD_{i,j})^{\beta_4}
$$ {#eq-model}
Under the null hypotheses of no systematic bias, we expect all $\beta=0$. If $\beta>0$ for a factor, it positively rescales that factor's popularity in their suggestions; if $\beta<0$, it negatively rescales that factor's popularity.

@fig-beta-demo illustrate how different $\beta_2$ values (month popularity bias) rescales the distribution of monthly tourist share.
For example, if $\beta_2 = 1$, seasonal variation in tourist flow is amplified, whereas $\beta_2 = -1$ produces a uniform distribution across months.
This test is independet of destination-month popularity bias ($\beta_3 \ne 0$) because $DM_{j,m}$ measure popularities beyond independent popularities of destination and month.
Meaning, if we generate tourist flows with only the destination-month popularity bias ($\beta_3 \ne 0$), the resulting data would show no changes in overall destination or month popularity ($\beta_1 = 0, \beta_2 = 0$).

```{r} 
#| label: fig-beta-demo
#| fig-cap: Example of how different $\beta_2$ values affect distribution of monthly tourist share
#| fig-height: 5
df.beta.demo |> 
    mutate(
        case = factor(
            case,
            levels = c(
                "p.neg2",
                "p.neg1",
                "p",
                "p.pos1",
                "p.pos2"
            ),
            labels = c(
                "beta[2]==-2",
                "beta[2]==-1",
                "beta[2]==0",
                "beta[2]==1",
                "beta[2]==2"
            ),
            ordered = TRUE
        ),
    ) |>
    ggplot(aes(x = month, y = p)) +
    geom_bar(stat = "identity", fill = color.gemini) +
    scale_x_discrete(breaks = c("Jan", "Dec")) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    coord_cartesian(clip = "off") +
    facet_wrap( ~ case, ncol = 5, labeller = label_parsed) +
    theme(
        panel.spacing = unit(1.0, "lines"),
        panel.grid.major.x = element_blank(),
        plot.margin = margin(t = 10, r = 30, b =10, l = 10)
    ) +
    labs(
        title = "Positive β Amplifies Popularity, Negative β Suppresses and Inverts Popularity",
        x = "Month",
        y = "Share of total tourist flow",
    )
```

By taking the log of @eq-model, we can fit a regression model that tests the four popularity biases:
$$
\begin{aligned}
\ln Flow_{(i,j,m)}^{LLM} & = \ln Baseline_{(i,j,m)} \\
& + \beta_1 \cdot \ln D_{j} + \beta_2 \cdot \ln M_{m} + \beta_3 \cdot \ln DM_{j,m} + \beta_4 \cdot \ln OD_{i,j}
\end{aligned}
$$ {#eq-log-model}

## Data collection and analysis

@fig-steps summarizes our data collection and analysis process.
The large language model simulation involves generating tourist flow using empirically grounded demographic profiles.
Separately from the AI-driven simulation, two data sources were used to estimate real-world tourism patterns.
This empirical data is then used to derive baseline expectations and popularity factors.
Finally, we combine simulation and empirical data to test four hypothesized popularity biases by fitting the regression model in @eq-log-model.

![Overview of the simulation and analysis process](figures/steps.svg){#fig-steps}

### Definition of population and simulated samples

The population of our simulations is US residents aged 18 and over. 
The US domestic tourism market is one of the largest in the world [@unwto], offering geographically and socioeconomically diverse destinations.
Hence, the US context provides sufficient variability for large-scale simulations, while excluding complications of international tourism like visa requirements.
Most generative AI models also perform better on English tasks [@qin2025], making the US context advantageous for these models.

We used 2019-2023 American Community Survey 5-Year Public Use Microdata Sample data to derive stratum weights for the population.
@tbl-demo summarizes sex, age, and household income proportions of the population.
From this population, we took a random sample of 1,000 individuals stratified by state, sex, age, and income.
This sampling procedure was repeated 1,000 times, yielding one million simulated individuals with demographic characteristics that mirror the population.
By using empirically derived profiles, we ensure that the demographic distribution of simulated travelers resembles that of US domestic tourists.
This approach also fixes the number of outgoing tourists from each state, allowing us to control for origin-specific propensity to travel.
One limitation is that generative AI models may also influence the decision to travel itself, which we do not account for here.

```{r} 
#| label: tbl-demo
#| tbl-cap: Age, sex, and household income proportions of the population
df.demo.prop |>
    mutate(category = indent_row(category)) |>
    gt(groupname_col = "strat") |>
    fmt_number(
        columns = p,
        decimals = 3
    ) |>
    cols_label(
        category = "",
        p = "Proportion"
    ) |>
    cols_align(
        align = "left",
        columns = category
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_style(
        style = cell_text(whitespace = "nowrap"),
        locations = cells_body(columns = category)
    ) |>
    tab_footnote(
        "Note: Based on 2019-2023 American Community Survey 5-Year Public Use Microdata Sample."
    )
```

### Large language model simulations

Social science researchers are increasingly using generative AI models for generating synthetic data.
We highlight four key differences between our approach and prior studies.
First, we use AI-generated data because they provide means to show how these AI models *do not* replicate human behavior.
Our focus is thus fundamentally different from previous suggestions to use AI-generated data to *mimic* tourist behavior [for example @ali2025; @viglia2024a; @xiong2024].
Next, we base our simulations on empirically derived demographic profiles.
This modification is to ensure that any divergence from empirical tourism patterns is attributable to algorithmic biases, instead of using arbitrary or non-representative profiles that would confound the results [for example, @andreev2025].
Third, unlike studies that relied on a few handpicked responses or a single simulation run [for example @mellors2025; @xiong2024], we ran multiple iterations of simulations to sufficiently capture the uncertainty in large language model outputs.
Finally, our approach recognizes the network and temporal nature of tourism.
Beyong looking at destination choice alone, we simulate the complete network of tourist flows between all origin-destination pairs across months.

The simulation starts with a system prompt containing the simulation context, response structure, and examples (available in @apx-prompt).
To simplify the simulation, we assume that each person chooses one domestic destination within the US (50 US states and the District of Columbia).
We instructed large language models to act as travel agents recommending one domestic travel destination based on the provided demographic profile.
Subsequently, the models received demographic characteristics of each simulated individual.
Twenty people were processed at a time to improve the efficiency of the simulation. 
This process is similar to agent-based modeling using large language models [@gao2024].
But the key difference is that we prompt large language models to act as travel agents, rather than as tourists.
The rationale for this choice is that our goal is to project how generative AI would influence tourist flows if widely adopted, rather than using it to substitute for human travelers.
We captured the probablistic nature of large language model outputs by repeting simulation with 1,000 individuals for 1,000 iterations.
This process produces a distribution of simulated tourist visits for assessing whether the differences between AI-simulated and empirical tourism patterns are not result of stochastic variations.

Two different large language models were used to establish the consistency of our findings across different models: Google's Gemini 2.5 Flash Lite (version June 2025) and OpenAI's GPT-4.1 Nano (version April 2025).
They are among the leading large language models currently available in terms of their capabilities and market share.
Because our simulations require a large number of responses, we chose their smallest variants optimized for speed and cost.
Although the two large language models are closed-source, they are comparable in pricing structures ($0.10 per million input tokens; $0.30 and $0.40 per million output tokens, respectively).
We also chose these two models also because they use different architectures.
Gemini 2.5 family of models are build on mixture-of-experts architecture, while GPT-4.1 family are built on more traditional transformer architecture.
As these two models are developed by different companies, they are likely be trained on different datasets and tuning processes, which is ideal for assessing the generalizability of our findings.

All requests were made from the IP address of the university located in the southeastern US, using custom automation scripts.
We explicitly instructed large language models not to use IP-specific details when generating recommendations.
Data collection continued until we achieved a complete dataset.
The collected data were then aggregated to create destination-origin-month matrices for each iteration and model, where each cell represents the number of tourists from the origin. $i$ to destination $j$ in a month $m$.

### Empirical baseline data and simulations

The empirical data serve two purposes in this study.
It provides the baseline for descriptively comparing characteristics of AI-simulated tourist flows against real-world tourism patterns.
Additionally, we use the empirically derived baseline and popularity factors to explain the discrepancies between AI-simulated and empirical tourist flows.
Because biases also exist in the empirical mobility data [see @huang2021a; @li2024b], we rely on two different data sources to ensure the robustness of our findings.
Our primary data source is the @advan Mobility Data, which estimates movements between US census block groups based on mobile device panels.
This dataset is our primary data source due to its high spatial and temporal resolution.
The supplementary data source is the Department of Transportation's 2022 National Household Travel Survey (NHTS).
National Household Travel Survey is the only official national travel survey in the US, which collects travel behavior data such as trip purpose, modes, and distances [@nhts2022].

For both datasets, we used monthly data from January through December 2022 (the latest available for National Household Travel Survey). 
Following pre-processing steps were employed to filter out non-tourism mobility flows.
We first excluded visits to home and work locations, and movements within the county of residence [@lee2025c].
Additionally, trips under 50 miles one-way and trips within National Household Travel Survey designated commuting zones were considered non-tourism. 
This offers more conservative estimates of tourist visits by filtering out short-distance and commuting trips that are less likely to be tourism-related.
These estimates were then used to compute the empirical shares and the four popularity factors in the @eq-model.

Since we employed an iterative approach for the large language model simulations, direct comparison with empirical data is inappropriate.
Therefore, we also conducted empirical-based simulations for descriptive comparison between AI-simulated and empirical tourist flows.
Using empirical estimates as weights, we simulated tourist flows by randomly assigning destinations and months to each individual in the simulated sample.
Due to data anonymization, demographic factors could not be incorporated in the empirical-based simulations.
Therefore, we assume that the probability of traveling to another state in a given month is equal for all individuals in a given origin state. 
For instance, if 10% of Illinois residents visited Florida in January 2024, all Illinois residents were given a 0.1 probability to travel to Florida in January (irrespective of other demographic factors).
Same as the large language model simulations, the empirical-based simulation was repeated 1,000 times.
Subsequently, the results were aggregated to create destination-origin-month matrices for each iteration and two data sources.

## Hypotheses testing

The last step of the analysis is to combine simulation and empirical data to test hypothesized popularity biases.
We achieve this goal by fitting @eq-log-model using the Poisson count model. 
Essentially, the model explains variations in large language model-simulated tourist flows ($Flow_{(i,j,m)}^{LLM}$) beyond what can be expected by empirical data ($Baseline_{(i,j,m)}$), using the four popularity factors as predictors.
We chose the Poisson pseudo-maximum likelihood estimatior, which is widely used in estimating gravity models of trade and migration.
The Poisson pseudo-maximum likelihood estimator only requires the conditional mean to be correctly specified, without requiring a specific distributional assumption.
This estimator is robust to heteroskedasticity and having many zeros in the dependent variable, making the estimator suitable for our analysis [@silva2006; @silva2011].
Because we ran 1,000 iterations of simulations, we fit the model for each iteration then collect the result across iterations to assess the uncertainty in the effect estimates.

# Results

## Descriptive analysis

```{r}
#| label: intext-desc
max.advan <- round(df.sum |> filter(data.name == "Simulation: ADVAN Mobility Data", variable == "Tourist flow") |> pull(max))
max.nhts <- round(df.sum |> filter(data.name == "Simulation: National Household Travel Survey", variable == "Tourist flow") |> pull(max))
max.gemini <- round(df.sum |> filter(data.name == "Simulation: Gemini 2.5 Flash Lite", variable == "Tourist flow") |> pull(max))
max.gpt <- round(df.sum |> filter(data.name == "Simulation: GPT-4.1 Nano", variable == "Tourist flow") |> pull(max))
```

```{r}
#| label: tbl-desc
#| tbl-cap: Descriptive statistics of simulation and empirical data
df.sum |>
    mutate(
        variable = indent_row(variable)
    ) |>
    gt(groupname_col = "data.name") |>
    sub_small_vals(threshold = 0.001) |>
    fmt_number(decimals = 3) |>
    fmt_markdown(columns = notation, rows = TRUE) |>
    cols_align(
        align = "left",
        columns = variable
    ) |>
    cols_label(
        notation = "Notation",
        variable = "Variable",
        min = "Min",
        max = "Max",
        median = "Median",
        mean = "Mean",
        sd = "SD"
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote(
        md("Note: For *simulation* data, statistics are calculated over 1,000 iterations (N=31,212,000). Statistics for *empirical* data are based on a single destination-origin-month matrix (N=31,212).")
    )
```

```{r} 
#| label: tbl-any
#| tbl-cap: Agreement in precence of any tourist flow between large language model simulations and empirical-based simulations
t.any.gemini.advan <- df.any |>
    tbl_cross(
        row = gemini,
        col = advan,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")
 
t.any.gemini.nhts <- df.any |>
    tbl_cross(
        row = gemini,
        col = nhts,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gpt.advan <- df.any |>
    tbl_cross(
        row = gpt,
        col = advan,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gpt.nhts <- df.any |>
    tbl_cross(
        row = gpt,
        col = nhts,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gemini <- tbl_merge(
    list(t.any.gemini.advan, t.any.gemini.nhts ),
    tab_spanner = c(
        "*Simulation: ADVAN*",
        "*Simulation: NHTS*"
    )
) 
t.any.gpt <- tbl_merge(list(t.any.gpt.advan, t.any.gpt.nhts )) 

tbl_stack(
    list( t.any.gemini, t.any.gpt),
    group_header = c("Simulation: Gemini 2.5 Flash Lite", "Simulation: GPT-4.1 Nano"),
    ) |> 
    as_gt() |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote("Note: ADVAN=ADVAN Mobility Data, NHTS=National Household Travel Survey. Counts and percentages of destination-origin-month cells with no tourist flow in either simulations, any flow in either of simulations, and any flow in both simulations. Percentages are calculated based on number of possible destination-origin-month combinations (N=31,212). Based on simulated visits aggregated across all 1,000 iterations.")
```

```{r}
#| label: intext-any-prop
intext.any <- df.any |>
    mutate(
        only.gemini.advan = (gemini == "Any flow" & advan == "No flow"),
        only.gemini.nhts = (gemini == "Any flow" & nhts == "No flow"),
        only.gpt.advan = (gpt == "Any flow" & advan == "No flow"),
        only.gpt.nhts = (gpt == "Any flow" & nhts == "No flow"),
        only.advan.gemini = (advan == "Any flow" & gemini == "No flow"),
        only.nhts.gemini = (nhts == "Any flow" & gemini == "No flow"),
        only.advan.gpt = (advan == "Any flow" & gpt == "No flow"),
        only.nhts.gpt = (nhts == "Any flow" & gpt == "No flow")
    ) |>
    summarize(across(
        starts_with("only."),
        sum 
    )) / 31212
intext.any <- lapply(intext.any * 100, sprintf, fmt = "%.1f%%")
```


@tbl-desc presents descriptive statistics of simulation and empirical data.
The origin total outflow are closely matched across all simulations, as our simulated sample is stratified to reflect the population distribution across origins states.
The median tourist flow per destination-origin-month cell is 0 for all simulations, indicating that more than half of the cells have no tourist flow.
This sparsity is expected, given that each iteration assigns 1,000 tourists across 31,212 possible combinations (51 origins × 51 destinations × 12 months).
Thus, even if we randomly assign each of simulated tourists, only about 3.2% of destination-origin-month cells would have at least one tourist flow.
But the head of the distribution differs across simulations.
Large language model simulations show higher concentration of tourist flows in the most popular destination-origin-month combination.
The maximum tourist flow across all cells and iterations is `{r} max.gemini` for Gemini 2.5 Flash Lite and `{r} max.gpt` for GPT-4.1 Nano, which are high compared to two empirical-based simulations (`{r} max.advan` for ADVAN Mobility Data and `{r} max.nhts` for National Household Travel Survey).

Similar patterns emerge when examining presence of *any* tourist flow, without accounting for differences in number of tourists.
@tbl-any compares which destination-origin-month combinations receive any tourist visits in large language model simulations versus empirical patterns. 
We aggregated the simulated visits across all 1,000 iterations to reduce the sparsity.
In all four comparisons, large language models exclude specific destination-origin-month combinations even though they are present in empirical-based simulations.
About `{r} intext.any$only.nhts.gpt` to `{r} intext.any$only.advan.gemini` of combinations never appeared in the large language model simulations, even though they were observed in the empirical data.
In contrast, large language models rarely suggest destination-origin-month combinations that are absent in empirical-based simulations. 
For example, `{r} intext.any$only.advan.gemini` of 31,212 combinations are observable in simulation based on ADVAN Mobility Data but not in flows generated by Gemini 2.5 Flash Lite.
Meaning, large language models prune many empirically observed destination-origin-month combinations but rarely generate new ones.

```{r}
#| label: intext-dst
dst.gini.advan <- df.dst |> filter(data.name == "advan") |> pull(median.gini) |> first() |> pval_format()
dst.gini.nhts <- df.dst |> filter(data.name == "nhts") |> pull(median.gini) |> first() |> pval_format()
dst.gini.gemini <- df.dst |> filter(data.name == "gemini") |> pull(median.gini) |> first() |> pval_format()
dst.gini.gpt <- df.dst |> filter(data.name == "gpt") |> pull(median.gini) |> first() |> pval_format()
```

```{r}
#| label: plot-dst
#| include: false
bbox <- st_bbox(sf.states)
data_labeller <- as_labeller(
            c(
                "advan" = "ADVAN Mobility Data",
                "nhts" = "National Household Travel Survey",
                "gemini" = "Gemini 2.5 Flash Lite",
                "gpt" = "GPT-4.1 Nano"
            )
        )

df.dst.label <- df.dst |>
    group_by(data.name) |>
    summarize(median.gini = first(median.gini)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

p.dst <- df.dst |>
    ggplot() +
    geom_sf(
        aes(fill = median.sum.p, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Reds 2",
    ) +
    geom_sf_label(
        data = df.dst.label,
        aes(
            geometry = geometry,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Gini: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Are slightly more concentrated at popular destinations",
        fill = "Share of tourist flow (median over 1,000 iterations)",
        x = "",
        y = ""
    )
p.dst
```

```{r} 
#| label: intext-month-prop
month.gini.advan <- df.month |> filter(data.name == "advan") |> pull(median.gini) |> first() |> pval_format()
month.gini.nhts <- df.month |> filter(data.name == "nhts") |> pull(median.gini) |> first() |> pval_format()
month.gini.gemini <- df.month |> filter(data.name == "gemini") |> pull(median.gini) |> first() |> pval_format()
month.gini.gpt <- df.month |> filter(data.name == "gpt") |> pull(median.gini) |> first() |> pval_format()
```

```{r} 
#| label: plot-month
#| include: false
p.month <- df.month |>
    mutate(month = fct_rev(month)) |>
    ggplot() +
    geom_bar(
        aes(y = month, x = median.sum.p, fill = data.name),
        stat = "identity"
    ) +
    geom_label(
        data = df.month |>
            group_by(data.name) |>
            summarize(median.gini = first(median.gini)),
        aes(
            y = "Dec",
            x = 0.25,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Gini: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    # cheating my way to add y axis line for each facet
    geom_vline(xintercept = 0, lty = 1, color = "black") +
    scale_fill_manual(
        values = c(
            "advan" = color.advan,
            "nhts" = color.nhts,
            "gemini" = color.gemini,
            "gpt" = color.gpt
        )
    ) +
    scale_x_continuous(expand = expansion(mult = c(0.0, 0.1))) +
    scale_y_discrete(breaks = c("Jan", "Dec")) +
    coord_cartesian(clip = "off") +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    theme(
        axis.line.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.ticks.y = element_line(linewidth = 0.3),
        legend.position = "none"
    ) +
    labs(
        subtitle = "Are highly seasonal",
        x = "Share of tourist flow (median over 1,000 iterations)",
        y = "",
        fill = "Scenario"
    )
p.month 
```

```{r} 
#| label: plot-month-gini
#| include: false
df.gini.label <- df.month.gini |>
    group_by(data.name) |>
    summarize(median.gini = median(median.gini)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

# for in-text numbers
dst.month.gini.advan <- df.gini.label[1,2] |> pval_format()
dst.month.gini.nhts <- df.gini.label[2,2] |> pval_format()
dst.month.gini.gemini <- df.gini.label[3,2] |> pval_format()
dst.month.gini.gpt <- df.gini.label[4,2] |> pval_format()

p.month.gini <- df.month.gini |>
    ggplot() +
    geom_sf(
        aes(fill = median.gini, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Blues 2",
        rev = TRUE,
        limits = c(0, 1),
        breaks = seq(0, 1, by = 0.2)
    ) +
    geom_sf_label(
        data = df.gini.label,
        aes(
            geometry = geometry,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Median: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Destinations have higher seasonality in tourism demand",
        fill = "Gini coefficient (median over 1,000 iterations; higher values indicate greater inequality)",
        x = "",
        y = ""
    )
p.month.gini
```

```{r} 
#| label: plot-org-entropy
#| include: false
df.entropy.label <- df.org.entropy |>
    group_by(data.name) |>
    summarize(median.entropy = median(median.entropy)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

# for in-text numbers
dst.entropy.advan <- df.entropy.label[1,2] |> pval_format()
dst.entropy.nhts <- df.entropy.label[2,2] |> pval_format()
dst.entropy.gemini <- df.entropy.label[3,2] |> pval_format()
dst.entropy.gpt <- df.entropy.label[4,2] |> pval_format()

p.org.entropy <- df.org.entropy |>
    ggplot() +
    geom_sf(
        aes(fill = median.entropy, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Greens 2",
        limits = c(0.0, 3.0),
    ) +
    geom_sf_label(
        data = df.entropy.label,
        aes(
            geometry = geometry,
            label = median.entropy |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Median: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap( ~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Destinations have less diversified and balanced tourism demand",
        fill = "Entropy index (median over 1,000 iterations; higher values indicate more diversified and balanced demand)",
        x = "",
        y = ""
    )

p.org.entropy
```

```{r}
#| label: fig-prop
#| fig-cap: Characteristics of destination, month, destination-month, and origin-destination popularities across simulations
#| fig-width: 12
#| fig-height: 16 
(p.dst / p.month / p.month.gini / p.org.entropy) + 
    plot_annotation(
        title = "Large Language Models Produce More Unevenly Distributed Tourist Flows",
        subtitle = "Simulations using large language models tend to generate tourist flows that...",
        tag_levels = "a",
        tag_prefix = "(", tag_suffix = ")"
    ) & 
    theme(
        plot.tag = element_text(size = 20, face = "bold")
    )
```

We further examine differences in distribution of tourist flow across simulations by looking at the four popularity factors.
Since we ran 1,000 iterations of simulations, we summarize the findings by taking the median across all iterations.
Mathematical definitions of the metrics are available in @apx-eq.
First, we examine distribution of tourist share by destination states ($D_j$) and months ($M_m$).
We use the Gini index to quantify the inequality in these distributions, where a higher Gini index indicates greater concentration of tourist share among fewer states or months.
In all four simulations, tourist visits concentrate in a few popular states, such as California, Florida, and Texas (@fig-prop[a]()).
Large language model simulations show higher Gini indices than empirical-based simulations, indicating greater inequality in tourist arrivals across states (ADVAN Mobility Data=`r dst.gini.advan` and National Household Travel Survey=`r dst.gini.nhts`; Gemini 2.5 Flash Lite=`r dst.gini.gemini` and GPT-4.1 Nano=`r dst.gini.gpt`).

Seasonal patterns are also more pronounced in the large language model outputs than in the empirical-based simulations with substantially high Gini indices across months (@fig-prop[b]()).
This level of seasonality exceeds that of the two empirical-based simulations (Median = `r month.gini.gemini` and `r month.gini.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano; Median = `r month.gini.advan` and `r month.gini.nhts` for ADVAN Mobility Data and National Household Travel Survey).
Although, the two large language models differ in peak tourism months.
Gemini 2.5 Flash Lite shows a clear peak during September and October, with more than half of all simulated tourist arrivals concentrated in these two months.
GPT-4.1 Nano shows peaks in April, May, and September.
Large language models worsen the seasonality of tourism demand even at the destination level.
In @fig-prop[c](), we calculated Gini index of monthly tourist share for each destination state and took the median over 1,000 iterations.
Few states show relatively high seasonality in the empirical-based simulations, such as Alaska and Hawaii.
Contrarily, most states exhibit high seasonality in the large language model simulation, indicated by overall higher level Gini indices accross all destinations (Median of medians = `r dst.month.gini.advan` and `r dst.month.gini.nhts` for ADVAN Mobility Data and National Household Travel Survey; `r dst.month.gini.gemini` and `r dst.month.gini.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).

@fig-prop[d]() shows that large language models have tendency to generate travel suggestions that destinations rely on a few origins.
We use entropy index for measuring how diversified and balanced the demand for destinations is.
Although Gini index can be used, it does not effectively capture whether destination states receive tourists from a diverse set of origin states or rely on a few.
The empirical simulations show that states such as Florida, Illinois, and North Carolina tend to have diversified and balanced demand (higher entropy).
For the two AI-simulated tourist flows, the entropy indices are overall lower than those of empirical-based simulations (Median of medians = `r dst.entropy.advan` and `r dst.entropy.nhts` for ADVAN Mobility Data and National Household Travel Survey; `r dst.entropy.gemini` and `r dst.entropy.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).
We also observe that fewer states exhibit relatively high entropy values in the large language model simulations (for example, Colorado and Hawaii for Gemini 2.5 Flash Lite).
Such demand characteristics indicate that large language model simulations produce a less resilient tourism sector, as less diversity of tourist origins and higher reliance on a few origin markets undermines resilience to shocks [@lee2025c].

```{r} 
#| label: intext-graph-stats
df.graph.sum <- df.graph |>
    group_by(stat, data.name) |>
    summarize(
        median.value = median(value)
    )
# reciprocity
recip.advan <- df.graph.sum[1,3] |> pval_format()
recip.nhts <- df.graph.sum[2,3] |> pval_format()
recip.gemini <- df.graph.sum[3,3] |> pval_format()
recip.gpt <- df.graph.sum[4,3] |> pval_format()
# median travel distance
mdist.advan <- df.graph.sum[5,3] |> round()
mdist.nhts <- df.graph.sum[6,3] |> round()
mdist.gemini <- df.graph.sum[7,3] |> round()
mdist.gpt <- df.graph.sum[8,3] |> round()
# border ratio
br.advan <- df.graph.sum[9,3] |> pval_format()
br.nhts <- df.graph.sum[10,3] |> pval_format()
br.gemini <- df.graph.sum[11,3] |> pval_format()
br.gpt <- df.graph.sum[12,3] |> pval_format()
# self-loop ratio
sl.advan <- df.graph.sum[13,3] |> pval_format()
sl.nhts <- df.graph.sum[14,3] |> pval_format()
sl.gemini <- df.graph.sum[15,3] |> pval_format()
sl.gpt <- df.graph.sum[16,3] |> pval_format()
```

```{r} 
#| label: fig-graph-stats
#| fig-cap: Characteristics of tourist flow structure across simulations
#| fig-height: 10
df.graph |>
    mutate(
        data.name = fct_rev(data.name) 
    ) |>
    ggplot(aes(x = value, y = data.name, fill = data.name)) +
    geom_vline(
        data = df.graph.rand |>
            group_by(stat) |>
            summarize(value = median(value)),
        aes(xintercept = value),
        linetype = "dashed",
        linewidth = 0.7,
        color = "red",
    ) +
    geom_boxplot(
        alpha = 0.8,
        width = 0.6,
        linewidth = 0.3,
        outlier.shape=1,
    ) +
    scale_fill_manual(
        values = c(
            "ADVAN Mobility Data" = color.advan,
            "National Household Travel Survey" = color.nhts,
            "Gemini 2.5 Flash Lite" = color.gemini,
            "GPT-4.1 Nano" = color.gpt
        )
    ) +
    facet_wrap( ~ stat, ncol = 1, scales = "free_x", strip.position = "bottom") +
    expand_limits(x = 0) +
    theme(
        strip.text = element_text(face = "plain"),
        strip.placement = "outside",
        axis.ticks.y = element_line(linewidth = 0.3),
        axis.text.y = element_text(face = "italic"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5),
        panel.grid.major.y = element_blank(),
        panel.spacing = unit(2.0, "lines"),
        legend.position = "none",
        plot.margin = margin(t = 10, r = 60, b = 10, l = 10)
    ) +
    labs(
        title = "Generative AI Produce Structurally Different Tourist Flows",
        subtitle = "Large language model-generated tourist flows exhibit lower reciprocity and fewer trips to bordering states",
        caption = "Note. Dashed red line indicates what would be expected if destination-origin-month combinations are completely random (uniform probability).",
        x = "",
        y = "",
    )
```

Additionally, we analyze the overall structure of tourist flows.
We constructed an origin-destination matrix by aggregating tourist numbers at the year level.
Then we computed four statistics capturing how the global structure of tourist flows differ across simulations.
Box-plots in @fig-graph-stats present the distribution of the four network-level statistics across 1,000 iterations, colored by simulation scenario.
The dotted red line indicates what can be expected by chance alone, if there is no structure in tourist flow.
This expectation under complete randomness is calculated by assuming that each individual have equal probability of choosing a destination (a probability of $1/51$).

Large language models produce tourist flows with a clear separation between states that send tourists and those that receive them, as indicated by lower reciprocity of the origin-destination network.
Reciprocity refers to the tendency to form mutual relationships—in our case, two states exchanging a similar number of tourists.
Empirical-based simulations show higher levels of reciprocity compared to the random expectation (Median = `r recip.advan` and `r recip.nhts` for ADVAN Mobility Data and National Household Travel Survey).
However, large language model simulations show lower levels of reciprocity than expected by chance (Median = `r recip.gemini` and `r recip.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).

Gemini 2.5 Flash Lite and GPT-4.1 Nano tend to suggest farther destinations compared to empirical data, when looking at median travel distance excluding in-state trips (Median of medians = `r mdist.gemini` and `r mdist.gpt`).
This tendency is partially due to large language models' lower propensity to suggest trips to bordering states.
Gemini 2.5 Flash Lite has lower ratio of tourist flows between bordering states compared to the empirical models (Median = `r br.gemini`).
GPT-4.1 Nano shows even lower tendency to suggest bordering states, lower that what would be expected under randomness (Median = `r br.gpt`).
But the two models exhibit substantial difference in tendency to suggest in-state tourism.
Gemini 2.5 Flash Lite shows ratio of in-state trips comparable to the empirical models (Median = `r sl.gemini`).
In contrast, GPT-4.1 Nano shows much stronger preference for recommending tourist to travel within their own state (Median = `r sl.gpt`).

## Model estimation results

```{r} 
#| label: intext-betas
# d coeffs
b.d.gemini.advan <- betas.sum[1, 4] |> sprintf(fmt = "%4.3f")
b.d.gemini.nhts <- betas.sum[5, 4] |> sprintf(fmt = "%4.3f")
b.d.gpt.advan <- betas.sum[9, 4] |> sprintf(fmt = "%4.3f")
b.d.gpt.nhts <- betas.sum[13, 4] |> sprintf(fmt = "%4.3f")

# m coeffs
b.m.gemini.advan <- betas.sum[2, 4] |> sprintf(fmt = "%4.3f")
b.m.gemini.nhts <- betas.sum[6, 4] |> sprintf(fmt = "%4.3f")
b.m.gpt.advan <- betas.sum[10, 4] |> sprintf(fmt = "%4.3f")
b.m.gpt.nhts <- betas.sum[14, 4] |> sprintf(fmt = "%4.3f")

# dm coeffs
b.dm.gemini.advan <- betas.sum[3, 4] |> sprintf(fmt = "%4.3f")
b.dm.gemini.nhts <- betas.sum[7, 4] |> sprintf(fmt = "%4.3f")
b.dm.gpt.advan <- betas.sum[11, 4] |> sprintf(fmt = "%4.3f")
b.dm.gpt.nhts <- betas.sum[15, 4] |> sprintf(fmt = "%4.3f")

# od coeffs
b.od.gemini.advan <- betas.sum[4, 4] |> sprintf(fmt = "%4.3f")
b.od.gemini.nhts <- betas.sum[8, 4] |> sprintf(fmt = "%4.3f")
b.od.gpt.advan <- betas.sum[12, 4] |> sprintf(fmt = "%4.3f")
b.od.gpt.nhts <- betas.sum[16, 4] |> sprintf(fmt = "%4.3f")
```

@tbl-betas and @fig-betas summarizes the estimated effects of the four popularity biases on large language model-simulated tourist flows (@eq-log-model).
Across two large language models and two empirical baselines, destination-month popularity consistently has the largest positive coefficient.
Meaning, large language models show a tendency to favor popular destination-month combinations when generating travel recommendations.
Although,95% credible intervals indicates high uncertaintay around the estimates for Gemini 2.5 Flash Lite with both empirical baselines. 
One way to interpret the coefficient for destination-month popularity bias is to consider it as an elasticity.
For example, GPT-4.1 Nano with ADVAN Mobility Data baseline had a median coefficient of `r b.dm.gpt.advan` for destination-month popularity.
If real-world data shows that a particular destination-month combination is twice as popular than what is expected under independence of destination and month popularity ($DM_{(j,m)} = 2$), then the expected tourist flow generated by GPT-4.1 Nano for that combination is approximately `r round(2 ** as.numeric(b.dm.gpt.advan), 1)` times higher ($2^{1.771}$), holding other factors constant.

We find mixed results for the rest of the popularity biases.
Some effects are specific to the large language model.
For example, Gemini 2.5 Flash Lite consistently shows negative coefficients for destination popularity, indicating that it tends to negatively rescale popular destinations (Median $\beta_{1}$ = `r b.d.gemini.advan` and `r b.d.gemini.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).
The same pattern is only observed for GPT-4.1 Nano with National Household Travel Survey baseline (Median $\beta_{1}$ = `r b.d.gpt.nhts`) but not with ADVAN Mobility Data baseline (Median $\beta_{1}$ = `r b.d.gpt.advan`).
GPT-4.1 Nano with shows positive rescaling for origin-destination popularity (Median $\beta_{4}$ = `r b.od.gpt.advan` and `r b.od.gpt.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines), while Gemini 2.5 Flash Lite shows mixed findings (Median $\beta_{4}$ = `r b.od.gemini.advan` and `r b.od.gemini.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).

Finally, we note that the month popularity coefficients are negative for GPT-4.1 Nano (Median $\beta_{2}$ = `r b.m.gpt.advan` and `r b.m.gpt.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).
This is contradictory, given prior descriptive analysis indicated GPT-4.1 Nano having greater seasonality.
One possible explanation is that peak months in GPT-4.1 Nano simulations poorly align with those in empirical data (see @fig-prop[b]()).
Therefore, the model attempts to fit the month popularity factor by flattening the empirical month popularity distribution.

```{r}
#| label: tbl-betas
#| tbl-cap: Median and 95% credible intervals of Poisson model coefficients accross 1,000 iterations
betas.sum |> 
    pivot_wider(names_from = emp, values_from = c(median.coeff, lower.ci, upper.ci)) |>
    relocate(ends_with("_ADVAN"), .after = param) |>
    mutate(
        param = factor(
            param,
            levels = levels(param),
            labels = md(
                c(
                "$\\beta_{1}$: Destination",
                "$\\beta_{2}$: Month",
                "$\\beta_{3}$: Destination-Month",
                "$\\beta_{4}$: Origin-Destination"
                )
            )
        ),
        sim = paste("Simulation:", sim)
    ) |>
    mutate(param = indent_row(param)) |>
    gt(groupname_col = "sim") |>
    tab_spanner(
        label = html("Empirical: ADVAN"),
        columns = ends_with("_ADVAN")
    ) |>
    tab_spanner(
        label = html("Empirical: NHTS"),
        columns = ends_with("_NHTS")
    ) |>
    fmt_number(decimals = 3) |>
    fmt_markdown(columns = param, rows = TRUE) |>
    cols_align(
        align="left",
        columns = param
    ) |>
    cols_label(
        param = "",
        starts_with("median.coeff") ~ "Median",
        starts_with("lower.ci") ~ "2.5%",
        starts_with("upper.ci") ~ "97.5%",
    ) |>
    # italicize sim & emp names
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_column_spanners()
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote(
        md("Note: ADVAN=ADVAN Mobility Data, NHTS=National Household Travel Survey. Summary of Poisson model results over 1,000 iterations.")
    )
```

```{r} 
#| label: fig-betas
#| fig-cap: Summary of popularity effect estimates across 1,000 iterations
text.beta <- data.frame(
    median.coeff = c(0, 0),
    param = c(4, 4),
    emp = c("ADVAN", "ADVAN"),
    sim = c("GPT-4.1 Nano", "GPT-4.1 Nano"),
    label = c("***Negative rescaling*** ←", "→ ***Positive rescaling***")
)

p.betas <- draw_beta_fig(betas.sum) +
    scale_shape_manual(
        values = c("Gemini 2.5 Flash Lite" = 20, "GPT-4.1 Nano" = 18)
    ) +
    scale_color_manual(
        values = c("Gemini 2.5 Flash Lite" = color.gemini, "GPT-4.1 Nano" = color.gpt)
    ) +
    # annotate attenuation (B<0) and amplification (B>0)
    geom_richtext(
        data = text.beta,
        label = text.beta$label,
        color = "black",
        fill = NA, label.color = NA,
        vjust = -2,
        hjust = c(1.1, -0.1),
        size = 4,
    ) +
    labs(
        title = "Generative AI Amplify Popularity of Destination-Month Pairs",
        subtitle = "Other popularity factors are dependent on specific large language model used and show mixed results",
        caption = "Note: Summary of Poisson model results over 1,000 iterations. Error bars represent 95% credible intervals for the estimates.",
    )
p.betas
```

## Robustness checks

We conducted following robustness checks to test the sensitivity of our findings to different simulation choices (reported in @apx-robust).
These additional simulations were performed with the first 100 iterations due to budget and computing time constraints.
First, using alternative prompts does not substantially change the main findings.
Large language model outputs are sensitive to the specific prompts used.
Hence, we collected additional simulation data using slightly modified prompts (see @apx-prompt).
One version excluded explicit instruction that demographic factors influence tourist choices ("reduced instruction" prompt).
Another version instructed the models to act as *tourists* choosing destinations instead of travel agents giving suggestions ("tourist persona" prompt).
None of these alterations substantially changed the main findings (@fig-prompt-betas).
One notable exception is that Gemini 2.5 Flash Lite with reduced instruction prompt showed negative coefficients for month popularity.
However, this case also showed stronger effects for destination-month and origin-destination popularity compared to using the original prompt.

Changing the temperature parameter also does not alter the results.
The temperature parameter controls randomness in large language model outputs.
Higher temperature setting produce more diverse outputs, while lower temperature setting generate more deterministic outputs.
The default temperature setting used in our main analysis is 1.0.
We collected additional data using temepratures of 0.5 and 1.5 (@fig-temp-betas).
GPT-4.1 Nano with temperature of 1.5 could not generate valid outputs and hence was excluded.
Similiar to @bai2025, we find that temperature setting has minimal impact on the popularity bias of large language models.

Larger models in the Gemini 2.5 and GPT-4.1 series, as well as models from other providers, still show positive destination-month popularity bias.
We repeated the main analysis with larger variants of Gemini 2.5 and GPT-4.1 series models (Gemini 2.5 Flash and GPT-4.1 Mini).
Additionally, we collected data using xAI's Grok 3 Mini and Meta's Llama 4 Scout to examine whether the findings are generalizable beyond OpenAI and Google models.
Across all models tested, destination-month popularity shows strongest positive effects (@fig-model-betas).
Compared to the models used in our main analysis, larger models show stronger destination-month popularity bias, not weaker.

Finally, the results are unchanged when aggregating data across all iterations instead of fitting Poisson regression models for each iteration separately.
We conducted alternative hypothesis tests by aggregating the simulation data across all 1,000 iterations and fitting a single Poisson regression model for each large language model simulation.
This approach significantly reduces the number of destination-origin-month cells with zero tourist counts.
We can also obtain significance levels for the estimated coefficients using  traditional frequentist tests.
Still, coefficient estimates using aggregated data are nearly identical to median estimates from our main approach (see @tbl-agg-betas).

# Discussions

Despite the rapid adoption of generative AI in tourism, there exists little empirical evidence on how these algorithms operate and what impacts will have.
This study focuses on in what way generative AI diverges from empricial tourism patterns and what underlying mechanisms drive such differences.
Such generative AI models are complex and opaque.
But so are humans—tourists are complex decision-makers influenced by myriad factors, many of which are not fully understood.
Same as how social scientists study human cognitive bases based on their behaviors, we proposed a model for testing hypothesized mechanisms behind generative AI biases.
Beyond quantifying the difference between algorithm outcomes and emprically-grounded baselines, our model allowed us to obtain interpretable results on what factors drive such differences.

## Key findings

The models generate less diverse and more unevenly distributed tourist flows compared to empirical US domestic tourism patterns.
States show slightly more unequal levels of tourist arrivals, with popular states continuing to be popular in large language model simulations (@fig-prop[a]()).
More concerning issue is that both models produce highly seasonal tourism patterns.
While seasonality is common feature of tourism [@butler1994; @duro2016], these algorithms show much sharper peaks and troughs than empirical data (@fig-prop[b]()).
This finding is alarming for *all* US destinations, as both popular and less popular states show greater seasonality in tourist arrivals (@fig-prop[c]()).
Destinations also become more reliant on a few tourist origins in large language model simulations (@fig-prop[d]()).

Large language models also produce structurally different tourist flows (@fig-graph-stats).
These models produce less reciprocal tourist flows where popular destinations would receive more tourists but send fewer to others, leading to a more "one-way" tourism system.
While these models also tend to recommend traveling to farther destinations, other spatial patterns differ between the two large language models.
GPT-4.1 Nano shows much stronger avoidance for bordering states and favors in-state tourism.
Tendency to avoid bordering states is not as severe in Gemini 2.5 Flash Lite, while showing prevalence of in-state tourism similar to empirical baseline.
Biases in spatial perception of these models is one possible explanation, such as overestimating inter-regional distance while underestimating intra-regional distance [@fulman2024].
Given that these algorithms are *language* models, they may also reflect linguistic and cultural representations of what is meant by tourism [see @resnik2025; @tao2024].

Large language models favor visiting destinations during their peak months (@fig-betas).
We find consistent evidence of this positive destination-month popularity bias, across three different prompts, three temperature settings, and six large language models (@apx-robust).
Findings are mixed for the other three popularity biases.
For example, the two GPT-4.1 family of models also show bias toward popular origin-destination pairs, while aother models attenuate empirically popular destinations.
The results mostly vary by large language model used, rather than alternative specifications for simulations or empirical baselines.

Unfortenately, this study could not identify why the models show different types and degree of popularity biases.
Because process of building these models remain opaque, we can only speculate that the differences arise from variations in training data, model architectures, and human feedback [@santurkar2023].
These biases also arise from feedback loops where human biases seep into training data, producing biased models that in turn influence human behavior [@chen2023d].
Understanding and mitigating these biases will therefore require greater transparency from developers of generative AI about training processes and data sources.

## Theoretical implications

This study provides early empirical evidence that generative AI poses significant potential to undermine sustainability and resilience of tourism sector.
While we are seeing generative AI increasingly affecting decisions of tourists and pracitioners, what this entails for stakeholders in the tourism system reamined unclear.
Hence, understanding the downstream consequences of generative AI adoption is urgent real-world issue that tourism research could impact society [@li2026].

Our findings substantiate prior concerns that these algorithms could introduce biases that exacerbate ethical and social issues in tourism [@law2025; @lehto2025; @mellors2025].
We show that such biases not only have ethical implications but also practical consequences destinations that rely on tourism.
Generative AI models provide travel suggestions that worsen seasonality of tourism, reduce diversity of demand origins, and reduce bi-directional exchange of tourists among regions.
All these patterns go against conditions for fostering sustainable and resilient tourism sector [for example, @cisneros-martinez2018; @lee2025c; @wttc2022].
Thus, we echo the previous cautions that technology adoptions in tourism should not be seen as *progress* or *advancements*; rather, they are *changes* that we must carelly assess their broad implications [@tribe2017].

The proposed Baseline-Rescaling-Outcome Model contribute to existing literature on AI bias metrics by offering an interpretable framework for testing algorithmic bises.
The existing methods often required access to internal model parameters and could mainly tell whether biases exists [@bai2025; @chen2023d].
Our approach further allows testing multiple hypothesized mechanisms that could amplify or attenuate empirical patterns, thereby explaining why we observed divergence from empirical data.
While these explanations are still correlational rather than causal, they allow us to understand systemic mechanisms behind the black-box algorithms.

This study focused on measuring bias in genreative AI from supplier-side and its implications for destinations.
However, bias and their consequences can also be studied from both demand-side, focusing on whether *tourists* are exposed to personalized and diverse travel options.
For instance, recommendation algorithm with popularity biase from supply-side can also lead to users receiving less satisfying options [@abdollahpouri2020].
Similarly, casues of these biases can also be spectulated from both demand- and supply-side.
These biases may arises from learning to reflect popular tourist behvaviors (demand-side) or content from popular destinations with more marketing resources being more prevalent in training data (supply-side).

Our large language model simulations are projections wherein *all* tourists’ decisions are made by generative AI.
They are hypothetical scenarios, far from the current reality.
However, we use these projections because they can illustrate how generative AI might reshape tourist flows, by isolating the patterns of generative AI-driven tourism and comparing them to empirical baselines.
This present an opportunity to shift the relationship between empirical phenomena of generative AI adoption in tourism and related tourism knowledge.
Currently, empirical phenomena of generative AI adoption outpace tourism knowledge production, due to generative AI's rapid evolution and academic publication delays.
This study demonstrates an alternative route: *a priori* knowledge production by tourism scholars that informs decision-making in tourism practice.
Such guiding knowledge will prove crucial for tourism scholarship and practitioners to ensure sustainable and resilient tourism systems amid rapid technological changes.

## Methodological contributions

Our methodological contributions are twofold.
One is providing empirically-grounded profiles of simulated tourists to ensure representativeness of the simulations.
This approach contrasts with prior tourism studies that used synthetic data from generative AI, which either assumed hypothetical tourist segments or bludly instructed to simulate tourist behavior without first providing what touirists the model needs to simulate [for example @andreev2025; @xiong2024].

Another difference is that we account for stochasticity in simulations by running multiple iterations instead of relying on a single run [for example @andreev2025;@mellors2025].
Tourism is a complex system, where the outcomes are probabilistic rather than deterministic [@faulkner2003].
As such, our approach acknowledges that even the empirical data is one of many possible outcomes.
By creating simulated realizations of the tourism patterns under empirical-driven and AI-driven scenarios, we can better project the range of possible outcomes and identify which observed patterns constitute robust features versus artifacts of stochastic variation.
We provide all code and synthetic data from the simulations, for replicating and extending our analyses.
This includes the full dataset of two millon individual-level travel suggestions from two main large language models and additional one million obtaind for robustness checks.

Based on the findings, we question relability of using AI-generated synthetic data even for exploratory and early-stage research purposes [suggested by @ali2025; @viglia2024a].
Despite our efforts to ensure representativeness and robustness of simulations, large language models still produced tourism patterns that diverge substantially from empirical data.
@santurkar2023 also show that generative AI poorly represent both general public and particular subpopulation even when steered to do so.
Because our purpose is to examine the biases in generative AI, such divergences are informative.
However, if researchers use AI-generated synthetic data for a pilot study, the results may mislead future research directions.
As these algorithms behave in more extreme and different ways than real-world tourists, we must caution synthetic data *limiting* tourism knowledge development rather than advancing it.

## Practical implications

Our perspective is that generative AI has benefits for tourism sectors but we also need to weigh its potential risks.
It can be used as a tool for tourists to efficiently seek travel information, practitionrs to guide their decisions, and destinations to get ideas for improving their tourism experiences [@dogru2025].
Nevertheless, these benefits are not without costs; they also introducing new issues to tourism system.
Therefore, we urge tourism practitioners and regulators to monitor and prepare for generative AI’s potential impacts on tourist behavior and destination choice.
Lesser-known destinations are particularly vulnurable.
Generative AI models train on extensive cross-domain datasets, making their outputs difficult to alter.
Addressing such challenges would require efforts from both regulators and tourism intermediaries to ensure equitable and diverse representation of destinations.
For example, EU AI Act mandates bias testing for high-risk AI systems, such as credit scoring and employment screening [@vanbekkum2025].
Tourism sector could also advocate for simliar legislation for auditing biases.
Such bias audits would needed for both tourist- and employee-facing generative AI applications.
We urge already-popular destinations to advocate such policy, negative comsequences like worsend seasonality and reduced demand diversity equally affect them.
More simple interventions could be implemented by tourism intermediaries, such as putting a disclosure that "AI-generated suggestions may overrepresent popular options" and stratifying options before producing AI-generated options.

We call for national and international tourism organizations begin assessing implications of generative AI adoption, including potential ethical and social consequences that were not examined in this study.
Organizations must recognize that tourism functions not merely as a "market offering" but as a societal force affecting people and communities [@higgins-desbiolles2006].
For example, one social benefit of tourism is that it provides experiences and opportunities for socially excluded groups [@mccabe2020a].
These benefits may diminish if generative AI limits travel options for particular demographic groups.
While we caution generative AI's potential consequences for tourism, the time is right to proactively shape the future of tourism before generative AI is further integrated into tourism industries.
Our projected generative AI-driven tourism is still hypothetical; it is up to us whether such a future may never come to pass.

## Limitations and future research

Consider the following key limitations when interpreting our findings.
The results are subject to the modifiable areal unit problem  [@fotheringham1991].
Large language models recommended destinations in varying geographic units, which we aggregated to the state level for analyses.
This aggregation masks variations at finer geographic scales, thus likely underestimates the differences between the empirical and generative AI-driven simulations.

Our large language model simulations rely solely on demographic factors and exclude psychological, behavioral, and social factors that shape tourist decisions.
One of which is tourist motivation.
Even if two individuals with an identical demographic profile visited the same destination, they could have entirely different motivations for visiting.
Future research could consider specifying preferences and motivations for each simulated tourist [see @gao2024].
In addition, simulations could incorporate different rates of accepting AI-generated recommendations for more realistic projections.
For instance, younger individuals are generally more inclined to accept generative AI recommendations compared to older individuals [@seyfi2025], which could result in different travel patterns than those observed in our "extreme-case" scenarios.

The simulations assumed that everyone travels and selects a single destination.
But we must consider that there are non-travelers who choose not to travel and tourists visiting multiple destinations during a single trip [@haukeland1990; @yang2013].
One tourist's decision can also influence the decisions of others [@lee2025a], although our simulations do not account for interactions between simulated individuals.
Our simulation also assumed scenario where *all* destination choices are made by generative AI.
Future research could explore scenarios where acceptance rates of generative AI recommendations vary across different demographic groups.
Such analysis would reveal whether outcomes of generative AI biases scale linearly or require a critical mass of adoption for substantial impacts.

Further, studies show that generative AI exhibits stonger bias when decisions are relative rather than absolute [@bai2025].
Since we instructed the model to recommend a single destination instead of chosing one among given options, the degree of popularity bias shown in this study may be conservative.
However, decisions of real-world tourists also are significantly affected by how and what choices are presented [@kim2025c].
For future research examining generative AI models' biases in relative decision-making, we recommend conducting both empricial expriments and AI-driven simulations.

Future research could refine how popularity biases are measured.
For example, popularity bias may be non-linear where destinations with popularity under certain threshold receive no recommendations at all.
We also note that our biase estimates are less reliable when the peaks of empirical and generative AI-driven tourism patterns poorly align.
Further extensions could consider including alternative model terms that account for such shifts in rank orders of options.
Fianally, we recommend applying our model to other types of biases and algorithms.
As tourism and hospitality firms are adopting generative AI for consumer and employee-facing applications, examining socio-demographic biases would be crucial for ensuring ethical and fair integration of generative AI.

# Data availability

The data and code for reproducing the results are available at [https://github.com/jinvim/genai-tourism-bias](https://github.com/jinvim/genai-tourism-bias).


::: {#refs}
:::

{{< pagebreak >}}

{{< include appendix.qmd >}}