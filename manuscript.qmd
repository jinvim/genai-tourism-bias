```{r} 
#| label: setup
#| include: false
library(tidyverse)
library(arrow)
library(sf)
library(colorspace)
library(gt)
library(gtsummary)
library(ggtext)
library(glue)
library(patchwork)
library(broom)
```

```{r} 
#| label: load-functions
# load custom functions and theme
source("r/helpers.r")
source("r/theme.r")
theme_set(theme_myriad())

color.rand <- "#777777"
color.nhts <- "#af9da6"
color.advan <- "#c4b4a1"
color.gemini <- "#214e7b"
color.gpt <- "#ff7f05"
```

```{r} 
#| label: read-data
#| include: false
source("r/data.r")
```

# Highlights

- Quantifies generative AI’s potential impact on US domestic tourist flows
- Proposes a Baseline-Rescaling-Outcome Model for testing algorithmic biases in tourism
- Large language models produce more seasonal and unequally distributed tourist flows
- The models exhibit a popularity bias that favors popular destination-month pairs
- Calls for assessing generative AI biases and their consequences in tourism

# Introduction

Generative AI has moved quickly from novelty to everyday tool.
Pepole use these algorithms as always-ready collaborators that can assist in making mundane choices to critical business decisions [@marr2023]
Tourism is no exception.
Most travelers already use generative AI to plan their trips, and major travel intermediaries like Expedia and TripAdvisor are integrating generative AI into their platforms [@booking.com2025; @tripadvisor2023;@expedia2023].
Beyond travel planning, generative AI is also supporting core operations of tourism industry and destination management, such as marketing, human resource management, and tourism experience design [@amadeus2024; @dogru2025].

Despite widespread adoption of generative AI in tourism, empirical evidence on its impacts are scarce [@hsu2024; @mellors2025].
Major concerns include ethical and cultural biases in these algorithms [@ali2025; @law2025].
As more tourists and practitioners rely on generative AI, algorithmic biases can lead to behavioral shifts that reproduce or amplify biases in our society [@kordzadeh2022; @vicente2023].
Limited access to model internals and training data, combined with the black-box nature of generative AI, makes revealing these biases difficult [@bai2025; @gallegos2024]. 
This knowledge gap leaves tourism stakeholders uncertain about how to prepare for generative AI’s potential impacts, or to determine whether such preparation is even necessary.

This study assess how the rapid adoption of generative AI and its algorithmic biases can reshape tourist destination choices.
We develop the *Baseline-Rescaling-Outcome Model* that can test algorithmic biases using empirical expectations, algorithmic outcomes, and hypothesized bias mechanisms.
Using demographic profiles from the US Census Bureau, we created a simulated sample of one million US residents.
Then large language models (LLMs) acted as travel agents who recommend one domestic travel destination for each individual.
We explain deviations between AI-generated and empirical US domestic tourism patterns as systematic *biases* in generative AI, particularly biases that favor popular options and pairs of options.

Compared to empirical tourism patterns, LLMs yield less diverse tourist flows that are more concentrated on specific combinations of destination, origin, and month.
They also produced more unevenly distributed tourist flows where destinations have more seasonal and less diversified tourism demand.
The models showed a strong tendency to favor visiting destinations during their peak seasons, indicating amplification of destination-month popularity.
However, tested models differed in popularity biases toward popular destinations, months, and origin-destination pairs.
The findings serve as early empirical evidence that generative AI poses significant potential to undermine the sustainability and resilience of the tourism sector.

# Background

## Generative AI and its impacts on tourism

This study focuses on generative AI and its implications for tourism.
AI has become a catch-all term that encompasses various technologies aimed at simulating human intelligence. 
Generative AI specifically refers to algorithms that are trained to recognize patterns in vast data and generate content such as text, images, or videos [@li2025].
We avoid *chatbots* because they represent just one application of generative AI.
Likewise, we do not use brand-specific terms like *ChatGPT* when discussing generative AI in general.

We currently lack empiricial evidence on how and to what extent generative AI will affect tourism [@hsu2024; @mellors2025].
Although tourism and hospitality literature on generative AI is growing, their primary focus is on adoption behaviors: who, when, and why tourists and practitioners adopt generative AI [see recent reviews by @gossling2025; @li2025].
Some preliminary works underscore benefits that generative AI brings to businesses and tourists.
Businesses who announced generative AI integration saw competitive advantages in market value [@jung2026].
Additionally, counterfactual analysis shows that underperforming businesses can improve their revenue by using generative AI for product marketing [@fan2025].
For tourists, generative AI reduces cognitive load during travel planning, thereby increasing visit intentions and decision satisfaction [@shin2025].
However, others also caution negative impacts of generative AI on tourism [@law2025; @lehto2025].
Few studies examine how generative AI have biases that favor mainstream tourism patterns [@andreev2025; @mellors2025].
Such biases can affect behaviors of users relying on generative AI, leading to real-world impacts that reproduce or amplify existing biases in society [@kordzadeh2022; @vicente2023].
These preliminary findings echo standing debates about how technologies---from search engines to social media---have both benefited and harmed tourism [@gong2024a; @leung2013].

## Challenges of defining and measuring biases in generative AI

Both conceptual and empirical works on generative AI in tourism commonly raise concerns about biases in these algorithms.
In particular, social biases in AI and their ethical implications are prominent focus of tourism and hospitality research.
This trend aligns with broader literature on algorithmic biases that emphasize ethical challenges of such biases, specifically racial and stereotypes [see @ghosh2025; @kordzadeh2022].
For example, @law2025 highlight ethical challenges of AI adoption in tourism and hospitality sectors, urging inclusiveness of AI adoption with reduced "biased and discriminatory actions" (p.287).
@hsu2024 suggests fine-tuning generative AI with tourism-specific data, noting that such models "could perpetuate stereotypes and result in discrimination" (p.2).
@viglia2024a caution biases in AI-generated tourism data, giving a specific example of AI generating racist content.
Beyond ethical concerns, several schloars mention popularity biases in generative AI as a potential threat, where algorithms favor popular options while underrepresenting less popular ones [@law2024; @lehto2025].
This bias poses practical concerns for the tourim sector, as it can exacerbate challenges like over-tourism for popular destinations, while less popular destinations struggle to sustain their tourism sector [@mellors2025].

We note two key challenges in examining biases in generative AI: defining and measuring biases.
First, works on AI biases in tourism and hospitality are often vague about what is meant by these algorithms being *biased*.
This issue is not unique to tourism scholarship; broader AI bias literature have also been criticized for lacking explicit definition of bias [@ghosh2025].
Even policies mandating bias assessments, like the EU AI Act, often leave bias undefined [@vanbekkum2025].
Such ambiguity in defining bias results in discrepancies between the concerns raised and the empirical evidence provided [@blodgett2020].

Algorithmic bias has no single definition.
When the focus is on stereotyping, studies define bias as *act of* unjustified association between social groups and attributes [@bai2025].
This definition follows social psychology literature on implicit asssociations [@greenwald1998].
Studies examining ethical implications of algorithmic biases often define bias in terms of *outcomes or treatment*: unequal allocation of resources or unfavorable representation of social groups [@blodgett2020; @gallegos2024; @kordzadeh2022].
Such definitions parallel discrimination laws that require proof of disparate outcomes, which treat biases as individual beliefs that are unactionable [@seiner2006].
Others distinguish bias from harm, where bias is defined as a model having a particular inclination or deviation compared to empirical data [@ghosh2025; @wu2024a].
This more netural definition of bias is closely tied to statistics and computer science, where bias is considered unavoidable for generalization [@chen2023d; @ghosh2025].
Thus, definition of algorithmic bias varies not only across disciplines but also by specific bias being examined.

Even with clear definitions, measuring biases in generative AI is challenging.
A major obstacle is that these models are often proprietary and closed-source.
@ali2025 proposes using tools like IBM's AI Fairness 360 or Google’s What-If toolkits for assesing biases in AI-generated tourism data.
However, these tools assume access to data and model internals, neither of which is available for commonly used generative AI models like ChatGPT [@gallegos2024].
Detecting biases is also difficult for recent generative AI models because they undergo safety tunings to avoid explicit biases [@bai2025; @santurkar2023].
Moreover, most existing AI bias metrics are designed to quantify disparate outcomes, not to explain how such disparities arise [see review of bias metrics by @gallegos2024; @kordzadeh2022].
For example, existing metrics can identify that generative AI disproportionately suggest resort destinations to certain racial groups.
But they cannot explain whether such disparities arise due to favoring popular destinations, peak seasons, racial stereotypes, or a combination of these mechanisms.
These definitional and measurement challenges collectively limit our ability to effectively test biases in generative AI models and assess their implications for tourism.

# Baseline-Rescaling-Outcome Model for testing algorithmic biases in tourism

We propose the Baseline-Rescaling-Outcome model designed to address the challenges of measuring biases in proprietary and closed-source algorithms.
Bias is defined as a *systematic deviation of algorithmic outputs from empirically grounded expectations of phenomena*.
Our definition separate bias from harm since what is considered harmful depends on who is affected [@blodgett2020; @ghosh2025]
For example, if an algorithm systematically favors one destination over another, such bias is benefical to the favored but harmful to the rest.
Even within the favored destination, the tourism sector may benefit while locals suffer from over-tourism.
We therefore separate the detection of biases from the assessment of their consequences.

Our model tests bias by modeling the divergence between algorithmic *outcome* and empirical *baseline* as a function of *rescaling* factors representing hypothesized bias mechanisms (@fig-model).
This approach has three advantages over existing bias tests.
First, the model can test biases without access to model internals or training data.
We adapt social science methods that infer human biases from behavioral outcomes like response speed and error rates [@greenwald1998].
Like cognitive processes, we assume the algorithm and its modeling process as unobservable,inferring biases from outputs instead.
Our approach is also flexible.
The test can be adapted beyond generative AI and tourism to any context with empirically grounded expectations, rescaling factors, and algorithmic outputs. 
Finally, the rescaling factors enable interpretable bias diagnosis that translates directly into practical suggestions for debiasing.
Although, the model cannot provide *causal* explanations of how biases arise in algorithms.
Biases in algorithms are caused by complex socio-technical processes that includes biases in data generating processes, model architectures, and human feedback [@santurkar2023; @viglia2024a].
Because we often lack access to these processes and due to uninterpretable nature of some algorithms, we can only speculate on what causes biases [@bai2025].

![Baseline-Rescaling-Outcome Model](figures/model.svg){#fig-model}

## Outcome: Projected tourism patterns under complete reliance on the algorithm

The first component of our model is the *outcome* when the phenomena are entirely driven by the algorithm, following the logic of scenario-based projection models.
Examples of such projections models include Shared Socioeconomic Pathways for climate trajectories and COVID-19 diffusion models [@adam2020; @ipcc2021].
These models contain “worst-case” scenarios that project the most extreme outcomes: climate projections without emission reductions or infection rates without government interventions.
For example, we can test bias in generative AI tourism recommendatinos by projecting the outcome when generative AI makes all destination choices.
Similarly, biases in hiring algorithms for tourism firms can be tested by projecting a scenario where all hiring decisions are made by the algorithm.
Though unrealistic, these undilluted outcomes of the algorithm are necessary to reveal the full extent of their biases.

## Baseline: Empirically grounded expectations of phenomena

Empirical *baseline* is a foundational component of our model.
Prior works have used similiar empirically-grounded approaches, comparing real-world distributions with algorithmic outputs to assess representation and popularity biases [@abdollahpouri2020; @santurkar2023].
Consider a situation where an algorithm has a four-in-ten chance of suggesting US domestic tourists to visit San Francisco.
Could we say that this algorithm has a systematic tendency to favor San Francisco as a tourism destination?
If four in ten Americans visit San Francisco, then the algorithm is simply reproducing what is expected in the real-world tourism patterns.
However, if only one in ten US domestic tourists visit San Francisco, then the algorithm does favor San Francisco beyond the empirical expectation.
Thus, empirical baseline provide benchmark for "unbiased" algorithmic outputs.

## Rescaling: Testable factors for hypothesized bias mechanisms

*Rescaling* is the final component of the model that tests specific mechanisms that produce biases.
We do so by reproducing the algorithm outcome using the baseline and a set of rescaling factors.
Under the null condition of no bias, the algorothm should reproduce the baseline hence the rescaling factors are unnecessary.
If the algorithm deviates from the baseline, we can test whether such deviation is systematic by explaining the divergence using hypothesized mechanisms.
This approach yields interpretable tests of specific bias in algorithms, going beyond measuring the degree of biases.
Our model also captures the direction of biases.
The algorithm could exhibit bises that reduce empricially-observed asymmetries [@ghosh2025].
For example, it may favor less popular destinations and off-peak seasons, diversifying the tourism demand across destinations and time.
Our model can test for such biases as negative rescaling factors, allowing us to explain algorithm outputs as mixtures of amplification and attenuation of empirical patterns.

# Study design

We apply the Baseline-Rescaling-Outcome Model to test popularity biases in generative AI travel recommendations.
Popularity bias is defined as tendency where popular options "are recommended even more frequently than their popularity would warrant" [@abdollahpouri2020, p.1].
Understanding this bias in tourism is particularly timely and practical, as major online travel agencies are already integrating generative AI into their platforms.
Humans also exhibit similar behaviors, such as popular people gaining even more friends over time and tourists flocking to popular destinations [@barabasi1999; @lee2025a].
Our study therefore tests whether generative AI amplifies or attenuates such popularity biases beyond what is observed empirically.

Examining pouplarity in tourism context is also of theoretical significance.
Unlike recommending movies or music, tourism recommendations need to consider spatial and temporal dimmensions of travel choices.
Decision to travel is not only about *whether* to travel, but also *from where*, *to where*, and *when*.
Thus, we further extend popuarity bias into four types that are tourism-specific: destination popularity, month popularity, destination-month popularity, and origin-destination popularity biases.
The first two measure whether generative AI amplifies or attenuates the popularity of destinations and peak months.
While these two factors account for destination and month popularities independently, bias may also exist in specific combinations of destinations and months.
Destination-month popularity bias caputure whether algorithms favor specific destinations during specific months.
Similarly, origin-destination popularity bias capture tendency to excessively pair tourists from specific origins to specific destinations.

@fig-steps summarizes our data collection and analysis process.
The LLM simulation involves generating tourist flow using empirically grounded demographic profiles.
Separately from the AI-driven simulation, two data sources were used to estimate real-world tourism patterns.
This empirical data is then used to derive baseline expectations and popularity factors.
Finally, we combine simulation and empirical data to test four hypothesized popularity biases by fitting the Poission model.

![Overview of the simulation and analysis process](figures/steps.svg){#fig-steps}

## Data collection

### Definition of population and simulated samples

The population of our simulations is US residents aged 18 and over. 
The US domestic tourism market is one of the largest in the world, offering geographically and socioeconomically diverse destinations [@unwto].
Hence, the US context provides sufficient variability for large-scale simulations, while excluding complications of international tourism like visa requirements.
Most generative AI models also perform better on English tasks, making the US context advantageous for these models [@qin2025].

We used 2019-2023 American Community Survey 5-Year Public Use Microdata Sample data to derive stratum weights for the population.
@tbl-demo summarizes sex, age, and household income proportions of the population.
From this population, we took a random sample of 1,000 individuals stratified by state, sex, age, and income.
This sampling procedure was repeated 1,000 times, yielding one million simulated individuals with demographic characteristics that mirror the population.
By using empirically derived profiles, we ensure that the demographic distribution of simulated travelers resembles that of US domestic tourists.
This approach also fixes the number of outgoing tourists from each state, allowing us to control for origin-specific propensity to travel.
One limitation is that generative AI models may also influence the decision to travel itself, which we do not account for here.

```{r} 
#| label: tbl-demo
#| tbl-cap: Age, sex, and household income proportions of the population
df.demo.prop |>
    mutate(category = indent_row(category)) |>
    gt(groupname_col = "strat") |>
    fmt_number(
        columns = p,
        decimals = 3
    ) |>
    cols_label(
        category = "",
        p = "Proportion"
    ) |>
    cols_align(
        align = "left",
        columns = category
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_style(
        style = cell_text(whitespace = "nowrap"),
        locations = cells_body(columns = category)
    ) |>
    tab_footnote(
        "Note: Based on 2019-2023 American Community Survey 5-Year Public Use Microdata Sample."
    )
```

### Large language model simulations

Social science researchers are increasingly using generative AI models for generating synthetic data.
We highlight four key differences between our approach and prior studies.
First, we use AI-generated data because they provide means to show how these AI models *do not* replicate human behavior.
Our focus is thus fundamentally different from previous suggestions to use AI-generated data to *mimic* tourist behavior [for example @ali2025; @viglia2024a; @xiong2024].
Next, we base our simulations on empirically derived demographic profiles.
This modification is to ensure that any divergence from empirical tourism patterns is attributable to algorithmic biases, instead of using arbitrary or non-representative profiles that would confound the results [for example, @andreev2025].
Third, unlike studies that relied on a few handpicked responses or a single simulation run [for example @mellors2025; @xiong2024], we ran multiple iterations of simulations to sufficiently capture the uncertainty in LLM outputs.
Finally, our approach recognizes the network and temporal nature of tourism.
Beyong looking at destination choice alone, we simulate the complete network of tourist flows between all origin-destination pairs across months.

The simulation starts with a system prompt containing the simulation context, response structure, and examples (available in @apx-prompt).
To simplify the simulation, we assume that each person chooses one domestic destination within the US (50 US states and the District of Columbia).
We instructed LLMs to act as travel agents and suggest one domestic travel destination based on the provided demographic profile.
Twenty simulated tourists were processed at a time to improve the efficiency of the simulation. 
This process is similar to agent-based modeling using LLMs [@gao2024].
But the key difference is that we prompt LLMs to act as travel agents, rather than as tourists.
The rationale for this choice is that our goal is to project how generative AI would influence tourist flows if widely adopted, rather than using it to substitute for human travelers.
We captured the probablistic nature of LLM outputs by repeting simulation with 1,000 individuals for 1,000 iterations.
This process produces a distribution of simulated tourist visits for assessing whether the differences between AI-simulated and empirical tourism patterns are not result of stochastic variations.

Two different LLMs were used to establish the consistency of our findings across different models: Google's Gemini 2.5 Flash Lite (version June 2025) and OpenAI's GPT-4.1 Nano (version April 2025).
They are among the leading LLMs currently available in terms of their capabilities and market share.
Because our simulations require a large number of responses, we chose their smallest variants optimized for speed and cost.
Although the two LLMs are closed-source, they are comparable in pricing structures ($0.10 per million input tokens; $0.30 and $0.40 per million output tokens, respectively).
We also chose these two models also because they use different architectures.
Gemini 2.5 family of models are build on mixture-of-experts architecture, while GPT-4.1 family are built on more traditional transformer architecture.
As these two models are developed by different companies, they are likely be trained on different datasets and tuning processes, which is ideal for assessing the generalizability of our findings.

All requests were made from the IP address of the university located in the southeastern US, using custom automation scripts.
We explicitly instructed LLMs not to use IP-specific details when generating recommendations.
Data collection continued until we achieved a complete dataset.
We then aggregated the data to create destination-origin-month matrices for each iteration and model, where each cell represents the number of tourists from the origin. $i$ to destination $j$ in a month $m$.

### Empirical baseline data and simulations

The empirical data serve two purposes in this study.
It provides the baseline for descriptively comparing characteristics of AI-simulated tourist flows against real-world tourism patterns.
Additionally, we use the empirically derived baseline and popularity factors to explain the discrepancies between AI-simulated and empirical tourist flows.
Because biases also exist in the empirical mobility data, we rely on two different data sources to ensure the robustness of our findings [@li2024b].
Our primary data source is the @advan Mobility Data, which estimates movements between US census block groups based on mobile device panels.
This dataset is our primary data source due to its high spatial and temporal resolution.
The supplementary data source is the Department of Transportation's 2022 National Household Travel Survey.
This is the only official national travel survey in the US that collects travel behavior data such as trip purpose, modes, and communiting zones [@nhts2022].

For both datasets, we used monthly data from January through December 2022 (the latest available for National Household Travel Survey). 
Following pre-processing steps were employed to filter out non-tourism mobility flows.
We first excluded visits to home and work locations, and movements within the county of residence [@lee2025c].
Additionally, trips under 50 miles one-way or within the same commuting zones were considered non-tourism. 
This offers more conservative estimates of tourist visits by filtering out short-distance and commuting trips that are less likely to be tourism-related.
These estimates were then used to compute the empirical shares and the four popularity factors.

Since we employed an iterative approach for the LLM simulations, direct comparison with empirical data is inappropriate.
Therefore, we also conducted empirical-based simulations for descriptive comparison between AI-simulated and empirical tourist flows.
Using empirical estimates as weights, we simulated tourist flows by randomly assigning destinations and months to each individual in the simulated sample.
Due to data anonymization, demographic factors could not be incorporated in the empirical-based simulations.
Therefore, we assume that the probability of traveling to another state in a given month is equal for all individuals in a given origin state. 
For instance, if 10% of Illinois residents visited Florida in January 2024, all Illinois residents were given a 0.1 probability to travel to Florida in January (irrespective of other demographic factors).
Same as the LLM simulations, the empirical-based simulation was repeated 1,000 times.
Subsequently, the results were aggregated to destination-origin-month matrices.

## Operationalizing the Baseline-Rescaling-Outcome Model

Below is the empirical model for testing four popularity biases.
Define number of tourist flow from origin $i$ to destination $j$ in month $m$ as $Flow_{(i,j,m)}$.
Let $P_{(i,j,m)}$ be the share of tourists from origin $i$ to destination $j$ in month $m$ over all tourist flow ($Flow_{(i,j,m)} / \sum{Flow_{(i,j,m)}}$).
Under the null condition that LLMs produce "unbiased" travel suggestions, we expect:
$$
Flow^{LLM}_{(i,j,m)} \sim \sum_{j,m}{Flow^{LLM}_{(i,j,m)}} \cdot P^{Empirical}_{(j,m|i)} = Baseline_{(i,j,m)}
$$ {#eq-null}
where $P^{Empirical}_{(j,m|i)}$ is the share of tourists traveling to destination $j$ in month $m$ given origin $i$, observed empirically ($P_{(i,j,m)} / \sum_{j,m}{P_{(i,j,m)}}$).
This share is multiplied by total number of LLM-produced tourists from origin $i$, which scales the expected number of tourists based on total tourist outflow from origin $i$.
Meaning, the right hand side of @eq-null is the baseline expectation when generative AI can perfectly replicate empirical tourism patterns ($Baseline_{(i,j,m)}$).

Destination and month popularities are defined as:
$$
\begin{aligned}
D_{j} &= \sum_{i,m}{P^{Empirical}_{(i,j,m)}} \\
M_{m} &= \sum_{i,j}{P^{Empirical}_{(i,j,m)}}
\end{aligned}
$$ {#eq-d-m}
where $D_{j}$ is the popularity of destination $j$ across all origins and months, and $M_{m}$ is the popularity of month $m$ across all origins and destinations.

We account for the popularity of specific destination-month pairs as a joint probability of choosing destination $j$ in month $m$ beyond what can be expected from their independent popularities:
$$
DM_{j,m} = \frac{\sum_{i}{P^{Empirical}_{(i,j,m)}}}{D_{j} \cdot M_{m}}
$$ {#eq-dm}
The denominator in @eq-dm is the expected popularity of the destination-month pair if destination and month popularities were independent.
If $DM_{j,m} > 1$, destination-month pair $(j,m)$ is more popular than expected under independence, while $DM_{j,m} < 1$ indicates the pair is less popular than expected.
Similarly, we account for the popularity of specific origin-destination pairs:
$$
OD_{i,j} = \frac{\sum_{m}{P^{Empirical}_{(i,j,m)}}}{O_{i} \cdot D_{j}}
$$ {#eq-od}
where $O_{i} = \sum_{j,m}{P^{Empirical}_{(i,j,m)}}$.
Same as @eq-dm, $OD_{i,j}$ measures how popular the origin-destination pair $(i,j)$ is than what would be expected if origin and destination popularities were independent.

We test the four popularity rescaling factors using the following multiplicative model:
$$
\frac{Flow_{(i,j,m)}^{LLM}}{Baseline_{(i,j,m)}} = 
(D_{j})^{\beta_1} \cdot 
(M_{m})^{\beta_2} \cdot 
(DM_{j,m})^{\beta_3} \cdot 
(OD_{i,j})^{\beta_4}
$$ {#eq-model}
Under the null hypotheses of no systematic bias, we expect all $\beta=0$. If $\beta>0$ for a factor, it positively rescales that factor's popularity in their suggestions; if $\beta<0$, it negatively rescales that factor's popularity.

@fig-beta-demo illustrate how different $\beta_2$ values (month popularity bias) rescales the distribution of monthly tourist share.
For example, if $\beta_2 = 1$, seasonal variation in tourist flow is amplified, whereas $\beta_2 = -1$ produces a uniform distribution across months.
This test is independet of destination-month popularity bias ($\beta_3 \ne 0$) because $DM_{j,m}$ measure popularities beyond independent popularities of destination and month.
Meaning, if we generate tourist flows with only the destination-month popularity bias ($\beta_3 \ne 0$), the resulting data would show no changes in overall destination or month popularity ($\beta_1 = 0, \beta_2 = 0$).

```{r} 
#| label: fig-beta-demo
#| fig-cap: Example of how different $\beta_2$ values affect distribution of monthly tourist share
#| fig-height: 5
df.beta.demo |> 
    mutate(
        case = factor(
            case,
            levels = c(
                "p.neg2",
                "p.neg1",
                "p",
                "p.pos1",
                "p.pos2"
            ),
            labels = c(
                "beta[2]==-2",
                "beta[2]==-1",
                "beta[2]==0",
                "beta[2]==1",
                "beta[2]==2"
            ),
            ordered = TRUE
        ),
    ) |>
    ggplot(aes(x = month, y = p)) +
    geom_bar(stat = "identity", fill = color.gemini) +
    scale_x_discrete(breaks = c("Jan", "Dec")) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    coord_cartesian(clip = "off") +
    facet_wrap( ~ case, ncol = 5, labeller = label_parsed) +
    theme(
        panel.spacing = unit(1.0, "lines"),
        panel.grid.major.x = element_blank(),
        plot.margin = margin(t = 10, r = 30, b =10, l = 10)
    ) +
    labs(
        title = "Positive β Amplifies Popularity, Negative β Suppresses and Inverts Popularity",
        x = "Month",
        y = "Share of total tourist flow",
    )
```

By taking the log of @eq-model, we can fit a regression model that tests the four popularity biases:
$$
\begin{aligned}
\ln Flow_{(i,j,m)}^{LLM} & = \ln Baseline_{(i,j,m)} \\
& + \beta_1 \cdot \ln D_{j} + \beta_2 \cdot \ln M_{m} + \beta_3 \cdot \ln DM_{j,m} + \beta_4 \cdot \ln OD_{i,j}
\end{aligned}
$$ {#eq-log-model}

## Hypotheses testing

The last step of the analysis is to combine simulation and empirical data to test hypothesized popularity biases.
We achieve this goal by fitting @eq-log-model using the Poisson count model. 
Essentially, the model explains variations in LLM-simulated tourist flows ($Flow_{(i,j,m)}^{LLM}$) beyond what can be expected by empirical data ($Baseline_{(i,j,m)}$), using the four popularity factors as predictors.
We chose the Poisson pseudo-maximum likelihood estimatior, which is widely used in estimating gravity models of trade and migration.
The Poisson pseudo-maximum likelihood estimator only requires the conditional mean to be correctly specified, without requiring a specific distributional assumption.
This estimator is robust to heteroskedasticity and having many zeros in the dependent variable, making the estimator suitable for our analysis [@silva2011].
Because we ran 1,000 iterations of simulations, we fit the model for each iteration then collect the result across iterations to assess the uncertainty in the effect estimates.

# Results

## Descriptive analysis

```{r}
#| label: intext-desc
max.advan <- round(df.sum |> filter(data.name == "Simulation: ADVAN Mobility Data", variable == "Tourist flow") |> pull(max))
max.nhts <- round(df.sum |> filter(data.name == "Simulation: National Household Travel Survey", variable == "Tourist flow") |> pull(max))
max.gemini <- round(df.sum |> filter(data.name == "Simulation: Gemini 2.5 Flash Lite", variable == "Tourist flow") |> pull(max))
max.gpt <- round(df.sum |> filter(data.name == "Simulation: GPT-4.1 Nano", variable == "Tourist flow") |> pull(max))
```

```{r}
#| label: tbl-desc
#| tbl-cap: Descriptive statistics of simulation and empirical data
df.sum |>
    mutate(
        variable = indent_row(variable)
    ) |>
    gt(groupname_col = "data.name") |>
    sub_small_vals(threshold = 0.001) |>
    fmt_number(decimals = 3) |>
    fmt_markdown(columns = notation, rows = TRUE) |>
    cols_align(
        align = "left",
        columns = variable
    ) |>
    cols_label(
        notation = "Notation",
        variable = "Variable",
        min = "Min",
        max = "Max",
        median = "Median",
        mean = "Mean",
        sd = "SD"
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote(
        md("Note: For *simulation* data, statistics are calculated over 1,000 iterations (N=31,212,000). Statistics for *empirical* data are based on a single destination-origin-month matrix (N=31,212).")
    )
```

```{r} 
#| label: tbl-any
#| tbl-cap: Agreement in presence of any tourist flow between large language model simulations and empirical-based simulations
t.any.gemini.advan <- df.any |>
    tbl_cross(
        row = gemini,
        col = advan,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")
 
t.any.gemini.nhts <- df.any |>
    tbl_cross(
        row = gemini,
        col = nhts,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gpt.advan <- df.any |>
    tbl_cross(
        row = gpt,
        col = advan,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gpt.nhts <- df.any |>
    tbl_cross(
        row = gpt,
        col = nhts,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gemini <- tbl_merge(
    list(t.any.gemini.advan, t.any.gemini.nhts ),
    tab_spanner = c(
        "*Simulation: ADVAN*",
        "*Simulation: NHTS*"
    )
) 
t.any.gpt <- tbl_merge(list(t.any.gpt.advan, t.any.gpt.nhts )) 

tbl_stack(
    list( t.any.gemini, t.any.gpt),
    group_header = c("Simulation: Gemini 2.5 Flash Lite", "Simulation: GPT-4.1 Nano"),
    ) |> 
    as_gt() |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote("Note: ADVAN=ADVAN Mobility Data, NHTS=National Household Travel Survey. Counts and percentages of destination-origin-month cells with no tourist flow in both simulations, any flow in either  simulation, or any flow in both simulations. Percentages are calculated based on number of possible destination-origin-month combinations (N=31,212). Based on one million simulated visits aggregated across all 1,000 iterations.")
```

```{r}
#| label: intext-any-prop
intext.any <- df.any |>
    mutate(
        only.gemini.advan = (gemini == "Any flow" & advan == "No flow"),
        only.gemini.nhts = (gemini == "Any flow" & nhts == "No flow"),
        only.gpt.advan = (gpt == "Any flow" & advan == "No flow"),
        only.gpt.nhts = (gpt == "Any flow" & nhts == "No flow"),
        only.advan.gemini = (advan == "Any flow" & gemini == "No flow"),
        only.nhts.gemini = (nhts == "Any flow" & gemini == "No flow"),
        only.advan.gpt = (advan == "Any flow" & gpt == "No flow"),
        only.nhts.gpt = (nhts == "Any flow" & gpt == "No flow")
    ) |>
    summarize(across(
        starts_with("only."),
        sum 
    )) / 31212
intext.any <- lapply(intext.any * 100, sprintf, fmt = "%.1f%%")
```


@tbl-desc presents descriptive statistics of simulation and empirical data.
The origin total outflow are closely matched across all simulations, as our simulated sample is stratified to reflect differences in population size across states.
The median tourist flow per destination-origin-month cell is 0 for all simulations, indicating that more than half of the cells have no tourist flow.
This sparsity is expected, given that each iteration assigns 1,000 tourists across 31,212 possible combinations (51 origins × 51 destinations × 12 months).
Thus, even if we randomly assign each of simulated tourists, only about 3.2% of destination-origin-month cells would have at least one tourist flow.
But the head of the distribution differs across simulations.
LLM simulations show higher concentration of tourist flows in the most popular destination-origin-month combination.
The maximum tourist flow across all cells and iterations is `{r} max.gemini` for Gemini 2.5 Flash Lite and `{r} max.gpt` for GPT-4.1 Nano, which are higher than two empirical-based simulations (`{r} max.advan` for ADVAN Mobility Data and `{r} max.nhts` for National Household Travel Survey).

Similar patterns emerge when examining presence of *any* tourist flow, without accounting for differences in number of tourists.
@tbl-any compares which destination-origin-month combinations are present or absent in LLM versus empirical simulations.
We aggregated the simulated visits across all 1,000 iterations to reduce the sparsity.
In all four comparisons, LLMs exclude many destination-origin-month combinations.
About `{r} intext.any$only.nhts.gpt` to `{r} intext.any$only.advan.gemini` of combinations never appeared in the LLM simulations, even though they were observed in the empirical data.
In contrast, LLMs rarely suggest destination-origin-month combinations that are absent in empirical-based simulations. 
For example, of 31,212 possible combinations of destination-origin-month, less than 10%
are “new” combinations that were not observed in the empirical data
Meaning, LLMs prune many empirically observed destination-origin-month combinations but rarely generate new ones.

```{r}
#| label: intext-dst
dst.gini.advan <- df.dst |> filter(data.name == "advan") |> pull(median.gini) |> first() |> pval_format()
dst.gini.nhts <- df.dst |> filter(data.name == "nhts") |> pull(median.gini) |> first() |> pval_format()
dst.gini.gemini <- df.dst |> filter(data.name == "gemini") |> pull(median.gini) |> first() |> pval_format()
dst.gini.gpt <- df.dst |> filter(data.name == "gpt") |> pull(median.gini) |> first() |> pval_format()
```

```{r}
#| label: plot-dst
#| include: false
bbox <- st_bbox(sf.states)
data_labeller <- as_labeller(
            c(
                "advan" = "ADVAN Mobility Data",
                "nhts" = "National Household Travel Survey",
                "gemini" = "Gemini 2.5 Flash Lite",
                "gpt" = "GPT-4.1 Nano"
            )
        )

df.dst.label <- df.dst |>
    group_by(data.name) |>
    summarize(median.gini = first(median.gini)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

p.dst <- df.dst |>
    ggplot() +
    geom_sf(
        aes(fill = median.sum.p, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Reds 2",
    ) +
    geom_sf_label(
        data = df.dst.label,
        aes(
            geometry = geometry,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Gini: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Are slightly more concentrated at popular destinations",
        fill = "Share of tourist flow (median over 1,000 iterations)",
        x = "",
        y = ""
    )
p.dst
```

```{r} 
#| label: intext-month-prop
month.gini.advan <- df.month |> filter(data.name == "advan") |> pull(median.gini) |> first() |> pval_format()
month.gini.nhts <- df.month |> filter(data.name == "nhts") |> pull(median.gini) |> first() |> pval_format()
month.gini.gemini <- df.month |> filter(data.name == "gemini") |> pull(median.gini) |> first() |> pval_format()
month.gini.gpt <- df.month |> filter(data.name == "gpt") |> pull(median.gini) |> first() |> pval_format()
```

```{r} 
#| label: plot-month
#| include: false
p.month <- df.month |>
    mutate(month = fct_rev(month)) |>
    ggplot() +
    geom_bar(
        aes(y = month, x = median.sum.p, fill = data.name),
        stat = "identity"
    ) +
    geom_label(
        data = df.month |>
            group_by(data.name) |>
            summarize(median.gini = first(median.gini)),
        aes(
            y = "Dec",
            x = 0.25,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Gini: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    # cheating my way to add y axis line for each facet
    geom_vline(xintercept = 0, lty = 1, color = "black") +
    scale_fill_manual(
        values = c(
            "advan" = color.advan,
            "nhts" = color.nhts,
            "gemini" = color.gemini,
            "gpt" = color.gpt
        )
    ) +
    scale_x_continuous(expand = expansion(mult = c(0.0, 0.1))) +
    scale_y_discrete(breaks = c("Jan", "Dec")) +
    coord_cartesian(clip = "off") +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    theme(
        axis.line.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.ticks.y = element_line(linewidth = 0.3),
        legend.position = "none"
    ) +
    labs(
        subtitle = "Are highly seasonal",
        x = "Share of tourist flow (median over 1,000 iterations)",
        y = "",
        fill = "Scenario"
    )
p.month 
```

```{r} 
#| label: plot-month-gini
#| include: false
df.gini.label <- df.month.gini |>
    group_by(data.name) |>
    summarize(median.gini = median(median.gini)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

# for in-text numbers
dst.month.gini.advan <- df.gini.label[1,2] |> pval_format()
dst.month.gini.nhts <- df.gini.label[2,2] |> pval_format()
dst.month.gini.gemini <- df.gini.label[3,2] |> pval_format()
dst.month.gini.gpt <- df.gini.label[4,2] |> pval_format()

p.month.gini <- df.month.gini |>
    ggplot() +
    geom_sf(
        aes(fill = median.gini, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Blues 2",
        rev = TRUE,
        limits = c(0, 1),
        breaks = seq(0, 1, by = 0.2)
    ) +
    geom_sf_label(
        data = df.gini.label,
        aes(
            geometry = geometry,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Median: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Destinations have higher seasonality in tourism demand",
        fill = "Gini coefficient (median over 1,000 iterations; higher values indicate greater inequality)",
        x = "",
        y = ""
    )
p.month.gini
```

```{r} 
#| label: plot-org-entropy
#| include: false
df.entropy.label <- df.org.entropy |>
    group_by(data.name) |>
    summarize(median.entropy = median(median.entropy)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

# for in-text numbers
dst.entropy.advan <- df.entropy.label[1,2] |> pval_format()
dst.entropy.nhts <- df.entropy.label[2,2] |> pval_format()
dst.entropy.gemini <- df.entropy.label[3,2] |> pval_format()
dst.entropy.gpt <- df.entropy.label[4,2] |> pval_format()

p.org.entropy <- df.org.entropy |>
    ggplot() +
    geom_sf(
        aes(fill = median.entropy, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Greens 2",
        limits = c(0.0, 3.0),
    ) +
    geom_sf_label(
        data = df.entropy.label,
        aes(
            geometry = geometry,
            label = median.entropy |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Median: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap( ~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Destinations have less diversified and balanced tourism demand",
        fill = "Entropy index (median over 1,000 iterations; higher values indicate more diversified and balanced demand)",
        x = "",
        y = ""
    )

p.org.entropy
```

```{r}
#| label: fig-prop
#| fig-cap: Characteristics of destination, month, destination-month, and origin-destination popularities across simulations
#| fig-width: 12
#| fig-height: 16 
(p.dst / p.month / p.month.gini / p.org.entropy) + 
    plot_annotation(
        title = "Large Language Models Produce More Unevenly Distributed Tourist Flows",
        subtitle = "Simulations using large language models tend to generate tourist flows that...",
        tag_levels = "a",
        tag_prefix = "(", tag_suffix = ")"
    ) & 
    theme(
        plot.tag = element_text(size = 20, face = "bold")
    )
```

We further examine differences in distribution of tourist flow across simulations by looking at the four popularity factors.
Results are summarized by taking the median across 1,000 iterations.
Mathematical definitions of the metrics are available in @apx-eq.
First, we examine distribution of tourist share by destination states ($D_j$) and months ($M_m$).
We use the Gini index to quantify the inequality in these distributions, where a higher Gini index indicates greater concentration of tourist share among fewer states or months.
In all four simulations, tourist visits concentrate in a few popular states, such as California, Florida, and Texas (@fig-prop[a]()).
LLM simulations show higher Gini indices than empirical-based simulations, indicating greater inequality in tourist arrivals across states (ADVAN Mobility Data=`r dst.gini.advan` and National Household Travel Survey=`r dst.gini.nhts`; Gemini 2.5 Flash Lite=`r dst.gini.gemini` and GPT-4.1 Nano=`r dst.gini.gpt`).

Seasonal patterns are also more pronounced in the LLM outputs than in the empirical-based simulations with substantially high Gini indices across months (@fig-prop[b]()).
This level of seasonality exceeds that of the two empirical-based simulations (Gemini 2.5 Flash Lite=`r month.gini.gemini` and GPT-4.1 Nano=`r month.gini.gpt`; ADVAN Mobility Data=`r month.gini.advan` and National Household Travel Survey=`r month.gini.nhts`).
Although, the two LLMs differ in peak tourism months.
Gemini 2.5 Flash Lite shows a clear peak during September and October, with more than half of all simulated tourist arrivals concentrated in these two months.
GPT-4.1 Nano shows peaks in April, May, and September.
LLMs worsen the seasonality of tourism demand even at the destination level.
In @fig-prop[c](), we calculated Gini index of monthly tourist share for each destination state and took the median over 1,000 iterations.
Few states show relatively high seasonality in the empirical-based simulations, such as Alaska and Hawaii.
Contrarily, most states exhibit high seasonality in the LLM simulation, indicated by overall higher Gini indices across all destinations (Median of medians=`r dst.month.gini.advan` and `r dst.month.gini.nhts` for ADVAN Mobility Data and National Household Travel Survey; `r dst.month.gini.gemini` and `r dst.month.gini.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).

@fig-prop[d]() shows that LLMs have tendency to generate travel suggestions that destinations rely on a few origins.
We use entropy index for measuring how diversified and balanced the demand for destinations is.
Although Gini index can be used, it does not effectively capture whether destination states receive tourists from a diverse set of origin states or rely on a few.
The empirical simulations show that states such as Florida, Illinois, and North Carolina tend to have diversified and balanced demand (higher entropy).
For the two AI-simulated tourist flows, the entropy indices are overall lower than those of empirical-based simulations (Median of medians = `r dst.entropy.advan` and `r dst.entropy.nhts` for ADVAN Mobility Data and National Household Travel Survey; `r dst.entropy.gemini` and `r dst.entropy.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).
We also observe that fewer states exhibit relatively high entropy values in the LLM simulations.
Such demand characteristics indicate that LLM produce a less resilient tourism sector, as less diversity of tourist origins and higher reliance on a few origin markets undermines resilience to shocks [@lee2025c].

```{r} 
#| label: intext-graph-stats
df.graph.sum <- df.graph |>
    group_by(stat, data.name) |>
    summarize(
        median.value = median(value)
    )
# reciprocity
recip.advan <- df.graph.sum[1,3] |> pval_format()
recip.nhts <- df.graph.sum[2,3] |> pval_format()
recip.gemini <- df.graph.sum[3,3] |> pval_format()
recip.gpt <- df.graph.sum[4,3] |> pval_format()
# median travel distance
mdist.advan <- df.graph.sum[5,3] |> round()
mdist.nhts <- df.graph.sum[6,3] |> round()
mdist.gemini <- df.graph.sum[7,3] |> round()
mdist.gpt <- df.graph.sum[8,3] |> round()
# border ratio
br.advan <- df.graph.sum[9,3] |> pval_format()
br.nhts <- df.graph.sum[10,3] |> pval_format()
br.gemini <- df.graph.sum[11,3] |> pval_format()
br.gpt <- df.graph.sum[12,3] |> pval_format()
# self-loop ratio
sl.advan <- df.graph.sum[13,3] |> pval_format()
sl.nhts <- df.graph.sum[14,3] |> pval_format()
sl.gemini <- df.graph.sum[15,3] |> pval_format()
sl.gpt <- df.graph.sum[16,3] |> pval_format()
```

```{r} 
#| label: fig-graph-stats
#| fig-cap: Characteristics of tourist flow structure across simulations
#| fig-height: 10
df.graph |>
    mutate(
        data.name = fct_rev(data.name) 
    ) |>
    ggplot(aes(x = value, y = data.name, fill = data.name)) +
    geom_vline(
        data = df.graph.rand |>
            group_by(stat) |>
            summarize(value = median(value)),
        aes(xintercept = value),
        linetype = "dashed",
        linewidth = 0.7,
        color = "red",
    ) +
    geom_boxplot(
        alpha = 0.8,
        width = 0.6,
        linewidth = 0.3,
        outlier.shape=1,
    ) +
    scale_fill_manual(
        values = c(
            "ADVAN Mobility Data" = color.advan,
            "National Household Travel Survey" = color.nhts,
            "Gemini 2.5 Flash Lite" = color.gemini,
            "GPT-4.1 Nano" = color.gpt
        )
    ) +
    facet_wrap( ~ stat, ncol = 1, scales = "free_x", strip.position = "bottom") +
    expand_limits(x = 0) +
    theme(
        strip.text = element_text(face = "plain"),
        strip.placement = "outside",
        axis.ticks.y = element_line(linewidth = 0.3),
        axis.text.y = element_text(face = "italic"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5),
        panel.grid.major.y = element_blank(),
        panel.spacing = unit(2.0, "lines"),
        legend.position = "none",
        plot.margin = margin(t = 10, r = 60, b = 10, l = 10)
    ) +
    labs(
        title = "Generative AI Produce Structurally Different Tourist Flows",
        subtitle = "Large language model-generated tourist flows exhibit lower reciprocity and fewer trips to bordering states",
        caption = "Note. Dashed red line indicates what would be expected if destination-origin-month combinations are completely random (uniform probability).",
        x = "",
        y = "",
    )
```

Additionally, we analyze the overall structure of tourist flows.
We constructed an origin-destination matrix by aggregating tourist numbers at the year level.
Then we computed four statistics capturing how the global structure of tourist flows differ across simulations.
Box-plots in @fig-graph-stats present the distribution of the four network-level statistics across 1,000 iterations, colored by simulation scenario.
The dotted red line indicates what can be expected by chance alone, if there is no structure in tourist flow.
This expectation under complete randomness is calculated by assuming that each individual has equal probability of choosing a destination (a probability of $1/51$).

LLMs produce tourist flows with a clear separation between states that send tourists and those that receive them, as indicated by lower reciprocity of the origin-destination network.
Reciprocity refers to the tendency to form mutual relationships—in our case, two states exchanging a similar number of tourists.
Empirical-based simulations show higher levels of reciprocity than the random expectation (Median = `r recip.advan` and `r recip.nhts` for ADVAN Mobility Data and National Household Travel Survey).
However, LLM simulations show lower levels of reciprocity than expected by chance (Median = `r recip.gemini` and `r recip.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).

Gemini 2.5 Flash Lite and GPT-4.1 Nano tend to suggest farther destinations than empirical data, based on median travel distance excluding in-state trips (Median of medians = `r mdist.gemini` and `r mdist.gpt`).
This tendency is partially due to LLMs' lower propensity to suggest trips to bordering states.
Gemini 2.5 Flash Lite has lower ratio of tourist flows between bordering states than the empirical models (Median = `r br.gemini`).
GPT-4.1 Nano shows even lower tendency to suggest bordering states, lower that what would be expected under randomness (Median = `r br.gpt`).
But the two models exhibit substantial difference in tendency to suggest in-state tourism.
Gemini 2.5 Flash Lite shows ratio of in-state trips comparable to the empirical models (Median = `r sl.gemini`).
In contrast, GPT-4.1 Nano shows much stronger preference for recommending tourist to travel within their own state (Median = `r sl.gpt`).

## Model estimation results

```{r} 
#| label: intext-betas
# d coeffs
b.d.gemini.advan <- betas.sum[1, 4] |> sprintf(fmt = "%4.3f")
b.d.gemini.nhts <- betas.sum[5, 4] |> sprintf(fmt = "%4.3f")
b.d.gpt.advan <- betas.sum[9, 4] |> sprintf(fmt = "%4.3f")
b.d.gpt.nhts <- betas.sum[13, 4] |> sprintf(fmt = "%4.3f")

# m coeffs
b.m.gemini.advan <- betas.sum[2, 4] |> sprintf(fmt = "%4.3f")
b.m.gemini.nhts <- betas.sum[6, 4] |> sprintf(fmt = "%4.3f")
b.m.gpt.advan <- betas.sum[10, 4] |> sprintf(fmt = "%4.3f")
b.m.gpt.nhts <- betas.sum[14, 4] |> sprintf(fmt = "%4.3f")

# dm coeffs
b.dm.gemini.advan <- betas.sum[3, 4] |> sprintf(fmt = "%4.3f")
b.dm.gemini.nhts <- betas.sum[7, 4] |> sprintf(fmt = "%4.3f")
b.dm.gpt.advan <- betas.sum[11, 4] |> sprintf(fmt = "%4.3f")
b.dm.gpt.nhts <- betas.sum[15, 4] |> sprintf(fmt = "%4.3f")

# od coeffs
b.od.gemini.advan <- betas.sum[4, 4] |> sprintf(fmt = "%4.3f")
b.od.gemini.nhts <- betas.sum[8, 4] |> sprintf(fmt = "%4.3f")
b.od.gpt.advan <- betas.sum[12, 4] |> sprintf(fmt = "%4.3f")
b.od.gpt.nhts <- betas.sum[16, 4] |> sprintf(fmt = "%4.3f")
```

@tbl-betas and @fig-betas summarizes the estimated effects of the four popularity biases on LLM-simulated tourist flows (@eq-log-model).
Across two LLMs and two empirical baselines, destination-month popularity consistently has the largest positive coefficient.
Meaning, LLMs show a tendency to favor popular destination-month combinations when generating travel recommendations.
Although, 95% credible intervals indicates high uncertaintay around the estimates for Gemini 2.5 Flash Lite with both empirical baselines. 
The coefficients can be interpreted as elasticity.
For example, GPT-4.1 Nano with ADVAN Mobility Data baseline had a median coefficient of `r b.dm.gpt.advan` for destination-month popularity.
If real-world data shows that a particular destination-month combination is twice as popular than what is expected under independence of destination and month popularity ($DM_{(j,m)} = 2$), then the expected tourist flow generated by GPT-4.1 Nano for that combination is approximately `r round(2 ** as.numeric(b.dm.gpt.advan), 1)` times higher ($2^{1.771}$), holding other factors constant.

We find mixed results for the rest of the popularity biases.
Some effects are specific to the LLM.
For example, Gemini 2.5 Flash Lite consistently shows negative coefficients for destination popularity, indicating that it tends to negatively rescale popular destinations (Median $\beta_{1}$ = `r b.d.gemini.advan` and `r b.d.gemini.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).
The same pattern is only observed for GPT-4.1 Nano with National Household Travel Survey baseline (Median $\beta_{1}$ = `r b.d.gpt.nhts`) but not with ADVAN Mobility Data baseline (Median $\beta_{1}$ = `r b.d.gpt.advan`).
GPT-4.1 Nano with shows positive rescaling for origin-destination popularity (Median $\beta_{4}$ = `r b.od.gpt.advan` and `r b.od.gpt.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines), while Gemini 2.5 Flash Lite shows mixed findings (Median $\beta_{4}$ = `r b.od.gemini.advan` and `r b.od.gemini.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).

Finally, we note that the month popularity coefficients are negative for GPT-4.1 Nano (Median $\beta_{2}$ = `r b.m.gpt.advan` and `r b.m.gpt.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).
This result is contradictory, given prior descriptive analysis indicated GPT-4.1 Nano having greater seasonality.
One possible explanation is that peak months in GPT-4.1 Nano simulations poorly align with those in empirical data (see @fig-prop[b]()).
Therefore, the model attempts to fit the month popularity factor by flattening the empirical month popularity distribution.

```{r}
#| label: tbl-betas
#| tbl-cap: Median and 95% credible intervals of Poisson model coefficients across 1,000 iterations
betas.sum |> 
    pivot_wider(names_from = emp, values_from = c(median.coeff, lower.ci, upper.ci)) |>
    relocate(ends_with("_ADVAN"), .after = param) |>
    mutate(
        param = factor(
            param,
            levels = levels(param),
            labels = md(
                c(
                "$\\beta_{1}$: Destination",
                "$\\beta_{2}$: Month",
                "$\\beta_{3}$: Destination-Month",
                "$\\beta_{4}$: Origin-Destination"
                )
            )
        ),
        sim = paste("Simulation:", sim)
    ) |>
    mutate(param = indent_row(param)) |>
    gt(groupname_col = "sim") |>
    tab_spanner(
        label = html("Empirical: ADVAN"),
        columns = ends_with("_ADVAN")
    ) |>
    tab_spanner(
        label = html("Empirical: NHTS"),
        columns = ends_with("_NHTS")
    ) |>
    fmt_number(decimals = 3) |>
    fmt_markdown(columns = param, rows = TRUE) |>
    cols_align(
        align="left",
        columns = param
    ) |>
    cols_label(
        param = "",
        starts_with("median.coeff") ~ "Median",
        starts_with("lower.ci") ~ "2.5%",
        starts_with("upper.ci") ~ "97.5%",
    ) |>
    # italicize sim & emp names
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_column_spanners()
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote(
        md("Note: ADVAN=ADVAN Mobility Data, NHTS=National Household Travel Survey. Summary of Poisson model results over 1,000 iterations.")
    )
```

```{r} 
#| label: fig-betas
#| fig-cap: Summary of popularity effect estimates across 1,000 iterations
text.beta <- data.frame(
    median.coeff = c(0, 0),
    param = c(4, 4),
    emp = c("ADVAN", "ADVAN"),
    sim = c("GPT-4.1 Nano", "GPT-4.1 Nano"),
    label = c("***Negative rescaling*** ←", "→ ***Positive rescaling***")
)

p.betas <- draw_beta_fig(betas.sum) +
    scale_shape_manual(
        values = c("Gemini 2.5 Flash Lite" = 20, "GPT-4.1 Nano" = 18)
    ) +
    scale_color_manual(
        values = c("Gemini 2.5 Flash Lite" = color.gemini, "GPT-4.1 Nano" = color.gpt)
    ) +
    # annotate attenuation (B<0) and amplification (B>0)
    geom_richtext(
        data = text.beta,
        label = text.beta$label,
        color = "black",
        fill = NA, label.color = NA,
        vjust = -2,
        hjust = c(1.1, -0.1),
        size = 4,
    ) +
    labs(
        title = "Generative AI Amplify Popularity of Destination-Month Pairs",
        subtitle = "Other popularity factors are dependent on specific large language model used and show mixed results",
        caption = "Note: Summary of Poisson model results over 1,000 iterations. Error bars represent 95% credible intervals for the estimates.",
    )
p.betas
```

## Robustness checks

We conducted following robustness checks to test the sensitivity of our findings to different simulation choices (reported in @apx-robust).
These additional simulations were performed with the first 100 iterations due to budget and computing time constraints.
First, using alternative prompts does not substantially change the main findings.
Large language model outputs are sensitive to the specific prompts used.
Hence, we collected additional simulation data using slightly modified prompts (see @apx-prompt).
One version excluded explicit instruction that demographic factors influence tourist choices ("reduced instruction" prompt).
Another version instructed the models to act as *tourists* choosing destinations instead of travel agents giving suggestions ("tourist persona" prompt).
None of these alterations substantially changed the main findings (@fig-prompt-betas).
One notable exception is that Gemini 2.5 Flash Lite with reduced instruction prompt showed negative coefficients for month popularity.
However, this case also showed stronger effects for destination-month and origin-destination popularity than using the original prompt.

Changing the temperature parameter also does not alter the results.
The temperature parameter controls randomness in LLM outputs.
Higher temperature setting produce more diverse outputs, while lower temperature setting generate more deterministic outputs.
The default temperature setting used in our main analysis is 1.0.
We collected additional data using temepratures of 0.5 and 1.5 (@fig-temp-betas).
GPT-4.1 Nano with temperature of 1.5 could not generate valid outputs and hence was excluded.
Similiar to @bai2025, we find that temperature setting has minimal impact on the popularity bias of LLMs.

Larger models in the Gemini 2.5 and GPT-4.1 series, as well as models from other providers, still show positive destination-month popularity bias.
We repeated the main analysis with larger variants of Gemini 2.5 and GPT-4.1 series models (Gemini 2.5 Flash and GPT-4.1 Mini).
Additionally, we collected data using xAI's Grok 3 Mini and Meta's Llama 4 Scout to examine whether the findings are generalizable beyond OpenAI and Google models.
Across all models tested, destination-month popularity shows strongest positive effects (@fig-model-betas).
than the models used in our main analysis, larger models show stronger destination-month popularity bias, not weaker.

Finally, the results are unchanged when aggregating data across all iterations instead of fitting Poisson regression models for each iteration separately.
We conducted alternative hypothesis tests by aggregating the simulation data across all 1,000 iterations and fitting a single Poisson regression model for each LLM simulation.
This approach significantly reduces the number of destination-origin-month cells with zero tourist counts.
We can also obtain significance levels for the estimated coefficients using  traditional frequentist tests.
Still, coefficient estimates using aggregated data are nearly identical to median estimates from our main approach (see @tbl-agg-betas).

# Discussions

We provide empirical evidence on how generative AI diverges from empirical tourism patterns and what underlying mechanisms drive such differences.
Such generative AI models are complex and opaque.
But so are humans.
Tourists are complex decision-makers influenced by myriad factors, many of which are not fully understood.
Same as how social scientists study human cognitive bases based on their behaviors, we proposed a model for testing hypothesized mechanisms behind generative AI biases.
Beyond quantifying the difference between algorithm outcomes and emprically-grounded baselines, our model allowed us to obtain interpretable results on what factors drive such differences.

## Key findings

LLMs generate less diverse and more unevenly distributed tourist flows than empirical US domestic tourism patterns.
States show slightly more unequal levels of tourist arrivals, with popular states continuing to be popular in LLM simulations (@fig-prop[a]()).
More concerning issue is that both models produce highly seasonal tourism patterns.
While seasonality is common feature of tourism [@butler1994; @duro2016], these algorithms show much sharper peaks and troughs than empirical data (@fig-prop[b]()).
This finding is alarming for *all* US destinations, as both popular and less popular states show greater seasonality in tourist arrivals (@fig-prop[c]()).
Destinations also become more reliant on a few tourist origins in LLM simulations (@fig-prop[d]()).

The models also produce structurally different tourist flows (@fig-graph-stats).
They produce less reciprocal tourist flows where popular destinations would receive more tourists but send fewer to others, leading to a more "one-way" tourism system.
While these models also tend to recommend traveling to farther destinations, other spatial patterns differ between the two LLMs.
GPT-4.1 Nano shows much stronger avoidance for bordering states and favors in-state tourism.
Tendency to avoid bordering states is not as severe in Gemini 2.5 Flash Lite, while showing prevalence of in-state tourism similar to empirical baseline.
Biases in spatial perception of these models is one possible explanation, such as overestimating inter-regional distance while underestimating intra-regional distance [@fulman2024].
Given that these algorithms are *language* models, they may also reflect linguistic and cultural representations of what is meant by tourism [see @resnik2025; @tao2024].

LLMs favor visiting destinations during their peak months (@fig-betas).
We find consistent evidence of this positive destination-month popularity bias, across three different prompts, three temperature settings, and six LLMs (@apx-robust).
Findings are mixed for the other three popularity biases.
For example, the two GPT-4.1 family of models also show bias toward popular origin-destination pairs, while aother models attenuate empirically popular destinations.
The results mostly vary by LLM used, rather than alternative specifications for simulations or empirical baselines.
Unfortunately, this study could not identify why the models show different types and degree of popularity biases.
We can only speculate that the differences arise from variations in training data, model architectures, and human feedback [@santurkar2023].
These biases also arise from feedback loops where human biases seep into training data, producing biased models that in turn influence human behavior [@chen2023d].
Understanding and mitigating these biases will therefore require greater transparency from developers of generative AI about training processes and data sources.

## Theoretical implications

This study provides early empirical evidence that generative AI poses significant potential to undermine sustainability and resilience of tourism sector.
While we are seeing generative AI increasingly affecting decisions of tourists and pracitioners, what this entails for stakeholders in the tourism system reamined unclear.
Hence, understanding generative AI's downstream consequences is an urgent real-world issue where tourism research can directly impact society [@li2026].

Our findings substantiate prior concerns that these algorithms could introduce biases that exacerbate ethical and social issues in tourism [@law2025; @lehto2025; @mellors2025].
We show that such biases not only have ethical implications but also practical consequences for destinations that rely on tourism.
Generative AI models provide travel suggestions that worsen seasonality of tourism, reduce diversity of demand origins, and reduce bi-directional exchange of tourists among regions.
All these patterns go against conditions for fostering sustainable and resilient tourism sector [for example, @cisneros-martinez2018; @lee2025c; @wttc2022].
Thus, we echo the previous cautions that technology adoptions in tourism should not be seen as *progress* or *advancements*; rather, they are *changes* that we must carelly assess their broad implications [@tribe2017].

The proposed Baseline-Rescaling-Outcome Model contribute to existing literature on AI bias metrics by offering an interpretable framework for testing algorithmic bises.
The existing methods often required access to internal model parameters and could mainly tell whether biases exists [@bai2025; @chen2023d].
Our approach further allows testing multiple hypothesized mechanisms that could amplify or attenuate empirical patterns, thereby explaining why we observed divergence from empirical data.
While these explanations are still correlational rather than causal, they are basis for unraveling systemic mechanisms behind the black-box algorithms.

This study focused on measuring bias in genreative AI from supplier-side and its implications for destinations.
However, bias and their consequences can also be studied from both demand-side, focusing on whether *tourists* are exposed to personalized and diverse travel options.
For instance, recommendation algorithm with popularity biase from supply-side can also lead to users receiving less satisfying options [@abdollahpouri2020].
Similarly, casues of these biases can also be spectulated from both demand- and supply-side.
These biases may arises from learning to reflect popular tourist behvaviors (demand-side) or content from popular destinations with more marketing resources being more prevalent in training data (supply-side).

Our LLM simulations are projections wherein all tourists’ decisions are made by generative AI.
We use such hypothetical scenario to *project* how generative AI might reshape tourist flows, enabling us to anticipate consequences rather than document them *a posteriori*.
Currently, empirical phenomena of generative AI adoption outpace tourism knowledge production, due to generative AI's rapid evolution and academic publication delays.
But we also need an alternative route: *a priori* knowledge production by tourism scholars that informs decision-making in tourism practice.
Such guiding knowledge will prove crucial for tourism scholarship and practitioners to ensure sustainable and resilient tourism systems amid rapid technological changes.

## Methodological contributions

This study pioneers large-scale, empirically grounded generative AI simulations for tourism research.
We ensure representativeness of the simulations by using real-world demographic profiles.
In contrast, prior studies either used hypothetical tourists or faield to specify what tourists the AI needs to simulate [for example @andreev2025; @xiong2024].
By running 1,000 iterations of simulations with varied samples of demographic profiles, we caputre stochasticity in generative AI outputs instead of relying on a single run [for example @andreev2025;@mellors2025].
Tourism is a complex system, where the outcomes are probabilistic rather than deterministic [@faulkner2003].
As such, our approach acknowledges that even the empirical data is one of many possible outcomes.
By creating simulated realizations of the tourism patterns under empirical-driven and AI-driven scenarios, we can better project the range of possible outcomes and identify which observed patterns constitute robust features versus artifacts of stochastic variation.
We provide all code and synthetic data from the simulations for replicating and extending our analyses.
This includes the full dataset of two millon individual-level travel suggestions from two main LLMs and additional one million obtaind for robustness checks.

Based on the findings, we question relability of using AI-generated synthetic data even for exploratory and early-stage research purposes [suggested by @ali2025; @viglia2024a].
Despite our efforts to ensure representativeness and robustness of simulations, LLMs still produced tourism patterns that diverge substantially from empirical data.
@santurkar2023 also show that generative AI poorly represent both general public and particular subpopulation even when steered to do so.
Because our purpose is to examine the biases in generative AI, such divergences are informative.
However, if researchers use AI-generated synthetic data for a pilot study, the results may mislead future research directions.
As these algorithms behave in more extreme and different ways than real-world tourists, we must caution synthetic data *limiting* tourism knowledge development rather than advancing it.

## Practical implications

Our perspective is that generative AI has benefits for tourism sectors but we also need to weigh its potential risks.
It can be used as a tool for tourists to efficiently seek travel information, practitionrs to guide their decisions, and destinations to get ideas for improving their tourism experiences [@dogru2025].
Nevertheless, these benefits are not without costs; they also introducing new issues to tourism system.
Therefore, we urge tourism practitioners and regulators to monitor and prepare for generative AI’s potential impacts on tourist behavior and destination choice.

Lesser-known destinations are particularly vulnurable.
Generative AI models train on extensive cross-domain datasets, making their outputs difficult to alter.
Addressing such challenges would require efforts from both regulators and tourism intermediaries to ensure equitable and diverse representation of destinations.
For example, EU AI Act mandates bias testing for high-risk AI systems, such as credit scoring and employment screening [@vanbekkum2025].
Tourism sector could also advocate for simliar legislation for auditing biases.
Such bias audits would needed for both tourist- and employee-facing generative AI applications.
We urge already-popular destinations to advocate such policy, negative comsequences like worsend seasonality and reduced demand diversity equally affect them.
More simple interventions could be implemented by tourism intermediaries, such as putting a disclosure that "AI-generated suggestions may overrepresent popular options" and stratifying options before producing AI-generated options.

We call for national and international tourism organizations begin assessing implications of generative AI adoption, including potential ethical and social consequences that were not examined in this study.
Organizations must recognize that tourism functions not merely as a "market offering" but as a societal force affecting people and communities [@higgins-desbiolles2006].
For example, one social benefit of tourism is that it provides experiences and opportunities for socially excluded groups [@mccabe2020a].
These benefits may diminish if generative AI limits travel options for particular demographic groups.
While we caution generative AI's potential consequences for tourism, the time is right to proactively shape the future of tourism before generative AI is further integrated into tourism industries.
Our projected generative AI-driven tourism is still hypothetical; it is up to us whether such a future may never come to pass.

## Limitations and future research

Consider the following key limitations when interpreting our findings.
The results are subject to the modifiable areal unit problem  [@fotheringham1991].
LLMs recommended destinations in varying geographic units, which we aggregated to the state level for analyses.
This aggregation masks variations at finer geographic scales, thus likely underestimates the differences between the empirical and generative AI-driven simulations.

Our LLM simulations rely solely on demographic factors and exclude psychological, behavioral, and social factors that shape tourist decisions.
One of which is tourist motivation.
Even if two individuals with an identical demographic profile visited the same destination, they could have entirely different motivations for visiting.
Future research could consider specifying preferences and motivations for each simulated tourist [see @gao2024].
In addition, simulations could incorporate different rates of accepting AI-generated recommendations for more realistic projections.
For instance, younger individuals are generally more inclined to accept generative AI recommendations than older individuals [@seyfi2025], which could result in different travel patterns than those observed in our "extreme-case" scenarios.

The simulations assumed that everyone travels and selects a single destination.
But we must consider that there are non-travelers who choose not to travel and tourists visiting multiple destinations during a single trip [@haukeland1990; @yang2013].
One tourist's decision can also influence the decisions of others [@lee2025a], although our simulations do not account for interactions between simulated individuals.
Our simulation also assumed scenario where *all* destination choices are made by generative AI.
Future research could explore scenarios where acceptance rates of generative AI recommendations vary across different demographic groups.
Such analysis would reveal whether outcomes of generative AI biases scale linearly or require a critical mass of adoption for substantial impacts.

Further, studies show that generative AI exhibits stonger bias when decisions are relative rather than absolute [@bai2025].
Since we instructed the model to recommend a single destination instead of chosing one among given options, the degree of popularity bias shown in this study may be conservative.
However, decisions of real-world tourists also are significantly affected by how and what choices are presented [@kim2025c].
For future research examining generative AI models' biases in relative decision-making, we recommend conducting both empricial expriments and AI-driven simulations.

Future research could refine how popularity biases are measured.
For example, popularity bias may be non-linear where destinations with popularity under certain threshold receive no recommendations at all.
We also note that our biase estimates are less reliable when the peaks of empirical and generative AI-driven tourism patterns poorly align.
Further extensions could consider including alternative model terms that account for such shifts in rank orders of options.
Fianally, we recommend applying our model to other types of biases and algorithms.
As tourism and hospitality firms are adopting generative AI for consumer and employee-facing applications, examining socio-demographic biases would be crucial for ensuring ethical and fair integration of generative AI.

# Data availability

The data and code for reproducing the results are available at [https://github.com/jinvim/genai-tourism-bias](https://github.com/jinvim/genai-tourism-bias).


::: {#refs}
:::

{{< pagebreak >}}

{{< include appendix.qmd >}}