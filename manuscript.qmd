```{r} 
#| label: setup
#| include: false
library(tidyverse)
library(arrow)
library(sf)
library(colorspace)
library(gt)
library(gtsummary)
library(ggtext)
library(glue)
library(patchwork)
library(broom)
```

```{r} 
#| label: load-functions
# load custom functions and theme
source("r/helpers.r")
source("r/theme.r")
theme_set(theme_myriad())

color.rand <- "#777777"
color.nhts <- "#af9da6"
color.advan <- "#c4b4a1"
color.gemini <- "#214e7b"
color.gpt <- "#ff7f05"
```

```{r} 
#| label: read-data
#| include: false
source("r/data.r")
```

::: {.content-visible when-format="docx"}

# Highlights

- Quantifies generative AI’s potential impact on US domestic tourist flows
- Proposes the Baseline-Rescaling-Outcome Model for testing algorithmic biases
- Large language models produce more seasonal and unequally distributed tourist flows
- The models exhibit a popularity bias that favors popular destination-month pairs
- Calls for assessing generative AI biases and their consequences in tourism

:::

# Introduction

Generative AI has moved quickly from novelty to an everyday tool.
People use these algorithms as always-ready collaborators that support tasks ranging from sending emails to critical business decisions [@marr2023].
Tourism is no exception.
Most travelers already use generative AI for travel planning, and major travel intermediaries like Expedia and TripAdvisor have integrated these algorithms into their platforms [@booking.com2025; @tripadvisor2023;@expedia2023].
Beyond travel planning, generative AI support core operations in tourism industries, including marketing, human resource management, and tourism experience design [@amadeus2024; @dogru2025].

Despite widespread adoption of generative AI in tourism, empirical evidence on its impacts is scarce [@hsu2024; @mellors2025].
Major concerns include ethical and cultural biases in these algorithms [@ali2025; @law2025].
As more tourists and practitioners rely on generative AI, algorithmic biases may drive behavioral shifts that reproduce or amplify existing societal issues [@kordzadeh2022; @vicente2023].
However, these algorithms are often proprietary and lack interpretability, impeding the detection of biases [@bai2025; @gallegos2024]. 

This study investigates how the rapid adoption of generative AI and its algorithmic biases can reshape tourism patterns.
We develop the *Baseline-Rescaling-Outcome Model* that can test algorithmic biases using empirical expectations, hypothesized bias mechanisms, and algorithmic outcomes.
Using demographic profiles from the US Census Bureau, we created a simulated sample of one million US residents.
Large language models (LLMs) then recommended one domestic travel destination per individual.
We explain deviations between AI-generated and empirical US domestic tourism patterns as systematic *biases* favoring popular options and pairs of options.

Compared to empirical tourism patterns, LLMs yield less diverse tourist flows concentrated in specific combinations of destination, origin, and month.
They also produce more unevenly distributed tourist flows with stronger seasonality and less diversified demand.
The models favor visiting destinations during their peak seasons, indicating amplification of destination-month popularity.
However, tested models vary in the strength and direction of other popularity biases.
The findings provide early empirical evidence that generative AI may undermine the sustainability and resilience of the tourism sector.

# Background

## Generative AI and its impacts on tourism

This study focuses on generative AI and its implications for tourism.
The term AI encompasses various technologies designed to simulate human intelligence. 
Generative AI is an algorithm that learns patterns from large datasets to generate text, images, or video content [@li2025].
When addressing generative AI in general, we avoid usage-specific terms like *chatbots* or brand-specific terms like *ChatGPT*.

Limited empirical evidence exists on how and to what extent generative AI will affect tourism [@hsu2024; @mellors2025].
Although tourism and hospitality literature on generative AI is growing, they primarily examine adoption behaviors: who, when, and why tourists and practitioners adopt generative AI [see recent reviews by @gossling2025; @li2025].
Some preliminary works highlight benefits of generative AI to businesses and tourists.
Announcing generative AI integration gave tourism firms competitive advantages in market value [@jung2026].
Additionally, underperforming businesses can improve revenue by using generative AI for product marketing [@fan2025].
For tourists, generative AI reduces cognitive load during travel planning, thereby increasing visit intentions and decision satisfaction [@shin2025].

However, others caution negative impacts of generative AI on tourism [@law2025; @lehto2025].
Few studies examine how generative AI has biases that favor mainstream tourism patterns [@andreev2025; @mellors2025].
Such biases can shape behaviors of generative AI users, leading to real-world impacts that reproduce or amplify existing biases in society [@kordzadeh2022; @vicente2023].
These preliminary findings echo standing debates about how technologies---from search engines to social media---have both benefited and harmed tourism [@gong2024a; @leung2013].

## Challenges of defining and measuring biases in generative AI

Both conceptual and empirical tourism studies frequently raise concerns about biases in generative AI.
A particularly prominent focus is on social biases and their ethical implications.
For example, @law2025 identify ethical risks associated with AI adoption in tourism and hospitality sectors, urging more inclusive practices to mitigate "biased and discriminatory actions" (p.287).
@hsu2024 note that generative AI "could perpetuate stereotypes and result in discrimination" (p.2), proposing generative AI fine-tuned for tourism.
@viglia2024a caution against biases in AI-generated tourism data, giving a specific example of AI generating racist content.
This trend aligns with broader literature on algorithmic biases that emphasize ethical challenges, especially racism and stereotypes [see @ghosh2025; @kordzadeh2022].
Beyond ethical concerns, several scholars note risks of a popularity bias in generative AI, where algorithms favor popular options and underrepresent unpopular ones [@law2024; @lehto2025].
This bias poses practical concerns for the tourism sector, as it can intensify over-tourism at popular destinations while damaging tourism sectors at less popular destinations [@mellors2025].

Two key challenges complicate the analysis of generative AI biases: definition and measurement.
What constitutes "biased" algorithms is often vague in tourism and hospitality studies.
This issue is not unique to tourism scholarship; broader AI bias literature has also been criticized for lacking an explicit definition of bias [@ghosh2025].
Even regulatory frameworks, like the EU AI Act, often leave bias undefined [@vanbekkum2025].
Such ambiguity creates discrepancies between the concerns raised and the empirical evidence provided [@blodgett2020].

Algorithmic bias has no single definition.
When the focus is on stereotyping, studies define bias as the *act of* unjustified association between social groups and attributes [@bai2025].
This definition follows social psychology literature on implicit associations [@greenwald1998].
Studies examining ethical implications of algorithmic biases define bias based on *outcomes or treatment*: unequal allocation of resources or unfavorable representation of social groups [@blodgett2020; @gallegos2024; @kordzadeh2022].
This use of bias parallels discrimination laws that require proof of disparate outcomes, which treat biases as individual beliefs that are unactionable [@seiner2006].
Others distinguish bias from harm, defining bias as an inclination of an algorithm or a deviation from data [@ghosh2025; @wu2024a].
This neutral definition of bias is closely tied to statistics and computer science that view bias as inherent and unavoidable [@chen2023d; @ghosh2025].
Taken together, the definition of algorithmic bias varies not only across disciplines but also by the specific bias being examined.

Even with a clear definition, measuring biases in generative AI is difficult.
Despite attempts to make generative AI more transparent, many models remain proprietary and closed-source.
@ali2025 proposes using IBM Fairness 360 and Google What-If toolkits for assessing biases in AI-generated tourism data.
However, these tools require access to training data and model internals, which commercial generative AI models like ChatGPT do not provide [@gallegos2024].
Bias detection is further complicated by safety tunings that recent generative AI models undergo to avoid explicit biases [@bai2025; @santurkar2023].
Moreover, most existing AI bias metrics are designed to quantify disparities, not how such disparities arise [see review of bias metrics by @gallegos2024; @kordzadeh2022].
For example, metrics may reveal that generative AI disproportionately suggests resort destinations to certain racial groups.
Yet they cannot identify whether such disparities stem from popularity biases that favor popular destinations or peak seasons, racial stereotypes, or a combination of these mechanisms.
Together, these conceptual and methodological challenges limit our ability to test biases in generative AI models and assess their implications for tourism.

# Baseline-Rescaling-Outcome Model for testing algorithmic biases in tourism

We propose the Baseline-Rescaling-Outcome model, designed to address the challenges of measuring biases in proprietary and closed-source algorithms.
Bias is defined as *systematic deviation of algorithmic outputs from empirically grounded expectations of phenomena*.
Our definition distinguishes bias from harm, as harm depends on affected stakeholders [@blodgett2020; @ghosh2025].
For example, if an algorithm systematically favors one destination over others, this bias benefits the favored but is harmful to the rest.
Even within the favored destination, the tourism sector may benefit while locals suffer from over-tourism.
We therefore separate the detection of biases from the assessment of their consequences.

Our model tests bias by modeling the divergence between the algorithmic *outcome* and empirical *baseline* as a function of *rescaling* factors representing hypothesized bias mechanisms (@fig-model).
This approach has three advantages over existing bias tests.
First, the model can test biases without access to model internals or training data.
We draw upon social science methods that infer human biases from behavioral outcomes like response speed and error rates [@greenwald1998].
Like cognitive processes, we assume the algorithm's internals and its modeling processes as unobservable, inferring biases from outputs instead.
Our approach is also adaptable beyond generative AI and tourism, to any context with empirically grounded expectations, rescaling factors, and algorithmic outputs. 
Finally, the rescaling factors enable interpretable bias diagnosis that translates directly into practical suggestions for debiasing.
However, the model does not provide *causal* explanations of how biases arise in algorithms, which are secluded inside socio-technical processes involving data generation, model design, and human feedback [@bai2025; @santurkar2023; @viglia2024a].

![Baseline-Rescaling-Outcome Model](figures/model.svg){#fig-model}

## Outcome: Projected tourism patterns under complete reliance on the algorithm

The *outcome* projects scenarios in which the phenomena are entirely driven by the algorithm, consistent with scenario-based projection models.
Examples of projection models include Shared Socioeconomic Pathways for climate trajectories and COVID-19 diffusion models [@adam2020; @ipcc2021].
These models contain “worst-case” scenarios that project the most extreme outcomes: climate projections without emission reductions or infection rates without government interventions.
For example, testing bias in generative AI tourism recommendations requires projecting the outcome when generative AI makes all destination choices.
Similarly, biases in hiring algorithms for tourism firms can be tested by projecting a scenario where all hiring decisions are made by the algorithm.
Although unrealistic, such undiluted projections are necessary to reveal the full extent of biases.

## Baseline: Empirically grounded expectations of phenomena

The empirical *baseline* anchors the model to real-world expectations of phenomena.
Prior works employed similar approaches by comparing real-world distributions with algorithmic outputs to assess representation and popularity biases [@abdollahpouri2020; @santurkar2023].
Consider a situation where an algorithm has a four-in-ten chance of suggesting US domestic tourists to visit San Francisco.
Could we say that this algorithm has a systematic tendency to favor San Francisco as a tourism destination?
If four in ten Americans visit San Francisco, then the algorithm is simply reproducing what is expected in the real-world tourism patterns.
However, if only one in ten US domestic tourists visit San Francisco, then the algorithm does favor San Francisco beyond the empirical expectation.
Thus, the empirical baseline sets benchmarks for "unbiased" algorithmic outputs.

## Rescaling: Testable factors for hypothesized bias mechanisms

*Rescaling* tests specific mechanisms that explain deviations between the algorithmic outcome and the empirical baseline.
Under the null condition of no bias, the algorithm should reproduce the baseline without rescaling factors.
By testing hypothesized bias mechanisms, rescaling factors provide interpretable tests of systematic biases in algorithms, going beyond measuring the degree of biases.
This approach also allows testing the direction of biases.
The algorithm could exhibit biases that reduce real-world inequalities [@ghosh2025].
For example, it may favor less popular destinations and off-peak seasons, diversifying the tourism demand across destinations and time.
Our model captures such biases as negative rescaling factors, explaining algorithm outputs as mixtures of amplification and attenuation of empirical patterns.

# Study design

We apply the Baseline-Rescaling-Outcome Model to test popularity biases in generative AI travel recommendations.
Popularity bias is defined as the tendency where popular options "are recommended even more frequently than their popularity would warrant" [@abdollahpouri2020, p.1].
Humans exhibit similar behaviors, such as tourists flocking to popular destinations [@lee2025a].
This study therefore tests whether generative AI amplifies or attenuates such popularity biases beyond what is observed empirically.

Understanding this bias in tourism is particularly timely and practical, as major online travel agencies are already integrating generative AI into their platforms.
Examining popularity in the tourism context is also of theoretical significance.
Unlike recommending movies or music, tourism recommendations need to consider spatial and temporal dimensions of travel choices.
The decision to travel is not only about *whether* to travel, but also *from where*, *to where*, and *when*.
Thus, we further extend popularity bias into four types that are tourism-specific: destination popularity, month popularity, destination-month popularity, and origin-destination popularity biases.
The first two measure whether generative AI amplifies or attenuates the popularity of destinations and peak months.
Bias may also exist in specific combinations of destinations, origins, and months.
Destination-month popularity bias captures whether algorithms favor specific destinations during specific months.
Similarly, origin-destination popularity bias captures the tendency to excessively pair tourists from specific origins to specific destinations.

@fig-steps summarizes our data collection and analysis process.
The LLM simulation involves generating tourist flow using empirically grounded demographic profiles.
Separately from the AI-driven simulation, two data sources were used to estimate real-world tourism patterns.
This empirical data is then used to derive baseline expectations and popularity factors.
Finally, we combine simulation and empirical data to test four hypothesized popularity biases by fitting the Poisson model.

![Overview of the simulation and analysis process](figures/steps.svg){#fig-steps}

## Data collection

### Definition of population and simulated samples

The population of our simulations is US residents aged 18 and over. 
The US domestic tourism market is one of the largest in the world, offering geographically and socioeconomically diverse destinations [@unwto].
Hence, the US context provides sufficient variability for large-scale simulations, while excluding complications of international tourism like visa requirements.
Most generative AI models also perform better on English tasks, making the US context advantageous for these models [@qin2025].

We used 2019-2023 American Community Survey 5-Year Public Use Microdata Sample data to derive stratum weights for the population.
@apx-demo summarizes sex, age, and household income of the population.
From this population, we took a random sample of 1,000 individuals stratified by state, sex, age, and income.
This sampling procedure was repeated 1,000 times, yielding one million simulated individuals with demographic characteristics that mirror the population.
By using empirically derived profiles, we ensure that the demographic distribution of simulated travelers resembles that of US domestic tourists.
This approach also fixes the number of outgoing tourists from each state, allowing us to control for origin-specific propensity to travel.
One limitation is that generative AI models may also influence the decision to travel itself, which we do not account for here.

### Large language model simulations

Social science researchers are increasingly using synthetic data from generative AI.
We highlight four key differences between our approach and prior studies.
First, we use AI-generated data to show how these AI models *do not* replicate human behavior, contrary to claims that generative AI can mimic real-world tourists [for example, @ali2025; @viglia2024a; @xiong2024].
Next, our simulations rely on empirically derived demographic profiles, instead of using arbitrary or non-representative profiles that confound the results [for example, @andreev2025].
Third, we repeat the simulation for 1,000 iterations to sufficiently capture the uncertainty in LLM outputs, unlike studies that relied on a few handpicked responses or a single simulation run [for example, @mellors2025; @xiong2024], 
Finally, our approach recognizes the network and temporal nature of tourism.
Beyond looking at destination choice alone, we simulate the complete network of tourist flows between all origin-destination pairs across months.

The simulation starts with a system prompt containing the simulation context, response structure, and examples (available in @apx-prompt).
To simplify the simulation, we assume that each person chooses one domestic destination within the US (50 US states and the District of Columbia).
We instructed LLMs to act as travel agents recommending one domestic travel destination based on the provided demographic profile.
Twenty simulated tourists are processed at a time to improve the efficiency of the simulation.
Our process resembles agent-based modeling using LLMs but differs in that we prompt LLMs to act as travel agents, not tourists [@gao2024].
This choice reflects our objective to project how generative AI would influence tourist flows if widely adopted, rather than using it to substitute for human travelers.
We captured the probabilistic nature of LLM outputs by repeating the simulation with 1,000 individuals for 1,000 iterations.
This process produces a distribution of simulated tourist visits that accounts for stochastic variations in LLM outputs.

We establish the consistency of our findings across two different LLMs: Google's Gemini 2.5 Flash Lite (version June 2025) and OpenAI's GPT-4.1 Nano (version April 2025).
They are among the leading commercial LLMs in capabilities and market share.
Given the scale of our simulations, we chose their smallest variants optimized for speed and cost.
Although the two LLMs are closed-source, they have comparable pricing structures ($0.10 per million input tokens; $0.30 and $0.40 per million output tokens, respectively).
We also chose these two models also because they use different architectures.
Gemini 2.5 family uses a mixture-of-experts architecture, while GPT-4.1 family relies on traditional transformer architecture.
Because the two models are developed by different companies, they are likely to be trained on different datasets and tuning processes, which is ideal for assessing the generalizability of our findings.

All requests were made from the IP address of the university located in the southeastern US, using custom automation scripts.
We explicitly instructed LLMs not to use IP-specific details when generating recommendations.
Data collection continued until we achieved a complete dataset.
We then aggregated the data to create destination-origin-month matrices for each iteration and model, where each cell represents the number of tourists from the origin. $i$ to destination $j$ in a month $m$.

### Empirical baseline data and simulations

The empirical data serve two purposes in this study.
It provides the baseline for descriptively comparing characteristics of AI-simulated tourist flows against real-world tourism patterns.
Additionally, we use the empirically derived baseline and popularity factors to explain the discrepancies between AI-simulated and empirical tourist flows.
Because biases also exist in the empirical mobility data, we rely on two different data sources to ensure the robustness of our findings [@li2024b].
Our primary data source is the @advan Mobility Data, which estimates movements between US census block groups based on mobile device panels.
This dataset is our primary data source due to its high spatial and temporal resolution.
The supplementary data source is the Department of Transportation's 2022 National Household Travel Survey.
This is the only official national travel survey in the US that collects travel behavior data such as trip purpose, modes, and commuting zones [@nhts2022].

For both datasets, we used monthly data from January through December 2022 (the latest available for National Household Travel Survey). 
Following pre-processing steps were employed to filter out non-tourism mobility flows.
We first excluded visits to home and work locations, and movements within the county of residence [@lee2025c].
Additionally, trips under 50 miles one-way or within the same commuting zones were considered non-tourism. 
This offers more conservative estimates of tourist visits by filtering out short-distance and commuting trips that are less likely to be tourism-related.
These estimates were then used to compute the empirical shares and the four popularity factors.

Since we employed an iterative approach for the LLM simulations, direct comparison with empirical data is inappropriate.
Therefore, we also conducted empirical-based simulations for descriptive comparison between AI-simulated and empirical tourist flows.
Using empirical estimates as weights, we simulated tourist flows by randomly assigning destinations and months to each individual in the simulated sample.
Due to data anonymization, demographic factors could not be incorporated in the empirical-based simulations.
Therefore, we assume that the probability of traveling to another state in a given month is equal for all individuals in a given origin state. 
For instance, if 10% of Illinois residents visited Florida in January 2024, all Illinois residents were given a 0.1 probability to travel to Florida in January (irrespective of other demographic factors).
Same as the LLM simulations, the empirical-based simulation was repeated 1,000 times.
Subsequently, the results were aggregated to destination-origin-month matrices.

## Operationalizing the Baseline-Rescaling-Outcome Model

Below is the empirical model for testing four popularity biases.
Define the number of tourist flow from origin $i$ to destination $j$ in month $m$ as $Flow_{(i,j,m)}$.
Let $P_{(i,j,m)}$ be the share of tourists from origin $i$ to destination $j$ in month $m$ over all tourist flow ($Flow_{(i,j,m)} / \sum{Flow_{(i,j,m)}}$).
Under the null condition that LLMs produce "unbiased" travel suggestions, we expect:
$$
Flow^{LLM}_{(i,j,m)} \sim \sum_{j,m}{Flow^{LLM}_{(i,j,m)}} \cdot P^{Empirical}_{(j,m|i)} = Baseline_{(i,j,m)}
$$ {#eq-null}
where $P^{Empirical}_{(j,m|i)}$ is the share of tourists traveling to destination $j$ in month $m$ given origin $i$, observed empirically ($P_{(i,j,m)} / \sum_{j,m}{P_{(i,j,m)}}$).
This share is multiplied by the total number of LLM-produced tourists from origin $i$, which scales the expected number of tourists based on total tourist outflow from origin $i$.
Meaning, the right-hand side of @eq-null is the baseline expectation when generative AI can perfectly replicate empirical tourism patterns ($Baseline_{(i,j,m)}$).

Destination and month popularity are defined as:
$$
\begin{aligned}
D_{j} &= \sum_{i,m}{P^{Empirical}_{(i,j,m)}} \\
M_{m} &= \sum_{i,j}{P^{Empirical}_{(i,j,m)}}
\end{aligned}
$$ {#eq-d-m}
where $D_{j}$ is the popularity of destination $j$ across all origins and months, and $M_{m}$ is the popularity of month $m$ across all origins and destinations.

We account for the popularity of specific destination-month pairs as a joint probability of choosing destination $j$ in month $m$ beyond what can be expected from their independent popularities:
$$
DM_{j,m} = \frac{\sum_{i}{P^{Empirical}_{(i,j,m)}}}{D_{j} \cdot M_{m}}
$$ {#eq-dm}
The denominator in @eq-dm is the expected popularity of the destination-month pair if destination and month popularities were independent.
If $DM_{j,m} > 1$, destination-month pair $(j,m)$ is more popular than expected under independence, while $DM_{j,m} < 1$ indicates the pair is less popular than expected.
Similarly, we account for the popularity of specific origin-destination pairs:
$$
OD_{i,j} = \frac{\sum_{m}{P^{Empirical}_{(i,j,m)}}}{O_{i} \cdot D_{j}}
$$ {#eq-od}
where $O_{i} = \sum_{j,m}{P^{Empirical}_{(i,j,m)}}$.
Same as @eq-dm, $OD_{i,j}$ measures how popular the origin-destination pair $(i,j)$ is than what would be expected if origin and destination popularities were independent.

We test the four popularity rescaling factors using the following multiplicative model:
$$
\frac{Flow_{(i,j,m)}^{LLM}}{Baseline_{(i,j,m)}} = 
(D_{j})^{\beta_1} \cdot 
(M_{m})^{\beta_2} \cdot 
(DM_{j,m})^{\beta_3} \cdot 
(OD_{i,j})^{\beta_4}
$$ {#eq-model}
Under the null hypotheses of no systematic bias, we expect all $\beta=0$. If $\beta>0$ for a factor, it positively rescales that factor's popularity in their suggestions; if $\beta<0$, it negatively rescales that factor's popularity.

@fig-beta-demo illustrates how different $\beta_2$ values (month popularity bias) rescale the distribution of the monthly tourist share.
For example, if $\beta_2 = 1$, seasonal variation in tourist flow is amplified, whereas $\beta_2 = -1$ produces a uniform distribution across months.
This test is independent of destination-month popularity bias ($\beta_3 \ne 0$) because $DM_{j,m}$ measure the popularity beyond destination and month popularity can predict.
Meaning, if we generate tourist flows with only the destination-month popularity bias ($\beta_3 \ne 0$), the resulting data will show no changes in overall destination or month popularity ($\beta_1 = 0, \beta_2 = 0$).

```{r} 
#| label: fig-beta-demo
#| fig-cap: Example of how different $\beta_2$ values affect the distribution of the monthly tourist share
#| fig-height: 5
df.beta.demo |> 
    mutate(
        case = factor(
            case,
            levels = c(
                "p.neg2",
                "p.neg1",
                "p",
                "p.pos1",
                "p.pos2"
            ),
            labels = c(
                "beta[2]==-2",
                "beta[2]==-1",
                "beta[2]==0",
                "beta[2]==1",
                "beta[2]==2"
            ),
            ordered = TRUE
        ),
    ) |>
    ggplot(aes(x = month, y = p)) +
    geom_bar(stat = "identity", fill = color.gemini) +
    scale_x_discrete(breaks = c("Jan", "Dec")) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    coord_cartesian(clip = "off") +
    facet_wrap( ~ case, ncol = 5, labeller = label_parsed) +
    theme(
        panel.spacing = unit(1.0, "lines"),
        panel.grid.major.x = element_blank(),
        plot.margin = margin(t = 10, r = 30, b =10, l = 10)
    ) +
    labs(
        title = "Positive β Amplifies Popularity, Negative β Suppresses and Inverts Popularity",
        x = "Month",
        y = "Share of total tourist flow",
    )
```

By taking the log of @eq-model, we can fit a regression model that tests the four popularity biases:
$$
\begin{aligned}
\ln Flow_{(i,j,m)}^{LLM} & = \ln Baseline_{(i,j,m)} \\
& + \beta_1 \cdot \ln D_{j} + \beta_2 \cdot \ln M_{m} + \beta_3 \cdot \ln DM_{j,m} + \beta_4 \cdot \ln OD_{i,j}
\end{aligned}
$$ {#eq-log-model}

## Hypotheses testing

The last step of the analysis is to combine simulation and empirical data to test hypothesized popularity biases.
We achieve this goal by fitting @eq-log-model using the Poisson count model. 
Essentially, the model explains variations in LLM-simulated tourist flows ($Flow_{(i,j,m)}^{LLM}$) beyond what can be expected by empirical data ($Baseline_{(i,j,m)}$), using the four popularity factors as predictors.
We chose the Poisson pseudo-maximum likelihood estimator, which is widely used in estimating gravity models of trade and migration.
The Poisson pseudo-maximum likelihood estimator only requires the conditional mean to be correctly specified, without requiring a specific distributional assumption.
This estimator is robust to heteroskedasticity and having many zeros in the dependent variable, making the estimator suitable for our analysis [@silva2011].
Because we run 1,000 iterations of simulations, we fit the model for each iteration and collect the results across iterations to assess the uncertainty in the effect estimates.

# Results

## Descriptive analysis

```{r}
#| label: intext-desc
max.advan <- round(df.sum |> filter(data.name == "Simulation: ADVAN Mobility Data", variable == "Tourist flow") |> pull(max))
max.nhts <- round(df.sum |> filter(data.name == "Simulation: National Household Travel Survey", variable == "Tourist flow") |> pull(max))
max.gemini <- round(df.sum |> filter(data.name == "Simulation: Gemini 2.5 Flash Lite", variable == "Tourist flow") |> pull(max))
max.gpt <- round(df.sum |> filter(data.name == "Simulation: GPT-4.1 Nano", variable == "Tourist flow") |> pull(max))
```

```{r}
#| label: intext-any-prop
intext.any <- df.any |>
    mutate(
        only.gemini.advan = (gemini == "Any flow" & advan == "No flow"),
        only.gemini.nhts = (gemini == "Any flow" & nhts == "No flow"),
        only.gpt.advan = (gpt == "Any flow" & advan == "No flow"),
        only.gpt.nhts = (gpt == "Any flow" & nhts == "No flow"),
        only.advan.gemini = (advan == "Any flow" & gemini == "No flow"),
        only.nhts.gemini = (nhts == "Any flow" & gemini == "No flow"),
        only.advan.gpt = (advan == "Any flow" & gpt == "No flow"),
        only.nhts.gpt = (nhts == "Any flow" & gpt == "No flow")
    ) |>
    summarize(across(
        starts_with("only."),
        sum 
    )) / 31212
intext.any <- lapply(intext.any * 100, sprintf, fmt = "%.1f%%")
```

@tbl-desc presents descriptive statistics of simulation and empirical data.
Origin total outflows are consistent across simulations because the simulated tourists are stratified by state population size.
The median tourist flow per destination-origin-month cell is 0 in all simulations, indicating high sparsity.
This sparsity is expected, as each iteration assigns 1,000 tourists across 31,212 possible combinations (51 origins×51 destinations×12 months).
By design, only about 3.1% (=1,000/31,212) of cells would have any tourist visits even under complete random assignment.
But the upper tail of the distribution differs across simulations.
LLM simulations show a stronger concentration of tourists in the most popular destination-origin-month combination than empirical-based ones (Max=`{r} max.gemini` for Gemini 2.5 Flash Lite and `{r} max.gpt` for GPT-4.1 Nano; `{r} max.advan` for ADVAN Mobility Data and `{r} max.nhts` for National Household Travel Survey).

Similar patterns emerge when examining the presence and absence of tourist flow.
@tbl-any compares presence and absence of destination-origin-month combinations between LLM and empirical simulations.
We aggregated the simulated visits across all 1,000 iterations to reduce sparsity.
LLMs exclude many destination-origin-month combinations.
About `{r} intext.any$only.nhts.gpt` to `{r} intext.any$only.advan.gemini` of empirically observed combinations never appearing in LLM simulations.
By contrast, LLMs rarely suggest destination-origin-month combinations that are absent from empirical data, with fewer than 10% of combinations appearing only in LLM simulations.
Meaning, LLMs prune empirical tourism patterns but rarely generate new ones.

```{r}
#| label: tbl-desc
#| tbl-cap: Descriptive statistics of simulation and empirical data
df.sum |>
    mutate(
        variable = indent_row(variable)
    ) |>
    gt(groupname_col = "data.name") |>
    sub_small_vals(threshold = 0.001) |>
    fmt_number(decimals = 3) |>
    fmt_markdown(columns = notation, rows = TRUE) |>
    cols_align(
        align = "left",
        columns = variable
    ) |>
    cols_label(
        notation = "Notation",
        variable = "Variable",
        min = "Min",
        max = "Max",
        median = "Median",
        mean = "Mean",
        sd = "SD"
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote(
        md("Note: For *simulation* data, statistics are calculated over 1,000 iterations (N=31,212,000). Statistics for *empirical* data are based on a single destination-origin-month matrix (N=31,212).")
    )
```

```{r} 
#| label: tbl-any
#| tbl-cap: Agreement in the presence of any tourist flow between large language model simulations and empirical-based simulations
t.any.gemini.advan <- df.any |>
    tbl_cross(
        row = gemini,
        col = advan,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")
 
t.any.gemini.nhts <- df.any |>
    tbl_cross(
        row = gemini,
        col = nhts,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gpt.advan <- df.any |>
    tbl_cross(
        row = gpt,
        col = advan,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gpt.nhts <- df.any |>
    tbl_cross(
        row = gpt,
        col = nhts,
        percent = "cell",
        digits = c(0, 1),
        margin = NULL
    ) |>
    remove_row_type(type = "header")

t.any.gemini <- tbl_merge(
    list(t.any.gemini.advan, t.any.gemini.nhts ),
    tab_spanner = c(
        "*Simulation: ADVAN*",
        "*Simulation: NHTS*"
    )
) 
t.any.gpt <- tbl_merge(list(t.any.gpt.advan, t.any.gpt.nhts )) 

tbl_stack(
    list( t.any.gemini, t.any.gpt),
    group_header = c("Simulation: Gemini 2.5 Flash Lite", "Simulation: GPT-4.1 Nano"),
    ) |> 
    as_gt() |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote("Note: ADVAN=ADVAN Mobility Data, NHTS=National Household Travel Survey. Counts and percentages of destination-origin-month cells with no tourist flow in both simulations, any flow in either simulation, or any flow in both simulations. Percentages are calculated based on the number of possible destination-origin-month combinations (N=31,212). Based on one million simulated visits aggregated across all 1,000 iterations.")
```

```{r}
#| label: intext-dst
dst.gini.advan <- df.dst |> filter(data.name == "advan") |> pull(median.gini) |> first() |> pval_format()
dst.gini.nhts <- df.dst |> filter(data.name == "nhts") |> pull(median.gini) |> first() |> pval_format()
dst.gini.gemini <- df.dst |> filter(data.name == "gemini") |> pull(median.gini) |> first() |> pval_format()
dst.gini.gpt <- df.dst |> filter(data.name == "gpt") |> pull(median.gini) |> first() |> pval_format()
```

```{r}
#| label: plot-dst
#| include: false
bbox <- st_bbox(sf.states)
data_labeller <- as_labeller(
            c(
                "advan" = "ADVAN Mobility Data",
                "nhts" = "National Household Travel Survey",
                "gemini" = "Gemini 2.5 Flash Lite",
                "gpt" = "GPT-4.1 Nano"
            )
        )

df.dst.label <- df.dst |>
    group_by(data.name) |>
    summarize(median.gini = first(median.gini)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

p.dst <- df.dst |>
    ggplot() +
    geom_sf(
        aes(fill = median.sum.p, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Reds 2",
    ) +
    geom_sf_label(
        data = df.dst.label,
        aes(
            geometry = geometry,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Gini: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(
        legend.position = "bottom",
    ) +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Are slightly more concentrated at popular destinations",
        fill = "Share of tourist flow (median over 1,000 iterations)",
        x = "",
        y = ""
    )
p.dst
```

```{r} 
#| label: intext-month-prop
month.gini.advan <- df.month |> filter(data.name == "advan") |> pull(median.gini) |> first() |> pval_format()
month.gini.nhts <- df.month |> filter(data.name == "nhts") |> pull(median.gini) |> first() |> pval_format()
month.gini.gemini <- df.month |> filter(data.name == "gemini") |> pull(median.gini) |> first() |> pval_format()
month.gini.gpt <- df.month |> filter(data.name == "gpt") |> pull(median.gini) |> first() |> pval_format()
```

```{r} 
#| label: plot-month
#| include: false
p.month <- df.month |>
    mutate(month = fct_rev(month)) |>
    ggplot() +
    geom_bar(
        aes(y = month, x = median.sum.p, fill = data.name),
        stat = "identity"
    ) +
    geom_label(
        data = df.month |>
            group_by(data.name) |>
            summarize(median.gini = first(median.gini)),
        aes(
            y = "Dec",
            x = 0.25,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Gini: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    # cheating my way to add y axis line for each facet
    geom_vline(xintercept = 0, lty = 1, color = "black") +
    scale_fill_manual(
        values = c(
            "advan" = color.advan,
            "nhts" = color.nhts,
            "gemini" = color.gemini,
            "gpt" = color.gpt
        )
    ) +
    scale_x_continuous(expand = expansion(mult = c(0.0, 0.1))) +
    scale_y_discrete(breaks = c("Jan", "Dec")) +
    coord_cartesian(clip = "off") +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    theme(
        axis.line.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.ticks.y = element_line(linewidth = 0.3),
        panel.spacing.x = unit(3, "lines"),
        legend.position = "none"
    ) +
    labs(
        subtitle = "Are highly seasonal",
        x = "Share of tourist flow (median over 1,000 iterations)",
        y = "",
        fill = "Scenario"
    )
p.month 
```

```{r} 
#| label: plot-month-gini
#| include: false
df.gini.label <- df.month.gini |>
    group_by(data.name) |>
    summarize(median.gini = median(median.gini)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

# for in-text numbers
dst.month.gini.advan <- df.gini.label[1,2] |> pval_format()
dst.month.gini.nhts <- df.gini.label[2,2] |> pval_format()
dst.month.gini.gemini <- df.gini.label[3,2] |> pval_format()
dst.month.gini.gpt <- df.gini.label[4,2] |> pval_format()

p.month.gini <- df.month.gini |>
    ggplot() +
    geom_sf(
        aes(fill = median.gini, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Blues 2",
        rev = TRUE,
        limits = c(0, 1),
        breaks = seq(0, 1, by = 0.2)
    ) +
    geom_sf_label(
        data = df.gini.label,
        aes(
            geometry = geometry,
            label = median.gini |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Median: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap(~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Destinations have higher seasonality in tourism demand",
        fill = "Gini coefficient (median over 1,000 iterations; higher values indicate greater inequality)",
        x = "",
        y = ""
    )
p.month.gini
```

```{r} 
#| label: plot-org-entropy
#| include: false
df.entropy.label <- df.org.entropy |>
    group_by(data.name) |>
    summarize(median.entropy = median(median.entropy)) |>
    mutate(
        geometry = st_sfc(
            st_point(c(bbox["xmax"], bbox["ymin"]))
        )
    )

# for in-text numbers
dst.entropy.advan <- df.entropy.label[1,2] |> pval_format()
dst.entropy.nhts <- df.entropy.label[2,2] |> pval_format()
dst.entropy.gemini <- df.entropy.label[3,2] |> pval_format()
dst.entropy.gpt <- df.entropy.label[4,2] |> pval_format()

p.org.entropy <- df.org.entropy |>
    ggplot() +
    geom_sf(
        aes(fill = median.entropy, geometry = geometry),
        color = "white",
        lwd = 0.2
    ) +
    scale_fill_continuous_sequential(
        palette = "Greens 2",
        limits = c(0.0, 3.0),
    ) +
    geom_sf_label(
        data = df.entropy.label,
        aes(
            geometry = geometry,
            label = median.entropy |>
              scales::label_number(accuracy = 0.001, zero_pad = TRUE)() %>%
              paste0("Median: ", .)
        ),
        hjust = 1,
        linewidth = 0,
    ) +
    facet_wrap( ~ data.name, ncol = 4, labeller = data_labeller) +
    coord_sf(datum = NA) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title.position = "top", title.hjust = 0.5, nrow = 1)) +
    labs(
        subtitle = "Destinations have less diversified and balanced tourism demand",
        fill = "Entropy index (median over 1,000 iterations; higher values indicate more diversified and balanced demand)",
        x = "",
        y = ""
    )

p.org.entropy
```

```{r}
#| label: fig-prop
#| fig-cap: Distributional characteristics of tourist flows across simulations
#| fig-width: 12
#| fig-height: 15.6
(p.dst / p.month / p.month.gini / p.org.entropy) + 
    plot_annotation(
        title = "Large Language Models Produce More Unevenly Distributed Tourist Flows",
        subtitle = "Simulations using large language models tend to generate tourist flows that...",
        tag_levels = "a",
        tag_prefix = "(", tag_suffix = ")"
    ) & 
    theme(
        plot.tag = element_text(size = 20, face = "bold")
    )
```

We further examine the differences in distribution of tourist flow across simulations.
Results are summarized by taking the median across 1,000 iterations.
Mathematical definitions of used metrics are available in @apx-eq.
First, we examine the distribution of tourist share by destination states ($D_j$) and months ($M_m$).
Inequality is measured using the Gini index, where higher values indicate greater concentration of tourists across states or months.
In all simulations, tourist visits concentrate in popular states such as California, Florida, and Texas (@fig-prop[a]()).
LLM simulations show higher Gini indices than empirical-based simulations, indicating greater inequality in tourist arrivals across states (ADVAN Mobility Data=`r dst.gini.advan` and National Household Travel Survey=`r dst.gini.nhts`; Gemini 2.5 Flash Lite=`r dst.gini.gemini` and GPT-4.1 Nano=`r dst.gini.gpt`).

Seasonality is substantially stronger in LLM simulations (@fig-prop[b]()).
Gini indices of monthly tourist share for LLM simulations far exceed empirical levels (Gemini 2.5 Flash Lite=`r month.gini.gemini` and GPT-4.1 Nano=`r month.gini.gpt`; ADVAN Mobility Data=`r month.gini.advan` and National Household Travel Survey=`r month.gini.nhts`).
Although, the two LLMs differ in peak tourism months.
Gemini 2.5 Flash Lite tends to recommend traveling in September and October, whereas GPT-4.1 Nano shows peaks in April, May, and September.
LLMs worsen the seasonality of tourism demand for most destinations.
For @fig-prop[c](), we calculated the Gini index of monthly tourist share for each destination state and took the median over 1,000 iterations.
In empirical-based simulations, a few states show relatively high seasonality, such as Alaska and Hawaii.
By contrast, most states exhibit high seasonality in LLM simulations, indicated by higher Gini indices across states (Median of medians=`r dst.month.gini.advan` and `r dst.month.gini.nhts` for ADVAN Mobility Data and National Household Travel Survey; `r dst.month.gini.gemini` and `r dst.month.gini.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).

LLMs generate tourist flows that destinations rely on a few origins (@fig-prop[d]()).
We use entropy index instead of Gini index because entropy is more suitable for 
measuring whether a destination has diversified and balanced tourism demand, which are characteristics of resilient destinations [@lee2025c].
Empirical simulations show that states such as Florida, Illinois, and North Carolina have diversified and balanced demand (higher entropy).
In LLM simulations, entropy indices are overall lower with much fewer states with relatively high entropy values (Median of medians=`r dst.entropy.advan` and `r dst.entropy.nhts` for ADVAN Mobility Data and National Household Travel Survey; `r dst.entropy.gemini` and `r dst.entropy.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).
These patterns suggest that LLMs produce less diversified and balanced origin-destination flows that are vulnerable to shocks.

```{r} 
#| label: intext-graph-stats
df.graph.sum <- df.graph |>
    group_by(stat, data.name) |>
    summarize(
        median.value = median(value)
    )
# reciprocity
recip.advan <- df.graph.sum[1,3] |> pval_format()
recip.nhts <- df.graph.sum[2,3] |> pval_format()
recip.gemini <- df.graph.sum[3,3] |> pval_format()
recip.gpt <- df.graph.sum[4,3] |> pval_format()
# median travel distance
mdist.advan <- df.graph.sum[5,3] |> round()
mdist.nhts <- df.graph.sum[6,3] |> round()
mdist.gemini <- df.graph.sum[7,3] |> round()
mdist.gpt <- df.graph.sum[8,3] |> round()
# border ratio
br.advan <- df.graph.sum[9,3] |> pval_format()
br.nhts <- df.graph.sum[10,3] |> pval_format()
br.gemini <- df.graph.sum[11,3] |> pval_format()
br.gpt <- df.graph.sum[12,3] |> pval_format()
# self-loop ratio
sl.advan <- df.graph.sum[13,3] |> pval_format()
sl.nhts <- df.graph.sum[14,3] |> pval_format()
sl.gemini <- df.graph.sum[15,3] |> pval_format()
sl.gpt <- df.graph.sum[16,3] |> pval_format()
```

```{r} 
#| label: fig-graph-stats
#| fig-cap: Characteristics of tourist flow structure across simulations
#| fig-height: 10
df.graph |>
    mutate(
        data.name = fct_rev(data.name) 
    ) |>
    ggplot(aes(x = value, y = data.name, fill = data.name)) +
    geom_vline(
        data = df.graph.rand |>
            group_by(stat) |>
            summarize(value = median(value)),
        aes(xintercept = value),
        linetype = "dashed",
        linewidth = 0.7,
        color = "red",
    ) +
    geom_boxplot(
        alpha = 0.8,
        width = 0.6,
        linewidth = 0.3,
        outlier.shape=1,
    ) +
    scale_fill_manual(
        values = c(
            "ADVAN Mobility Data" = color.advan,
            "National Household Travel Survey" = color.nhts,
            "Gemini 2.5 Flash Lite" = color.gemini,
            "GPT-4.1 Nano" = color.gpt
        )
    ) +
    facet_wrap( ~ stat, ncol = 1, scales = "free_x", strip.position = "bottom") +
    expand_limits(x = 0) +
    theme(
        strip.text = element_text(face = "plain"),
        strip.placement = "outside",
        axis.ticks.y = element_line(linewidth = 0.3),
        axis.text.y = element_text(face = "italic"),
        panel.border = element_rect(color = "black", fill = NA, linewidth = 0.5),
        panel.grid.major.y = element_blank(),
        panel.spacing = unit(2.0, "lines"),
        legend.position = "none",
        plot.margin = margin(t = 10, r = 60, b = 10, l = 10)
    ) +
    labs(
        title = "Generative AI Produce Structurally Different Tourist Flows",
        subtitle = "Large language model-generated tourist flows exhibit lower reciprocity and fewer trips to bordering states",
        caption = "Note. Dashed red line indicates what would be expected if destination-origin-month combinations are completely random (uniform probability).",
        x = "",
        y = "",
    )
```

Additionally, we analyze the overall structure of tourist flows.
We constructed an origin-destination matrix by aggregating tourist numbers at the year level.
Then we computed four statistics capturing how the structure of tourist flows differs across simulations.
Box plots in @fig-graph-stats summarize the distribution of the four network-level statistics across 1,000 iterations, colored by simulation scenario.
The dotted red line indicates the expected value under complete randomness, which assumes equal probability of choosing any destination (a probability of $1/51$).

LLMs produce tourist flows with clear separation between tourist sending and receiving states, as indicated by weaker reciprocity.
Reciprocity measures the tendency of two states to exchange a similar number of tourists.
Empirical-based simulations show stronger reciprocity than the random expectation (Median=`r recip.advan` and `r recip.nhts` for ADVAN Mobility Data and National Household Travel Survey).
However, LLM simulations show weaker reciprocity than expected by chance (Median=`r recip.gemini` and `r recip.gpt` for Gemini 2.5 Flash Lite and GPT-4.1 Nano).

Both Gemini 2.5 Flash Lite and GPT-4.1 Nano suggest farther destinations than empirical data, based on median travel distance excluding in-state trips (Median of medians=`r mdist.gemini` and `r mdist.gpt`).
This tendency is partially due to LLMs' lower propensity to suggest trips to bordering states.
Gemini 2.5 Flash Lite has a lower ratio of tourist flows between bordering states than the empirical models (Median=`r br.gemini`).
GPT-4.1 Nano shows even lower tendency to suggest bordering states, lower than what would be expected under randomness (Median=`r br.gpt`).
But the two models differ in their tendency to suggest in-state tourism.
Gemini 2.5 Flash Lite shows a ratio of in-state trips comparable to the empirical models (Median=`r sl.gemini`).
In contrast, GPT-4.1 Nano shows a stronger preference for recommending tourists to travel within their own state (Median=`r sl.gpt`).

## Model estimation results

```{r} 
#| label: intext-betas
# d coeffs
b.d.gemini.advan <- betas.sum[1, 4] |> sprintf(fmt = "%4.3f")
b.d.gemini.nhts <- betas.sum[5, 4] |> sprintf(fmt = "%4.3f")
b.d.gpt.advan <- betas.sum[9, 4] |> sprintf(fmt = "%4.3f")
b.d.gpt.nhts <- betas.sum[13, 4] |> sprintf(fmt = "%4.3f")

# m coeffs
b.m.gemini.advan <- betas.sum[2, 4] |> sprintf(fmt = "%4.3f")
b.m.gemini.nhts <- betas.sum[6, 4] |> sprintf(fmt = "%4.3f")
b.m.gpt.advan <- betas.sum[10, 4] |> sprintf(fmt = "%4.3f")
b.m.gpt.nhts <- betas.sum[14, 4] |> sprintf(fmt = "%4.3f")

# dm coeffs
b.dm.gemini.advan <- betas.sum[3, 4] |> sprintf(fmt = "%4.3f")
b.dm.gemini.nhts <- betas.sum[7, 4] |> sprintf(fmt = "%4.3f")
b.dm.gpt.advan <- betas.sum[11, 4] |> sprintf(fmt = "%4.3f")
b.dm.gpt.nhts <- betas.sum[15, 4] |> sprintf(fmt = "%4.3f")

# od coeffs
b.od.gemini.advan <- betas.sum[4, 4] |> sprintf(fmt = "%4.3f")
b.od.gemini.nhts <- betas.sum[8, 4] |> sprintf(fmt = "%4.3f")
b.od.gpt.advan <- betas.sum[12, 4] |> sprintf(fmt = "%4.3f")
b.od.gpt.nhts <- betas.sum[16, 4] |> sprintf(fmt = "%4.3f")
```

@tbl-betas and @fig-betas summarize the estimated effects of the four popularity biases on LLM-simulated tourist flows (@eq-log-model).
Across two LLMs and two empirical baselines, destination-month popularity consistently has the largest positive coefficient.
Meaning, LLMs show a tendency to favor popular destination-month combinations when generating travel recommendations.
Although, 95% credible intervals indicate high uncertainty around the estimates for Gemini 2.5 Flash Lite with both empirical baselines. 
The coefficients can be interpreted as elasticity.
For example, GPT-4.1 Nano with ADVAN Mobility Data baseline had a median coefficient of `r b.dm.gpt.advan` for destination-month popularity.
If real-world data shows that a particular destination-month combination is twice as popular than what is expected under independence of destination and month popularity ($DM_{(j,m)} = 2$), then the expected tourist flow generated by GPT-4.1 Nano for that combination is approximately `r round(2 ** as.numeric(b.dm.gpt.advan), 1)` times higher ($2^{1.771}$), holding other factors constant.

We find mixed results for the rest of the popularity biases.
Some effects are specific to the LLM.
For example, Gemini 2.5 Flash Lite consistently shows negative coefficients for destination popularity, indicating that it tends to negatively rescale popular destinations (Median $\beta_{1}$ = `r b.d.gemini.advan` and `r b.d.gemini.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).
The same pattern is only observed for GPT-4.1 Nano with National Household Travel Survey baseline (Median $\beta_{1}$ = `r b.d.gpt.nhts`) but not with the ADVAN Mobility Data baseline (Median $\beta_{1}$ = `r b.d.gpt.advan`).
GPT-4.1 Nano with shows positive rescaling for origin-destination popularity (Median $\beta_{4}$ = `r b.od.gpt.advan` and `r b.od.gpt.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines), while Gemini 2.5 Flash Lite shows mixed findings (Median $\beta_{4}$ = `r b.od.gemini.advan` and `r b.od.gemini.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).

Finally, we note that the month popularity coefficients are negative for GPT-4.1 Nano (Median $\beta_{2}$ = `r b.m.gpt.advan` and `r b.m.gpt.nhts` with ADVAN Mobility Data and National Household Travel Survey baselines).
This result is contradictory, given that prior descriptive analysis indicated GPT-4.1 Nano having greater seasonality.
One possible explanation is that peak months in GPT-4.1 Nano simulations poorly align with those in empirical data (see @fig-prop[b]()).
Therefore, the model attempts to fit the month popularity factor by flattening the empirical month popularity distribution.

```{r}
#| label: tbl-betas
#| tbl-cap: Median and 95% credible intervals of Poisson model coefficients across 1,000 iterations
betas.sum |> 
    pivot_wider(names_from = emp, values_from = c(median.coeff, lower.ci, upper.ci)) |>
    relocate(ends_with("_ADVAN"), .after = param) |>
    mutate(
        param = factor(
            param,
            levels = levels(param),
            labels = md(
                c(
                "$\\beta_{1}$: Destination",
                "$\\beta_{2}$: Month",
                "$\\beta_{3}$: Destination-Month",
                "$\\beta_{4}$: Origin-Destination"
                )
            )
        ),
        sim = paste("Simulation:", sim)
    ) |>
    mutate(param = indent_row(param)) |>
    gt(groupname_col = "sim") |>
    tab_spanner(
        label = html("Empirical: ADVAN"),
        columns = ends_with("_ADVAN")
    ) |>
    tab_spanner(
        label = html("Empirical: NHTS"),
        columns = ends_with("_NHTS")
    ) |>
    fmt_number(decimals = 3) |>
    fmt_markdown(columns = param, rows = TRUE) |>
    cols_align(
        align="left",
        columns = param
    ) |>
    cols_label(
        param = "",
        starts_with("median.coeff") ~ "Median",
        starts_with("lower.ci") ~ "2.5%",
        starts_with("upper.ci") ~ "97.5%",
    ) |>
    # italicize sim & emp names
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_column_spanners()
    ) |>
    tab_style(
        style = cell_text(style = "italic"),
        locations = cells_row_groups()
    ) |>
    tab_footnote(
        md("Note: ADVAN=ADVAN Mobility Data, NHTS=National Household Travel Survey. Summary of Poisson model results over 1,000 iterations.")
    )
```

```{r} 
#| label: fig-betas
#| fig-cap: Summary of popularity effect estimates across 1,000 iterations
text.beta <- data.frame(
    median.coeff = c(0, 0),
    param = c(4, 4),
    emp = c("ADVAN", "ADVAN"),
    sim = c("GPT-4.1 Nano", "GPT-4.1 Nano"),
    label = c("***Negative rescaling*** ←", "→ ***Positive rescaling***")
)

p.betas <- draw_beta_fig(betas.sum) +
    scale_shape_manual(
        values = c("Gemini 2.5 Flash Lite" = 20, "GPT-4.1 Nano" = 18)
    ) +
    scale_color_manual(
        values = c("Gemini 2.5 Flash Lite" = color.gemini, "GPT-4.1 Nano" = color.gpt)
    ) +
    # annotate attenuation (B<0) and amplification (B>0)
    geom_richtext(
        data = text.beta,
        label = text.beta$label,
        color = "black",
        fill = NA, label.color = NA,
        vjust = -2,
        hjust = c(1.1, -0.1),
        size = 4,
    ) +
    labs(
        title = "Generative AI Amplify Popularity of Destination-Month Pairs",
        subtitle = "Other popularity factors are dependent on specific large language model used and show mixed results",
        caption = "Note: Summary of Poisson model results over 1,000 iterations. Error bars represent 95% credible intervals for the estimates.",
    )
p.betas
```

## Robustness checks

We conducted following robustness checks to test the sensitivity of our findings to different simulation choices (reported in @apx-robust).
These additional simulations were performed with the first 100 iterations due to budget and computing time constraints.
First, using alternative prompts does not substantially change the main findings.
Large language model outputs are sensitive to the specific prompts used.
Hence, we collected additional simulation data using slightly modified prompts (see @apx-prompt).
One version excluded explicit instruction that demographic factors influence tourist choices ("reduced instruction" prompt).
Another version instructed the models to act as *tourists* choosing destinations instead of travel agents giving suggestions ("tourist persona" prompt).
None of these alterations substantially changed the main findings (@fig-prompt-betas).
One notable exception is that Gemini 2.5 Flash Lite with reduced instruction prompt showed negative coefficients for month popularity.
However, this case also showed stronger effects for destination-month and origin-destination popularity than the original prompt did.

Changing the temperature parameter also does not alter the results.
The temperature parameter controls randomness in LLM outputs.
Higher temperature settings produce more diverse outputs, while lower temperature settings generate more deterministic outputs.
The default temperature setting used in our main analysis is 1.0.
We collected additional data using temperatures of 0.5 and 1.5 (@fig-temp-betas).
GPT-4.1 Nano with a temperature of 1.5 could not generate valid outputs and hence was excluded.
Similar to @bai2025, we find that temperature setting has minimal impact on the popularity bias of LLMs.

Larger models in the Gemini 2.5 and GPT-4.1 series, as well as models from other providers, still show positive destination-month popularity bias.
We repeated the main analysis with larger variants of Gemini 2.5 and GPT-4.1 series models (Gemini 2.5 Flash and GPT-4.1 Mini).
Additionally, we collected data using xAI's Grok 3 Mini and Meta's Llama 4 Scout to examine whether the findings are generalizable beyond OpenAI and Google models.
Across all models tested, destination-month popularity shows the strongest positive effects (@fig-model-betas).
Compared to the models used in our main analysis, larger models show stronger destination-month popularity bias, not weaker.

Finally, the results are unchanged when aggregating data across all iterations instead of fitting Poisson regression models for each iteration separately.
We conducted alternative hypothesis tests by aggregating the simulation data across all 1,000 iterations and fitting a single Poisson regression model for each LLM simulation.
This approach significantly reduces the number of destination-origin-month cells with zero tourist counts.
We can also obtain significance levels for the estimated coefficients using  traditional frequentist tests.
Still, coefficient estimates using aggregated data are nearly identical to median estimates from our main approach (see @tbl-agg-betas).

# Discussions

We provide empirical evidence on how generative AI diverges from empirical tourism patterns and what underlying mechanisms drive such differences.
Such generative AI models are complex and opaque.
But so are humans.
Tourists are complex decision-makers influenced by myriad factors, many of which are not fully understood.
Same as how social scientists study human cognitive bases based on their behaviors, we proposed a model for testing hypothesized mechanisms behind generative AI biases.
Beyond quantifying the difference between algorithm outcomes and empirically grounded baselines, our model allowed us to obtain interpretable results on what factors drive such differences.

## Key findings

LLMs generate less diverse and more unevenly distributed tourist flows than empirical US domestic tourism patterns.
States show slightly more unequal levels of tourist arrivals, with popular states continuing to be popular in LLM simulations (@fig-prop[a]()).
More critically, both models produce highly seasonal tourism patterns.
While seasonality is a common feature of tourism [@butler1994; @duro2016], LLMs yield much sharper peaks and troughs than empirical data (@fig-prop[b]()).
This finding is alarming for *all* US destinations, as both popular and less popular states show more seasonal tourism demand (@fig-prop[c]()).
Destinations also become more reliant on fewer tourist origins in LLM simulations (@fig-prop[d]()).

The models also produce structurally different tourist flows (@fig-graph-stats).
In LLM simulations, destinations would receive more tourists but send fewer to others, leading to a more "one-way" tourism system.
Although two models also tend to recommend farther destinations, other spatial patterns differ between two LLMs.
GPT-4.1 Nano strongly avoids bordering states and favors in-state tourism, whereas Gemini 2.5 Flash Lite behaves more similarly to empirical patterns in these aspects.
Bias in the spatial perception of these models is one possible explanation, such as overestimation of inter-regional distance [@fulman2024].
Given that these algorithms are *language* models, the outputs also reflect how linguistic and cultural representations of tourism in training data [see @resnik2025; @tao2024].

LLMs favor visiting destinations during their peak months (@fig-betas).
We find robust evidence of this positive destination-month popularity bias  across prompts, temperature settings, and additional LLMs (@apx-robust).
Findings are mixed for the other three popularity biases.
Results vary primarily by LLM used, rather than by simulation settings or empirical baselines.
For example, two GPT-4.1 models amplify origin-destination popularity bias, while other LLMs attenuate destination popularity bias.
Unfortunately, this study could not identify why LLMs show different types and degrees of popularity biases.
The differences are likely due to variations in training data, model architectures, and human feedback [@santurkar2023].
Biases also arise from feedback loops where human biases seep into training data, producing biased models that in turn influence human behavior [@chen2023d].
More transparency from developers about training processes and data sources of generative AI will help us to better understand the causes of such biases.

## Theoretical implications

This study provides early evidence that generative AI poses significant potential to undermine the sustainability and resilience of the tourism sector.
Our findings substantiate prior concerns about these algorithms introducing biases that exacerbate ethical and social issues in tourism [@law2025; @lehto2025; @mellors2025].
We show that such biases have tangible consequences for destinations, including stronger seasonality, reduced demand diversity, and weaker reciprocal exchange of tourists.
All these outcomes defy conditions for fostering a sustainable and resilient tourism sector [for example, @cisneros-martinez2018; @lee2025c; @wttc2022].
Thus, we echo the previous cautions that technology adoptions in tourism should not be seen as *progress* or *advancements*; rather, they are *changes* that we must carefully assess their broad implications [@tribe2017].

The proposed Baseline-Rescaling-Outcome Model contributes to existing literature on AI bias metrics by offering an interpretable framework for testing algorithmic biases.
The existing methods often required access to internal model parameters and mainly tested the presence of bias [@bai2025; @chen2023d].
Our approach further allows testing multiple hypothesized mechanisms that could amplify or attenuate empirical patterns, thereby explaining why we observed divergence from empirical data.
While these explanations are still correlational than causal, they are a basis for unraveling systemic mechanisms behind the black-box algorithms.

This study focused on measuring bias in generative AI from the supplier-side and its implications for destinations.
However, bias and its consequences can also be studied from the demand-side, focusing on whether *tourists* receive personalized and diverse travel options.
For instance, a recommendation algorithm with supplier-side popularity bias can lead to users receiving less satisfying options [@abdollahpouri2020].
Similarly, causes of these biases can also be speculated from both demand- and supply-side.
Biases may also arise from both learning demand-side popularities and supply-side imbalances visibility of destinations in training data.

Our LLM simulations are projections wherein all tourists’ decisions are made by generative AI.
This hypothetical scenario allowed us to anticipate consequences of generative AI adoption rather than document them *a posteriori*.
Currently, empirical phenomena of generative AI adoption outpace tourism knowledge production, due to generative AI's rapid evolution and academic publication delays.
We thus need an alternative route: *a priori* knowledge production by tourism scholars that informs decision-making in tourism practice.
Such forward-looking research will be crucial for tourism scholarship and practitioners to ensure sustainable and resilient tourism systems amid rapid technological changes.

## Methodological contributions

This study pioneers large-scale, empirically grounded generative AI simulations for tourism research.
We ensure representativeness of the simulations by using real-world demographic profiles.
In contrast, prior studies either used hypothetical tourists or failed to specify what tourists the AI needs to simulate [for example @andreev2025; @xiong2024].
By running 1,000 iterations of simulations with varied samples of demographic profiles, we capture stochasticity in generative AI outputs instead of relying on a single run [for example @andreev2025;@mellors2025].
Tourism is a complex system, where the outcomes are probabilistic rather than deterministic [@faulkner2003].
As such, our approach acknowledges that even the empirical data is one of many possible outcomes.
By creating simulated realizations of the tourism patterns under empirical-driven and AI-driven scenarios, we can better project the range of possible outcomes and identify which observed patterns constitute robust features versus artifacts of stochastic variation.
We provide all code and synthetic data from the simulations for replicating and extending our analyses.
This includes the full dataset of two million individual-level travel suggestions from two main LLMs and an additional one million obtained for robustness checks.

Based on the findings, we question the validity of using AI-generated synthetic data even for exploratory and early-stage research purposes [suggested by @ali2025; @viglia2024a].
Despite our efforts to ensure representativeness and robustness of simulations, LLMs still produced tourism patterns that diverge substantially from empirical data.
@santurkar2023 also show that generative AI poorly represent both the general public and particular subpopulations even when steered to do so.
Because our purpose is to examine the biases in generative AI, such divergences are informative.
However, if researchers use AI-generated synthetic data for a pilot study, the results may mislead future research directions.
As these algorithms behave in more extreme and different ways than real-world tourists, we must caution against synthetic data *limiting* tourism knowledge development rather than advancing it.

## Practical implications

Our perspective is that generative AI has benefits for tourism sectors but we also need to weigh its potential risks.
It can be used as a tool for tourists to efficiently seek travel information, practitioners to guide their decisions, and destinations to get ideas for improving their tourism experiences [@dogru2025].
Nevertheless, these benefits are not without costs; they also introduce new issues in tourism.
Therefore, we urge tourism practitioners and regulators to monitor and prepare for generative AI’s potential impacts on tourist behavior and destination choice.

Lesser-known destinations are particularly vulnerable.
Generative AI models train on extensive cross-domain datasets, making their outputs difficult to alter.
Addressing such challenges would require efforts from both regulators and tourism intermediaries to ensure equitable and diverse representation of destinations.
For example, the EU AI Act mandates bias testing for high-risk AI systems, such as credit scoring and employment screening [@vanbekkum2025].
The tourism sector could also advocate for similar legislation for auditing biases.
Such bias audits would be needed for both tourist- and employee-facing generative AI applications.
We urge already-popular destinations to advocate such policies, as negative consequences like worsened seasonality and reduced demand diversity equally affect them.
More simple interventions could be implemented by tourism intermediaries, such as putting a disclosure that "AI-generated suggestions may overrepresent popular options" and stratifying options before producing AI-generated options.

We call for national and international tourism organizations to begin assessing implications of generative AI adoption, including potential ethical and social consequences that were not examined in this study.
Organizations must recognize that tourism functions not merely as a "market offering" but as a societal force affecting people and communities [@higgins-desbiolles2006].
For example, one social benefit of tourism is that it provides experiences and opportunities for socially excluded groups [@mccabe2020a].
These benefits may diminish if generative AI limits travel options for particular demographic groups.
While we caution generative AI's potential consequences for tourism, the time is right to proactively shape the future of tourism before generative AI is further integrated into tourism industries.
Our projected generative AI-driven tourism is still hypothetical; it is up to us whether such a future may never come to pass.

## Limitations and future research

Consider the following limitations when interpreting our findings.
The results are subject to the modifiable areal unit problem  [@fotheringham1991].
LLMs recommended destinations in varying geographic units, which we aggregated to the state level for analyses.
This aggregation masks variations at finer geographic scales, thus likely underestimates the differences between the empirical and generative AI-driven simulations.

Our LLM simulations rely solely on demographic factors and exclude psychological, behavioral, and social factors that shape tourist decisions.
Two individuals with identical demographic profiles may visit the same destination with entirely different motivations.
Future research could specify preferences and motivations for each simulated tourist [see @gao2024].
Acceptance rates of generative AI recommendations also vary by tourists.
For instance, younger individuals are generally more inclined to accept generative AI recommendations than older individuals [@seyfi2025], which could result in different travel patterns than those observed in our "extreme-case" scenarios.
Future research could explore scenarios where acceptance rates of generative AI recommendations vary across different demographic groups.
Such analysis would reveal whether outcomes of generative AI biases scale linearly or require a critical mass of adoption for substantial impacts.

The simulations assume that everyone travels and selects a single destination, excluding non-travelers and multi-destination trips [@haukeland1990; @yang2013].
We also do not account for interactions between simulated individuals, although empirical studies show one tourist's decision influencing decisions of others [@lee2025a].
Further, studies show that generative AI exhibits stronger bias in relative decisions than absolute ones [@bai2025].
Because we instructed LLMs to recommend any single destination instead of giving alternatives, the degree of popularity bias shown in this study may be conservative.
However, decisions of real-world tourists are also significantly affected by how and what choices are presented [@kim2025c].
For future research examining generative AI models' biases in relative decision-making, we recommend conducting both empirical experiments and AI-driven simulations.

Future research could refine how popularity biases are measured, including non-linear effects where destinations with popularity under a certain threshold receive no recommendations at all.
Our operationalization of the Baseline-Rescaling-Outcome Model is also less reliable when the peaks of empirical and generative AI-driven tourism patterns poorly align.
Further extensions could consider including additional model terms that account for shifts in rank orders of options.
Finally, we recommend applying our model to other types of biases and algorithms.
Examining socio-demographic biases in consumer and employee-facing generative AI applications would be crucial for ensuring ethical and fair integration of generative AI.

# Data availability

The data and code for reproducing the results are available at [https://github.com/jinvim/genai-tourism-bias](https://github.com/jinvim/genai-tourism-bias).

# Generative AI disclosure

The authors used GPT-5.2 for grammar and stylistic changes.
The manuscript was carefully reviewed and edited by the authors to ensure accuracy of content.
All figures and tables are the authors' original work.


::: {#refs}
:::

{{< pagebreak >}}

{{< include appendix.qmd >}}